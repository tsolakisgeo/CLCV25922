{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7d46968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "f = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526a363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe.\n"
     ]
    }
   ],
   "source": [
    "print(f[0:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The questions I would like to talk about are: one, where did we come from? How did the universe come into being?\n"
     ]
    }
   ],
   "source": [
    "print(f[52:164])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe.', 'The', 'questions', 'I', 'would', 'like', 'to', 'talk', 'about', 'are:', 'one,', 'where', 'did', 'we', 'come', 'from?', 'How', 'did', 'the', 'universe', 'come', 'into', 'being?', 'Are', 'we', 'alone', 'in', 'the', 'universe?', 'Is', 'there', 'alien', 'life', 'out', 'there?', 'What', 'is', 'the', 'future', 'of', 'the', 'human', 'race?', 'Up', 'until', 'the', '1920s,', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time.', 'Then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding.', 'Distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us.', 'This', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past.', 'If', 'we', 'extrapolate', 'back,', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago.', 'This', 'was', 'the', 'Big', 'Bang,', 'the', 'beginning', 'of', 'the', 'universe.', 'But', 'was', 'there', 'anything', 'before', 'the', 'Big', 'Bang?', 'If', 'not,', 'what', 'created', 'the', 'universe?', 'Why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'Big', 'Bang', 'the', 'way', 'it', 'did?', 'We', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts.', 'First,', 'there', 'were', 'the', 'laws', 'like', 'Maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe,', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time.', 'And', 'second,', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe.', 'We', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part,', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions.', 'But', 'until', 'recently,', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe.', 'However,', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct.', 'Under', 'extreme', 'conditions,', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space.', 'This', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space,', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state.', 'The', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing.', 'Moreover,', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states.', 'These', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'WMAP', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background,', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe.', 'We', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation.', 'Maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence.', 'I', 'now', 'turn', 'to', 'the', 'second', 'big', 'question:', 'are', 'we', 'alone,', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe?', 'We', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'Earth,', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets,', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy.', 'But', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared.', 'We', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing.', 'The', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '3.5', 'billion', 'years', 'ago.', 'The', 'Earth', 'was', 'formed', '4.6', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years.', 'So', 'life', 'appeared', 'on', 'Earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible,', 'which', 'is', 'short', 'compared', 'to', 'the', '10-billion-year', 'lifetime', 'of', 'a', 'planet', 'of', 'Earth', 'type.', 'This', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high.', 'If', 'it', 'was', 'very', 'low,', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available.', 'On', 'the', 'other', 'hand,', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens.', 'I', 'am', 'discounting', 'the', 'reports', 'of', 'UFOs.', 'Why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos?', 'If', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring,', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far.', 'Furthermore,', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'SETI', 'project,', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows.', 'This', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years.', 'Issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet.', 'This', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions:', 'the', 'future', 'of', 'the', 'human', 'race.', 'If', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy,', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue.', 'But', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history.', 'Our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'Earth', 'are', 'growing', 'exponentially,', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill.', 'But', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past.', 'It', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years,', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million.', 'Our', 'only', 'chance', 'of', 'long-term', 'survival', 'is', 'not', 'to', 'remain', 'inward-looking', 'on', 'planet', 'Earth,', 'but', 'to', 'spread', 'out', 'into', 'space.', 'The', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years.', 'But', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years,', 'our', 'future', 'is', 'in', 'space.', 'That', 'is', 'why', 'I', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'I', 'say,', 'personned', '–', 'space', 'flight.', 'All', 'of', 'my', 'life', 'I', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions.', 'I', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap.', 'Indeed,', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge.', 'The', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe,', 'and', 'we', 'are', 'making', 'good', 'progress.', 'Thank', 'you', 'for', 'listening.']\n"
     ]
    }
   ],
   "source": [
    "with open('Hawking-Questioning-the-Universe.txt', \"r\") as f:\n",
    "    text_as_list=[word for line in f for word in line.split()]\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe', 'the', 'questions', 'i', 'would', 'like', 'to', 'talk', 'about', 'are', 'one', 'where', 'did', 'we', 'come', 'from', 'how', 'did', 'the', 'universe', 'come', 'into', 'being', 'are', 'we', 'alone', 'in', 'the', 'universe', 'is', 'there', 'alien', 'life', 'out', 'there', 'what', 'is', 'the', 'future', 'of', 'the', 'human', 'race', 'up', 'until', 'the', '1920s', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time', 'then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding', 'distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us', 'this', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past', 'if', 'we', 'extrapolate', 'back', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago', 'this', 'was', 'the', 'big', 'bang', 'the', 'beginning', 'of', 'the', 'universe', 'but', 'was', 'there', 'anything', 'before', 'the', 'big', 'bang', 'if', 'not', 'what', 'created', 'the', 'universe', 'why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'big', 'bang', 'the', 'way', 'it', 'did', 'we', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts', 'first', 'there', 'were', 'the', 'laws', 'like', 'maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time', 'and', 'second', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe', 'we', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions', 'but', 'until', 'recently', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe', 'however', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct', 'under', 'extreme', 'conditions', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space', 'this', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state', 'the', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing', 'moreover', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states', 'these', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'wmap', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe', 'we', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation', 'maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence', 'i', 'now', 'turn', 'to', 'the', 'second', 'big', 'question', 'are', 'we', 'alone', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe', 'we', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'earth', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy', 'but', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared', 'we', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing', 'the', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '35', 'billion', 'years', 'ago', 'the', 'earth', 'was', 'formed', '46', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years', 'so', 'life', 'appeared', 'on', 'earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible', 'which', 'is', 'short', 'compared', 'to', 'the', '10billionyear', 'lifetime', 'of', 'a', 'planet', 'of', 'earth', 'type', 'this', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high', 'if', 'it', 'was', 'very', 'low', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available', 'on', 'the', 'other', 'hand', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens', 'i', 'am', 'discounting', 'the', 'reports', 'of', 'ufos', 'why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos', 'if', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far', 'furthermore', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'seti', 'project', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows', 'this', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years', 'issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet', 'this', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions', 'the', 'future', 'of', 'the', 'human', 'race', 'if', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue', 'but', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history', 'our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'earth', 'are', 'growing', 'exponentially', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill', 'but', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past', 'it', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million', 'our', 'only', 'chance', 'of', 'longterm', 'survival', 'is', 'not', 'to', 'remain', 'inwardlooking', 'on', 'planet', 'earth', 'but', 'to', 'spread', 'out', 'into', 'space', 'the', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years', 'but', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years', 'our', 'future', 'is', 'in', 'space', 'that', 'is', 'why', 'i', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'i', 'say', 'personned', '–', 'space', 'flight', 'all', 'of', 'my', 'life', 'i', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions', 'i', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap', 'indeed', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge', 'the', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe', 'and', 'we', 'are', 'making', 'good', 'progress', 'thank', 'you', 'for', 'listening']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'are', 'are', 'alone', 'alien', 'and', 'away', 'all', 'about', 'ago', 'anything', 'and', 'all', 'at', 'and', 'and', 'all', 'about', 'and', 'and', 'and', 'and', 'allow', 'another', 'and', 'and', 'also', 'a', 'are', 'agreement', 'an', 'and', 'are', 'alone', 'arose', 'appear', 'a', 'appeared', 'appearing', 'algae', 'ago', 'ago', 'and', 'about', 'appeared', 'a', 'a', 'appearing', 'available', 'aliens', 'am', 'appear', 'and', 'a', 'and', 'aliens', 'a', 'an', 'any', 'alien', 'are', 'alien', 'at', 'a', 'a', 'an', 'against', 'abduction', 'aliens', 'a', 'are', 'and', 'are', 'an', 'and', 'are', 'along', 'ability', 'and', 'aggressive', 'advantage', 'avoid', 'alone', 'answers', 'am', 'all', 'and', 'answers', 'a', 'a', 'and', 'are']\n"
     ]
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "for word in text_as_list:\n",
    "    if word.startswith(\"a\"):\n",
    "        words_begin_with_a.append(word)\n",
    "print(words_begin_with_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "while i<len(text_as_list):\n",
    "    if not text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38e92923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, universe appears in the text.\n"
     ]
    }
   ],
   "source": [
    "if \"universe\" in text_as_list:\n",
    "    print(\"Yes, universe appears in the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"aliens\" in text_as_list:\n",
    "    print(\"the word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d9304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ea11f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if \"aliens\" in text_as_list:\n",
    "    print()\n",
    "elif \"International Space Station\" in text_as_list:\n",
    "    print()\n",
    "else:\n",
    "    print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "for i, j in enumerate(text_as_list):\n",
    "    mydictionary[j] = i\n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "for i, j in enumerate(text_as_list):\n",
    "    mydictionary[i] = j\n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first method only displays each unique word once with the index of its final placement. The second method pairs each index to the specific word, so the whole text is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c902a269",
   "metadata": {},
   "source": [
    "#### Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 10, 'is': 13, 'nothing': 2, 'bigger': 1, 'or': 5, 'older': 1, 'than': 2, 'the': 77, 'universe': 19, 'questions': 4, 'i': 7, 'would': 3, 'like': 3, 'to': 22, 'talk': 1, 'about': 4, 'are': 9, 'one': 3, 'where': 1, 'did': 4, 'we': 26, 'come': 2, 'from': 4, 'how': 2, 'into': 4, 'being': 3, 'alone': 3, 'in': 14, 'alien': 3, 'life': 9, 'out': 3, 'what': 2, 'future': 3, 'of': 39, 'human': 2, 'race': 2, 'up': 1, 'until': 2, '1920s': 1, 'everyone': 2, 'thought': 1, 'was': 10, 'essentially': 1, 'static': 1, 'and': 19, 'unchanging': 1, 'time': 6, 'then': 1, 'it': 9, 'discovered': 1, 'that': 12, 'expanding': 1, 'distant': 1, 'galaxies': 1, 'were': 3, 'moving': 1, 'away': 1, 'us': 1, 'this': 7, 'meant': 1, 'they': 2, 'must': 3, 'have': 14, 'been': 6, 'closer': 1, 'together': 1, 'past': 2, 'if': 6, 'extrapolate': 1, 'back': 1, 'find': 2, 'all': 4, 'on': 9, 'top': 1, 'each': 1, 'other': 4, '15': 1, 'billion': 6, 'years': 10, 'ago': 3, 'big': 6, 'bang': 3, 'beginning': 1, 'but': 8, 'anything': 1, 'before': 1, 'not': 3, 'created': 2, 'why': 3, 'emerge': 1, 'way': 1, 'used': 1, 'think': 2, 'theory': 3, 'could': 1, 'be': 4, 'divided': 1, 'two': 2, 'parts': 1, 'first': 5, 'laws': 4, 'maxwell’s': 1, 'equations': 1, 'general': 2, 'relativity': 2, 'determined': 1, 'evolution': 4, 'given': 2, 'its': 1, 'state': 3, 'over': 1, 'space': 7, 'at': 2, 'second': 2, 'no': 2, 'question': 2, 'initial': 4, 'made': 2, 'good': 3, 'progress': 3, 'part': 1, 'now': 2, 'knowledge': 3, 'most': 3, 'extreme': 2, 'conditions': 4, 'recently': 1, 'had': 1, 'little': 1, 'idea': 1, 'for': 8, 'however': 1, 'division': 1, 'depends': 1, 'separate': 1, 'distinct': 1, 'under': 1, 'quantum': 1, 'allow': 1, 'behave': 1, 'another': 1, 'dimension': 1, 'removes': 1, 'distinction': 1, 'between': 1, 'means': 1, 'can': 3, 'also': 1, 'determine': 1, 'spontaneously': 2, 'create': 1, 'itself': 2, 'moreover': 1, 'calculate': 1, 'a': 11, 'probability': 3, 'different': 1, 'states': 1, 'these': 3, 'predictions': 1, 'excellent': 1, 'agreement': 1, 'with': 2, 'observations': 1, 'by': 4, 'wmap': 1, 'satellite': 1, 'cosmic': 1, 'microwave': 1, 'background': 1, 'which': 3, 'an': 4, 'imprint': 1, 'very': 3, 'early': 1, 'solved': 1, 'mystery': 1, 'creation': 1, 'maybe': 1, 'should': 3, 'patent': 1, 'charge': 1, 'royalties': 1, 'their': 1, 'existence': 1, 'turn': 1, 'believe': 1, 'arose': 1, 'earth': 6, 'so': 3, 'possible': 2, 'appear': 2, 'suitable': 1, 'planets': 1, 'seem': 2, 'large': 1, 'number': 1, 'galaxy': 2, 'don’t': 2, 'know': 1, 'appeared': 2, 'pieces': 1, 'observational': 1, 'evidence': 1, 'appearing': 2, 'fossils': 1, 'algae': 1, '35': 1, 'formed': 1, '46': 1, 'probably': 3, 'too': 1, 'hot': 1, 'half': 2, 'within': 2, 'short': 1, 'compared': 1, '10billionyear': 1, 'lifetime': 1, 'planet': 3, 'type': 1, 'suggests': 1, 'reasonably': 1, 'high': 1, 'low': 1, 'expected': 1, 'take': 1, 'ten': 1, 'available': 1, 'hand': 1, 'visited': 1, 'aliens': 3, 'am': 2, 'discounting': 1, 'reports': 2, 'ufos': 1, 'only': 3, 'cranks': 1, 'weirdos': 1, 'government': 1, 'conspiracy': 1, 'suppress': 1, 'keep': 1, 'scientific': 1, 'bring': 1, 'seems': 2, 'singularly': 1, 'ineffective': 1, 'policy': 2, 'far': 1, 'furthermore': 1, 'despite': 1, 'extensive': 1, 'search': 1, 'seti': 1, 'project': 1, 'haven’t': 1, 'heard': 1, 'any': 1, 'television': 1, 'quiz': 1, 'shows': 1, 'indicates': 1, 'civilizations': 1, 'our': 8, 'stage': 1, 'development': 1, 'radius': 1, 'few': 1, 'hundred': 4, 'light': 1, 'issuing': 1, 'insurance': 1, 'against': 1, 'abduction': 1, 'pretty': 1, 'safe': 1, 'bet': 1, 'brings': 1, 'me': 2, 'last': 2, 'intelligent': 1, 'beings': 1, 'make': 1, 'sure': 1, 'survive': 1, 'continue': 2, 'entering': 1, 'increasingly': 1, 'dangerous': 1, 'period': 1, 'history': 1, 'population': 1, 'use': 1, 'finite': 1, 'resources': 1, 'growing': 1, 'exponentially': 1, 'along': 1, 'technical': 1, 'ability': 1, 'change': 1, 'environment': 1, 'ill': 1, 'genetic': 1, 'code': 1, 'still': 1, 'carries': 1, 'selfish': 1, 'aggressive': 1, 'instincts': 1, 'survival': 2, 'advantage': 1, 'will': 1, 'difficult': 1, 'enough': 1, 'avoid': 1, 'disaster': 1, 'next': 3, 'let': 1, 'thousand': 1, 'million': 1, 'chance': 1, 'longterm': 1, 'remain': 1, 'inwardlooking': 1, 'spread': 1, 'answers': 2, 'show': 1, 'remarkable': 1, 'want': 1, 'beyond': 1, 'favor': 1, 'manned': 1, '–': 2, 'say': 1, 'personned': 1, 'flight': 1, 'my': 2, 'sought': 1, 'understand': 1, 'lucky': 1, 'disability': 1, 'has': 2, 'serious': 1, 'handicap': 1, 'indeed': 1, 'more': 1, 'people': 1, 'pursue': 1, 'quest': 1, 'ultimate': 1, 'goal': 1, 'complete': 1, 'making': 1, 'thank': 1, 'you': 1, 'listening': 1}\n"
     ]
    }
   ],
   "source": [
    "dict_counter = {}\n",
    "for word in text_as_list:\n",
    "    if dict_counter.get(word) != None:\n",
    "        dict_counter[word] = dict_counter[word] + 1\n",
    "    else:\n",
    "        dict_counter[word] = 1\n",
    "print(dict_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbfd1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = text_as_list.count(\"question\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecca145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>902</td>\n",
       "      <td>progress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>903</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>904</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>905</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>906</td>\n",
       "      <td>listening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1\n",
       "0      0      there\n",
       "1      1         is\n",
       "2      2    nothing\n",
       "3      3     bigger\n",
       "4      4         or\n",
       "..   ...        ...\n",
       "902  902   progress\n",
       "903  903      thank\n",
       "904  904        you\n",
       "905  905        for\n",
       "906  906  listening\n",
       "\n",
       "[907 rows x 2 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(mydictionary.items())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1    there\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          there\n",
       "1             is\n",
       "2        nothing\n",
       "3         bigger\n",
       "4             or\n",
       "         ...    \n",
       "902     progress\n",
       "903        thank\n",
       "904          you\n",
       "905          for\n",
       "906    listening\n",
       "Name: 1, Length: 907, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxies and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3fe2b30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6d94663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        level_0  index    0\n",
       "1                          \n",
       "galaxy      428    428  428\n",
       "galaxy      680    680  680"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"galaxy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n*fact(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(fact(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return(fib(n-1) + fib(n-2))\n",
    "    \n",
    "print(fib(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
