{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "f = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526a363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe.\n"
     ]
    }
   ],
   "source": [
    "print(f[0:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The questions I would like to talk about are: one, where did we come from? How did the universe come into being?\n"
     ]
    }
   ],
   "source": [
    "print(f[52:164])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe.', 'The', 'questions', 'I', 'would', 'like', 'to', 'talk', 'about', 'are:', 'one,', 'where', 'did', 'we', 'come', 'from?', 'How', 'did', 'the', 'universe', 'come', 'into', 'being?', 'Are', 'we', 'alone', 'in', 'the', 'universe?', 'Is', 'there', 'alien', 'life', 'out', 'there?', 'What', 'is', 'the', 'future', 'of', 'the', 'human', 'race?', 'Up', 'until', 'the', '1920s,', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time.', 'Then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding.', 'Distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us.', 'This', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past.', 'If', 'we', 'extrapolate', 'back,', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago.', 'This', 'was', 'the', 'Big', 'Bang,', 'the', 'beginning', 'of', 'the', 'universe.', 'But', 'was', 'there', 'anything', 'before', 'the', 'Big', 'Bang?', 'If', 'not,', 'what', 'created', 'the', 'universe?', 'Why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'Big', 'Bang', 'the', 'way', 'it', 'did?', 'We', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts.', 'First,', 'there', 'were', 'the', 'laws', 'like', 'Maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe,', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time.', 'And', 'second,', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe.', 'We', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part,', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions.', 'But', 'until', 'recently,', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe.', 'However,', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct.', 'Under', 'extreme', 'conditions,', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space.', 'This', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space,', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state.', 'The', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing.', 'Moreover,', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states.', 'These', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'WMAP', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background,', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe.', 'We', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation.', 'Maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence.', 'I', 'now', 'turn', 'to', 'the', 'second', 'big', 'question:', 'are', 'we', 'alone,', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe?', 'We', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'Earth,', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets,', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy.', 'But', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared.', 'We', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing.', 'The', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '3.5', 'billion', 'years', 'ago.', 'The', 'Earth', 'was', 'formed', '4.6', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years.', 'So', 'life', 'appeared', 'on', 'Earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible,', 'which', 'is', 'short', 'compared', 'to', 'the', '10-billion-year', 'lifetime', 'of', 'a', 'planet', 'of', 'Earth', 'type.', 'This', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high.', 'If', 'it', 'was', 'very', 'low,', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available.', 'On', 'the', 'other', 'hand,', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens.', 'I', 'am', 'discounting', 'the', 'reports', 'of', 'UFOs.', 'Why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos?', 'If', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring,', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far.', 'Furthermore,', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'SETI', 'project,', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows.', 'This', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years.', 'Issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet.', 'This', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions:', 'the', 'future', 'of', 'the', 'human', 'race.', 'If', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy,', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue.', 'But', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history.', 'Our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'Earth', 'are', 'growing', 'exponentially,', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill.', 'But', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past.', 'It', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years,', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million.', 'Our', 'only', 'chance', 'of', 'long-term', 'survival', 'is', 'not', 'to', 'remain', 'inward-looking', 'on', 'planet', 'Earth,', 'but', 'to', 'spread', 'out', 'into', 'space.', 'The', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years.', 'But', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years,', 'our', 'future', 'is', 'in', 'space.', 'That', 'is', 'why', 'I', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'I', 'say,', 'personned', '–', 'space', 'flight.', 'All', 'of', 'my', 'life', 'I', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions.', 'I', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap.', 'Indeed,', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge.', 'The', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe,', 'and', 'we', 'are', 'making', 'good', 'progress.', 'Thank', 'you', 'for', 'listening.']\n"
     ]
    }
   ],
   "source": [
    "with open('Hawking-Questioning-the-Universe.txt') as f:\n",
    "    text_as_list=[word for line in f for word in line.split()]\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe', 'the', 'questions', 'i', 'would', 'like', 'to', 'talk', 'about', 'are', 'one', 'where', 'did', 'we', 'come', 'from', 'how', 'did', 'the', 'universe', 'come', 'into', 'being', 'are', 'we', 'alone', 'in', 'the', 'universe', 'is', 'there', 'alien', 'life', 'out', 'there', 'what', 'is', 'the', 'future', 'of', 'the', 'human', 'race', 'up', 'until', 'the', '1920s', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time', 'then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding', 'distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us', 'this', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past', 'if', 'we', 'extrapolate', 'back', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago', 'this', 'was', 'the', 'big', 'bang', 'the', 'beginning', 'of', 'the', 'universe', 'but', 'was', 'there', 'anything', 'before', 'the', 'big', 'bang', 'if', 'not', 'what', 'created', 'the', 'universe', 'why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'big', 'bang', 'the', 'way', 'it', 'did', 'we', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts', 'first', 'there', 'were', 'the', 'laws', 'like', 'maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time', 'and', 'second', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe', 'we', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions', 'but', 'until', 'recently', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe', 'however', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct', 'under', 'extreme', 'conditions', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space', 'this', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state', 'the', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing', 'moreover', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states', 'these', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'wmap', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe', 'we', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation', 'maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence', 'i', 'now', 'turn', 'to', 'the', 'second', 'big', 'question', 'are', 'we', 'alone', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe', 'we', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'earth', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy', 'but', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared', 'we', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing', 'the', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '35', 'billion', 'years', 'ago', 'the', 'earth', 'was', 'formed', '46', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years', 'so', 'life', 'appeared', 'on', 'earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible', 'which', 'is', 'short', 'compared', 'to', 'the', '10billionyear', 'lifetime', 'of', 'a', 'planet', 'of', 'earth', 'type', 'this', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high', 'if', 'it', 'was', 'very', 'low', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available', 'on', 'the', 'other', 'hand', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens', 'i', 'am', 'discounting', 'the', 'reports', 'of', 'ufos', 'why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos', 'if', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far', 'furthermore', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'seti', 'project', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows', 'this', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years', 'issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet', 'this', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions', 'the', 'future', 'of', 'the', 'human', 'race', 'if', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue', 'but', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history', 'our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'earth', 'are', 'growing', 'exponentially', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill', 'but', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past', 'it', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million', 'our', 'only', 'chance', 'of', 'longterm', 'survival', 'is', 'not', 'to', 'remain', 'inwardlooking', 'on', 'planet', 'earth', 'but', 'to', 'spread', 'out', 'into', 'space', 'the', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years', 'but', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years', 'our', 'future', 'is', 'in', 'space', 'that', 'is', 'why', 'i', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'i', 'say', 'personned', '–', 'space', 'flight', 'all', 'of', 'my', 'life', 'i', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions', 'i', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap', 'indeed', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge', 'the', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe', 'and', 'we', 'are', 'making', 'good', 'progress', 'thank', 'you', 'for', 'listening']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'are', 'are', 'alone', 'alien', 'and', 'away', 'all', 'about', 'ago', 'anything', 'and', 'all', 'at', 'and', 'and', 'all', 'about', 'and', 'and', 'and', 'and', 'allow', 'another', 'and', 'and', 'also', 'a', 'are', 'agreement', 'an', 'and', 'are', 'alone', 'arose', 'appear', 'a', 'appeared', 'appearing', 'algae', 'ago', 'ago', 'and', 'about', 'appeared', 'a', 'a', 'appearing', 'available', 'aliens', 'am', 'appear', 'and', 'a', 'and', 'aliens', 'a', 'an', 'any', 'alien', 'are', 'alien', 'at', 'a', 'a', 'an', 'against', 'abduction', 'aliens', 'a', 'are', 'and', 'are', 'an', 'and', 'are', 'along', 'ability', 'and', 'aggressive', 'advantage', 'avoid', 'alone', 'answers', 'am', 'all', 'and', 'answers', 'a', 'a', 'and', 'are']\n"
     ]
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "for word in text_as_list:\n",
    "    if word.startswith(\"a\"):\n",
    "        words_begin_with_a.append(word)\n",
    "print(words_begin_with_a)\n",
    "\n",
    "# i = 0\n",
    "# counter = 0\n",
    "\n",
    "# while i<len(text_as_list):\n",
    "#     if text_as_list[i].startswith('a'):\n",
    "#         counter += 1\n",
    "#     i += 1\n",
    "# print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "while i<len(text_as_list):\n",
    "    if not text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38e92923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, universe appears in the text.\n"
     ]
    }
   ],
   "source": [
    "if \"universe\" in text_as_list:\n",
    "    print(\"Yes, universe appears in the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"aliens\" in text_as_list:\n",
    "    print(\"the word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d9304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea11f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if \"aliens\" in text_as_list:\n",
    "    print()\n",
    "elif \"International Space Station\" in text_as_list:\n",
    "    print()\n",
    "else:\n",
    "    print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'There': 0, 'is': 890, 'nothing': 2, 'bigger': 3, 'or': 831, 'older': 5, 'than': 878, 'the': 895, 'universe.': 353, 'The': 887, 'questions': 792, 'I': 856, 'would': 563, 'like': 280, 'to': 881, 'talk': 15, 'about': 478, 'are:': 17, 'one,': 18, 'where': 19, 'did': 139, 'we': 898, 'come': 28, 'from?': 23, 'How': 24, 'universe': 849, 'into': 785, 'being?': 30, 'Are': 31, 'alone': 761, 'in': 826, 'universe?': 394, 'Is': 37, 'there': 623, 'alien': 626, 'life': 842, 'out': 784, 'there?': 42, 'What': 43, 'future': 817, 'of': 894, 'human': 669, 'race?': 50, 'Up': 51, 'until': 235, '1920s,': 54, 'everyone': 371, 'thought': 56, 'was': 525, 'essentially': 60, 'static': 61, 'and': 897, 'unchanging': 63, 'time.': 194, 'Then': 66, 'it': 871, 'discovered': 69, 'that': 861, 'expanding.': 74, 'Distant': 75, 'galaxies': 76, 'were': 740, 'moving': 78, 'away': 79, 'from': 459, 'us.': 81, 'This': 655, 'meant': 83, 'they': 564, 'must': 406, 'have': 857, 'been': 866, 'closer': 88, 'together': 89, 'past.': 746, 'If': 671, 'extrapolate': 95, 'back,': 96, 'find': 851, 'all': 228, 'on': 778, 'top': 105, 'each': 107, 'other': 544, '15': 110, 'billion': 539, 'years': 540, 'ago.': 463, 'Big': 145, 'Bang,': 118, 'beginning': 120, 'But': 805, 'anything': 127, 'before': 128, 'Bang?': 131, 'not,': 133, 'what': 134, 'created': 324, 'Why': 562, 'emerge': 142, 'Bang': 146, 'way': 148, 'did?': 150, 'We': 437, 'used': 152, 'think': 355, 'theory': 893, 'could': 161, 'be': 749, 'divided': 163, 'two': 439, 'parts.': 166, 'First,': 167, 'laws': 296, 'Maxwell’s': 173, 'equations': 174, 'general': 271, 'relativity': 272, 'determined': 179, 'evolution': 298, 'universe,': 896, 'given': 874, 'its': 186, 'state': 204, 'over': 188, 'space': 837, 'at': 628, 'one': 528, 'And': 195, 'second,': 196, 'no': 625, 'question': 200, 'initial': 303, 'made': 797, 'good': 901, 'progress': 799, 'first': 480, 'part,': 216, 'now': 377, 'knowledge': 587, 'but': 781, 'most': 879, 'extreme': 269, 'conditions.': 233, 'recently,': 236, 'had': 239, 'little': 240, 'idea': 241, 'conditions': 258, 'for': 905, 'However,': 249, 'this': 250, 'division': 251, 'depends': 259, 'time': 877, 'being': 496, 'separate': 265, 'distinct.': 267, 'Under': 268, 'conditions,': 270, 'quantum': 274, 'allow': 276, 'behave': 279, 'another': 281, 'dimension': 282, 'space.': 820, 'removes': 286, 'distinction': 288, 'between': 289, 'space,': 292, 'means': 294, 'can': 316, 'also': 300, 'determine': 301, 'state.': 304, 'spontaneously': 400, 'create': 309, 'itself': 584, 'nothing.': 313, 'Moreover,': 314, 'calculate': 317, 'a': 891, 'probability': 516, 'different': 326, 'states.': 327, 'These': 328, 'predictions': 329, 'are': 899, 'excellent': 332, 'agreement': 333, 'with': 716, 'observations': 335, 'by': 648, 'WMAP': 338, 'satellite': 339, 'cosmic': 342, 'microwave': 343, 'background,': 344, 'which': 498, 'an': 693, 'imprint': 348, 'very': 859, 'early': 352, 'solved': 358, 'mystery': 360, 'creation.': 362, 'Maybe': 363, 'should': 832, 'patent': 366, 'charge': 370, 'royalties': 372, 'their': 374, 'existence.': 375, 'turn': 378, 'second': 381, 'big': 791, 'question:': 383, 'alone,': 386, 'believe': 396, 'arose': 399, 'Earth,': 780, 'so': 600, 'possible': 408, 'appear': 565, 'suitable': 415, 'planets,': 416, 'seem': 548, 'large': 424, 'number': 425, 'galaxy.': 428, 'don’t': 547, 'know': 432, 'how': 433, 'appeared.': 436, 'pieces': 440, 'observational': 442, 'evidence': 443, 'appearing.': 449, 'fossils': 456, 'algae': 458, '3.5': 460, 'Earth': 711, 'formed': 467, '4.6': 468, 'ago': 471, 'probably': 873, 'too': 475, 'hot': 476, 'half': 490, 'years.': 804, 'So': 484, 'appeared': 486, 'within': 633, 'possible,': 497, 'short': 500, 'compared': 501, '10-billion-year': 504, 'lifetime': 505, 'planet': 779, 'type.': 511, 'suggests': 513, 'appearing': 519, 'reasonably': 521, 'high.': 522, 'low,': 527, 'expected': 531, 'take': 534, 'ten': 538, 'available.': 541, 'On': 542, 'hand,': 545, 'visited': 552, 'aliens.': 554, 'am': 825, 'discounting': 557, 'reports': 580, 'UFOs.': 561, 'only': 768, 'cranks': 568, 'weirdos?': 570, 'government': 575, 'conspiracy': 576, 'suppress': 578, 'keep': 582, 'scientific': 586, 'aliens': 649, 'bring,': 590, 'seems': 650, 'singularly': 597, 'ineffective': 598, 'policy': 645, 'far.': 601, 'Furthermore,': 602, 'despite': 603, 'extensive': 605, 'search': 606, 'SETI': 609, 'project,': 610, 'haven’t': 612, 'heard': 613, 'any': 614, 'television': 616, 'quiz': 617, 'shows.': 618, 'indicates': 621, 'civilizations': 627, 'our': 816, 'stage': 630, 'development': 632, 'radius': 635, 'few': 638, 'hundred': 814, 'light': 640, 'Issuing': 642, 'insurance': 644, 'against': 646, 'abduction': 647, 'pretty': 652, 'safe': 653, 'bet.': 654, 'brings': 656, 'me': 875, 'last': 802, 'questions:': 664, 'race.': 670, 'intelligent': 676, 'beings': 677, 'galaxy,': 680, 'make': 683, 'sure': 684, 'survive': 686, 'continue.': 688, 'entering': 692, 'increasingly': 694, 'dangerous': 695, 'period': 696, 'history.': 699, 'Our': 767, 'population': 701, 'use': 704, 'finite': 707, 'resources': 708, 'growing': 713, 'exponentially,': 714, 'along': 715, 'technical': 718, 'ability': 719, 'change': 721, 'environment': 723, 'ill.': 727, 'genetic': 730, 'code': 731, 'still': 732, 'carries': 733, 'selfish': 735, 'aggressive': 737, 'instincts': 738, 'survival': 772, 'advantage': 743, 'It': 747, 'will': 748, 'difficult': 750, 'enough': 751, 'avoid': 753, 'disaster': 754, 'next': 813, 'years,': 815, 'let': 760, 'thousand': 764, 'million.': 766, 'chance': 769, 'long-term': 771, 'not': 865, 'remain': 776, 'inward-looking': 777, 'spread': 783, 'answers': 852, 'these': 854, 'show': 793, 'remarkable': 798, 'if': 806, 'want': 808, 'continue': 810, 'beyond': 811, 'That': 821, 'why': 823, 'favor': 827, 'manned': 829, '–': 836, 'say,': 834, 'personned': 835, 'flight.': 838, 'All': 839, 'my': 862, 'sought': 845, 'understand': 847, 'questions.': 855, 'lucky': 860, 'disability': 863, 'has': 872, 'serious': 868, 'handicap.': 869, 'Indeed,': 870, 'more': 876, 'people': 880, 'pursue': 882, 'quest': 884, 'knowledge.': 886, 'ultimate': 888, 'goal': 889, 'complete': 892, 'making': 900, 'progress.': 902, 'Thank': 903, 'you': 904, 'listening.': 906}\n"
     ]
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "for idx, word in enumerate(text_as_list):\n",
    "    mydictionary[word] = idx\n",
    "print(mydictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'There', 1: 'is', 2: 'nothing', 3: 'bigger', 4: 'or', 5: 'older', 6: 'than', 7: 'the', 8: 'universe.', 9: 'The', 10: 'questions', 11: 'I', 12: 'would', 13: 'like', 14: 'to', 15: 'talk', 16: 'about', 17: 'are:', 18: 'one,', 19: 'where', 20: 'did', 21: 'we', 22: 'come', 23: 'from?', 24: 'How', 25: 'did', 26: 'the', 27: 'universe', 28: 'come', 29: 'into', 30: 'being?', 31: 'Are', 32: 'we', 33: 'alone', 34: 'in', 35: 'the', 36: 'universe?', 37: 'Is', 38: 'there', 39: 'alien', 40: 'life', 41: 'out', 42: 'there?', 43: 'What', 44: 'is', 45: 'the', 46: 'future', 47: 'of', 48: 'the', 49: 'human', 50: 'race?', 51: 'Up', 52: 'until', 53: 'the', 54: '1920s,', 55: 'everyone', 56: 'thought', 57: 'the', 58: 'universe', 59: 'was', 60: 'essentially', 61: 'static', 62: 'and', 63: 'unchanging', 64: 'in', 65: 'time.', 66: 'Then', 67: 'it', 68: 'was', 69: 'discovered', 70: 'that', 71: 'the', 72: 'universe', 73: 'was', 74: 'expanding.', 75: 'Distant', 76: 'galaxies', 77: 'were', 78: 'moving', 79: 'away', 80: 'from', 81: 'us.', 82: 'This', 83: 'meant', 84: 'they', 85: 'must', 86: 'have', 87: 'been', 88: 'closer', 89: 'together', 90: 'in', 91: 'the', 92: 'past.', 93: 'If', 94: 'we', 95: 'extrapolate', 96: 'back,', 97: 'we', 98: 'find', 99: 'we', 100: 'must', 101: 'have', 102: 'all', 103: 'been', 104: 'on', 105: 'top', 106: 'of', 107: 'each', 108: 'other', 109: 'about', 110: '15', 111: 'billion', 112: 'years', 113: 'ago.', 114: 'This', 115: 'was', 116: 'the', 117: 'Big', 118: 'Bang,', 119: 'the', 120: 'beginning', 121: 'of', 122: 'the', 123: 'universe.', 124: 'But', 125: 'was', 126: 'there', 127: 'anything', 128: 'before', 129: 'the', 130: 'Big', 131: 'Bang?', 132: 'If', 133: 'not,', 134: 'what', 135: 'created', 136: 'the', 137: 'universe?', 138: 'Why', 139: 'did', 140: 'the', 141: 'universe', 142: 'emerge', 143: 'from', 144: 'the', 145: 'Big', 146: 'Bang', 147: 'the', 148: 'way', 149: 'it', 150: 'did?', 151: 'We', 152: 'used', 153: 'to', 154: 'think', 155: 'that', 156: 'the', 157: 'theory', 158: 'of', 159: 'the', 160: 'universe', 161: 'could', 162: 'be', 163: 'divided', 164: 'into', 165: 'two', 166: 'parts.', 167: 'First,', 168: 'there', 169: 'were', 170: 'the', 171: 'laws', 172: 'like', 173: 'Maxwell’s', 174: 'equations', 175: 'and', 176: 'general', 177: 'relativity', 178: 'that', 179: 'determined', 180: 'the', 181: 'evolution', 182: 'of', 183: 'the', 184: 'universe,', 185: 'given', 186: 'its', 187: 'state', 188: 'over', 189: 'all', 190: 'of', 191: 'space', 192: 'at', 193: 'one', 194: 'time.', 195: 'And', 196: 'second,', 197: 'there', 198: 'was', 199: 'no', 200: 'question', 201: 'of', 202: 'the', 203: 'initial', 204: 'state', 205: 'of', 206: 'the', 207: 'universe.', 208: 'We', 209: 'have', 210: 'made', 211: 'good', 212: 'progress', 213: 'on', 214: 'the', 215: 'first', 216: 'part,', 217: 'and', 218: 'now', 219: 'have', 220: 'the', 221: 'knowledge', 222: 'of', 223: 'the', 224: 'laws', 225: 'of', 226: 'evolution', 227: 'in', 228: 'all', 229: 'but', 230: 'the', 231: 'most', 232: 'extreme', 233: 'conditions.', 234: 'But', 235: 'until', 236: 'recently,', 237: 'we', 238: 'have', 239: 'had', 240: 'little', 241: 'idea', 242: 'about', 243: 'the', 244: 'initial', 245: 'conditions', 246: 'for', 247: 'the', 248: 'universe.', 249: 'However,', 250: 'this', 251: 'division', 252: 'into', 253: 'laws', 254: 'of', 255: 'evolution', 256: 'and', 257: 'initial', 258: 'conditions', 259: 'depends', 260: 'on', 261: 'time', 262: 'and', 263: 'space', 264: 'being', 265: 'separate', 266: 'and', 267: 'distinct.', 268: 'Under', 269: 'extreme', 270: 'conditions,', 271: 'general', 272: 'relativity', 273: 'and', 274: 'quantum', 275: 'theory', 276: 'allow', 277: 'time', 278: 'to', 279: 'behave', 280: 'like', 281: 'another', 282: 'dimension', 283: 'of', 284: 'space.', 285: 'This', 286: 'removes', 287: 'the', 288: 'distinction', 289: 'between', 290: 'time', 291: 'and', 292: 'space,', 293: 'and', 294: 'means', 295: 'the', 296: 'laws', 297: 'of', 298: 'evolution', 299: 'can', 300: 'also', 301: 'determine', 302: 'the', 303: 'initial', 304: 'state.', 305: 'The', 306: 'universe', 307: 'can', 308: 'spontaneously', 309: 'create', 310: 'itself', 311: 'out', 312: 'of', 313: 'nothing.', 314: 'Moreover,', 315: 'we', 316: 'can', 317: 'calculate', 318: 'a', 319: 'probability', 320: 'that', 321: 'the', 322: 'universe', 323: 'was', 324: 'created', 325: 'in', 326: 'different', 327: 'states.', 328: 'These', 329: 'predictions', 330: 'are', 331: 'in', 332: 'excellent', 333: 'agreement', 334: 'with', 335: 'observations', 336: 'by', 337: 'the', 338: 'WMAP', 339: 'satellite', 340: 'of', 341: 'the', 342: 'cosmic', 343: 'microwave', 344: 'background,', 345: 'which', 346: 'is', 347: 'an', 348: 'imprint', 349: 'of', 350: 'the', 351: 'very', 352: 'early', 353: 'universe.', 354: 'We', 355: 'think', 356: 'we', 357: 'have', 358: 'solved', 359: 'the', 360: 'mystery', 361: 'of', 362: 'creation.', 363: 'Maybe', 364: 'we', 365: 'should', 366: 'patent', 367: 'the', 368: 'universe', 369: 'and', 370: 'charge', 371: 'everyone', 372: 'royalties', 373: 'for', 374: 'their', 375: 'existence.', 376: 'I', 377: 'now', 378: 'turn', 379: 'to', 380: 'the', 381: 'second', 382: 'big', 383: 'question:', 384: 'are', 385: 'we', 386: 'alone,', 387: 'or', 388: 'is', 389: 'there', 390: 'other', 391: 'life', 392: 'in', 393: 'the', 394: 'universe?', 395: 'We', 396: 'believe', 397: 'that', 398: 'life', 399: 'arose', 400: 'spontaneously', 401: 'on', 402: 'the', 403: 'Earth,', 404: 'so', 405: 'it', 406: 'must', 407: 'be', 408: 'possible', 409: 'for', 410: 'life', 411: 'to', 412: 'appear', 413: 'on', 414: 'other', 415: 'suitable', 416: 'planets,', 417: 'of', 418: 'which', 419: 'there', 420: 'seem', 421: 'to', 422: 'be', 423: 'a', 424: 'large', 425: 'number', 426: 'in', 427: 'the', 428: 'galaxy.', 429: 'But', 430: 'we', 431: 'don’t', 432: 'know', 433: 'how', 434: 'life', 435: 'first', 436: 'appeared.', 437: 'We', 438: 'have', 439: 'two', 440: 'pieces', 441: 'of', 442: 'observational', 443: 'evidence', 444: 'on', 445: 'the', 446: 'probability', 447: 'of', 448: 'life', 449: 'appearing.', 450: 'The', 451: 'first', 452: 'is', 453: 'that', 454: 'we', 455: 'have', 456: 'fossils', 457: 'of', 458: 'algae', 459: 'from', 460: '3.5', 461: 'billion', 462: 'years', 463: 'ago.', 464: 'The', 465: 'Earth', 466: 'was', 467: 'formed', 468: '4.6', 469: 'billion', 470: 'years', 471: 'ago', 472: 'and', 473: 'was', 474: 'probably', 475: 'too', 476: 'hot', 477: 'for', 478: 'about', 479: 'the', 480: 'first', 481: 'half', 482: 'billion', 483: 'years.', 484: 'So', 485: 'life', 486: 'appeared', 487: 'on', 488: 'Earth', 489: 'within', 490: 'half', 491: 'a', 492: 'billion', 493: 'years', 494: 'of', 495: 'it', 496: 'being', 497: 'possible,', 498: 'which', 499: 'is', 500: 'short', 501: 'compared', 502: 'to', 503: 'the', 504: '10-billion-year', 505: 'lifetime', 506: 'of', 507: 'a', 508: 'planet', 509: 'of', 510: 'Earth', 511: 'type.', 512: 'This', 513: 'suggests', 514: 'that', 515: 'the', 516: 'probability', 517: 'of', 518: 'life', 519: 'appearing', 520: 'is', 521: 'reasonably', 522: 'high.', 523: 'If', 524: 'it', 525: 'was', 526: 'very', 527: 'low,', 528: 'one', 529: 'would', 530: 'have', 531: 'expected', 532: 'it', 533: 'to', 534: 'take', 535: 'most', 536: 'of', 537: 'the', 538: 'ten', 539: 'billion', 540: 'years', 541: 'available.', 542: 'On', 543: 'the', 544: 'other', 545: 'hand,', 546: 'we', 547: 'don’t', 548: 'seem', 549: 'to', 550: 'have', 551: 'been', 552: 'visited', 553: 'by', 554: 'aliens.', 555: 'I', 556: 'am', 557: 'discounting', 558: 'the', 559: 'reports', 560: 'of', 561: 'UFOs.', 562: 'Why', 563: 'would', 564: 'they', 565: 'appear', 566: 'only', 567: 'to', 568: 'cranks', 569: 'and', 570: 'weirdos?', 571: 'If', 572: 'there', 573: 'is', 574: 'a', 575: 'government', 576: 'conspiracy', 577: 'to', 578: 'suppress', 579: 'the', 580: 'reports', 581: 'and', 582: 'keep', 583: 'for', 584: 'itself', 585: 'the', 586: 'scientific', 587: 'knowledge', 588: 'the', 589: 'aliens', 590: 'bring,', 591: 'it', 592: 'seems', 593: 'to', 594: 'have', 595: 'been', 596: 'a', 597: 'singularly', 598: 'ineffective', 599: 'policy', 600: 'so', 601: 'far.', 602: 'Furthermore,', 603: 'despite', 604: 'an', 605: 'extensive', 606: 'search', 607: 'by', 608: 'the', 609: 'SETI', 610: 'project,', 611: 'we', 612: 'haven’t', 613: 'heard', 614: 'any', 615: 'alien', 616: 'television', 617: 'quiz', 618: 'shows.', 619: 'This', 620: 'probably', 621: 'indicates', 622: 'that', 623: 'there', 624: 'are', 625: 'no', 626: 'alien', 627: 'civilizations', 628: 'at', 629: 'our', 630: 'stage', 631: 'of', 632: 'development', 633: 'within', 634: 'a', 635: 'radius', 636: 'of', 637: 'a', 638: 'few', 639: 'hundred', 640: 'light', 641: 'years.', 642: 'Issuing', 643: 'an', 644: 'insurance', 645: 'policy', 646: 'against', 647: 'abduction', 648: 'by', 649: 'aliens', 650: 'seems', 651: 'a', 652: 'pretty', 653: 'safe', 654: 'bet.', 655: 'This', 656: 'brings', 657: 'me', 658: 'to', 659: 'the', 660: 'last', 661: 'of', 662: 'the', 663: 'big', 664: 'questions:', 665: 'the', 666: 'future', 667: 'of', 668: 'the', 669: 'human', 670: 'race.', 671: 'If', 672: 'we', 673: 'are', 674: 'the', 675: 'only', 676: 'intelligent', 677: 'beings', 678: 'in', 679: 'the', 680: 'galaxy,', 681: 'we', 682: 'should', 683: 'make', 684: 'sure', 685: 'we', 686: 'survive', 687: 'and', 688: 'continue.', 689: 'But', 690: 'we', 691: 'are', 692: 'entering', 693: 'an', 694: 'increasingly', 695: 'dangerous', 696: 'period', 697: 'of', 698: 'our', 699: 'history.', 700: 'Our', 701: 'population', 702: 'and', 703: 'our', 704: 'use', 705: 'of', 706: 'the', 707: 'finite', 708: 'resources', 709: 'of', 710: 'planet', 711: 'Earth', 712: 'are', 713: 'growing', 714: 'exponentially,', 715: 'along', 716: 'with', 717: 'our', 718: 'technical', 719: 'ability', 720: 'to', 721: 'change', 722: 'the', 723: 'environment', 724: 'for', 725: 'good', 726: 'or', 727: 'ill.', 728: 'But', 729: 'our', 730: 'genetic', 731: 'code', 732: 'still', 733: 'carries', 734: 'the', 735: 'selfish', 736: 'and', 737: 'aggressive', 738: 'instincts', 739: 'that', 740: 'were', 741: 'of', 742: 'survival', 743: 'advantage', 744: 'in', 745: 'the', 746: 'past.', 747: 'It', 748: 'will', 749: 'be', 750: 'difficult', 751: 'enough', 752: 'to', 753: 'avoid', 754: 'disaster', 755: 'in', 756: 'the', 757: 'next', 758: 'hundred', 759: 'years,', 760: 'let', 761: 'alone', 762: 'the', 763: 'next', 764: 'thousand', 765: 'or', 766: 'million.', 767: 'Our', 768: 'only', 769: 'chance', 770: 'of', 771: 'long-term', 772: 'survival', 773: 'is', 774: 'not', 775: 'to', 776: 'remain', 777: 'inward-looking', 778: 'on', 779: 'planet', 780: 'Earth,', 781: 'but', 782: 'to', 783: 'spread', 784: 'out', 785: 'into', 786: 'space.', 787: 'The', 788: 'answers', 789: 'to', 790: 'these', 791: 'big', 792: 'questions', 793: 'show', 794: 'that', 795: 'we', 796: 'have', 797: 'made', 798: 'remarkable', 799: 'progress', 800: 'in', 801: 'the', 802: 'last', 803: 'hundred', 804: 'years.', 805: 'But', 806: 'if', 807: 'we', 808: 'want', 809: 'to', 810: 'continue', 811: 'beyond', 812: 'the', 813: 'next', 814: 'hundred', 815: 'years,', 816: 'our', 817: 'future', 818: 'is', 819: 'in', 820: 'space.', 821: 'That', 822: 'is', 823: 'why', 824: 'I', 825: 'am', 826: 'in', 827: 'favor', 828: 'of', 829: 'manned', 830: '–', 831: 'or', 832: 'should', 833: 'I', 834: 'say,', 835: 'personned', 836: '–', 837: 'space', 838: 'flight.', 839: 'All', 840: 'of', 841: 'my', 842: 'life', 843: 'I', 844: 'have', 845: 'sought', 846: 'to', 847: 'understand', 848: 'the', 849: 'universe', 850: 'and', 851: 'find', 852: 'answers', 853: 'to', 854: 'these', 855: 'questions.', 856: 'I', 857: 'have', 858: 'been', 859: 'very', 860: 'lucky', 861: 'that', 862: 'my', 863: 'disability', 864: 'has', 865: 'not', 866: 'been', 867: 'a', 868: 'serious', 869: 'handicap.', 870: 'Indeed,', 871: 'it', 872: 'has', 873: 'probably', 874: 'given', 875: 'me', 876: 'more', 877: 'time', 878: 'than', 879: 'most', 880: 'people', 881: 'to', 882: 'pursue', 883: 'the', 884: 'quest', 885: 'for', 886: 'knowledge.', 887: 'The', 888: 'ultimate', 889: 'goal', 890: 'is', 891: 'a', 892: 'complete', 893: 'theory', 894: 'of', 895: 'the', 896: 'universe,', 897: 'and', 898: 'we', 899: 'are', 900: 'making', 901: 'good', 902: 'progress.', 903: 'Thank', 904: 'you', 905: 'for', 906: 'listening.'}\n"
     ]
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "for word, idx in enumerate(text_as_list):\n",
    "    mydictionary[word] = idx\n",
    "print(mydictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first method only displays each unique word once with the index of its final placement. The second method pairs each index to the specific word, so the whole text is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c902a269",
   "metadata": {},
   "source": [
    "#### Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'There': 1, 'is': 12, 'nothing': 1, 'bigger': 1, 'or': 5, 'older': 1, 'than': 2, 'the': 71, 'universe.': 5, 'The': 6, 'questions': 2, 'I': 7, 'would': 3, 'like': 3, 'to': 22, 'talk': 1, 'about': 4, 'are:': 1, 'one,': 1, 'where': 1, 'did': 3, 'we': 21, 'come': 2, 'from?': 1, 'How': 1, 'universe': 9, 'into': 4, 'being?': 1, 'Are': 1, 'alone': 2, 'in': 14, 'universe?': 3, 'Is': 1, 'there': 8, 'alien': 3, 'life': 9, 'out': 3, 'there?': 1, 'What': 1, 'future': 3, 'of': 39, 'human': 2, 'race?': 1, 'Up': 1, 'until': 2, '1920s,': 1, 'everyone': 2, 'thought': 1, 'was': 10, 'essentially': 1, 'static': 1, 'and': 18, 'unchanging': 1, 'time.': 2, 'Then': 1, 'it': 8, 'discovered': 1, 'that': 11, 'expanding.': 1, 'Distant': 1, 'galaxies': 1, 'were': 3, 'moving': 1, 'away': 1, 'from': 3, 'us.': 1, 'This': 6, 'meant': 1, 'they': 2, 'must': 3, 'have': 14, 'been': 6, 'closer': 1, 'together': 1, 'past.': 2, 'If': 5, 'extrapolate': 1, 'back,': 1, 'find': 2, 'all': 3, 'on': 8, 'top': 1, 'each': 1, 'other': 4, '15': 1, 'billion': 6, 'years': 5, 'ago.': 2, 'Big': 3, 'Bang,': 1, 'beginning': 1, 'But': 6, 'anything': 1, 'before': 1, 'Bang?': 1, 'not,': 1, 'what': 1, 'created': 2, 'Why': 2, 'emerge': 1, 'Bang': 1, 'way': 1, 'did?': 1, 'We': 5, 'used': 1, 'think': 2, 'theory': 3, 'could': 1, 'be': 4, 'divided': 1, 'two': 2, 'parts.': 1, 'First,': 1, 'laws': 4, 'Maxwell’s': 1, 'equations': 1, 'general': 2, 'relativity': 2, 'determined': 1, 'evolution': 4, 'universe,': 2, 'given': 2, 'its': 1, 'state': 2, 'over': 1, 'space': 3, 'at': 2, 'one': 2, 'And': 1, 'second,': 1, 'no': 2, 'question': 1, 'initial': 4, 'made': 2, 'good': 3, 'progress': 2, 'first': 4, 'part,': 1, 'now': 2, 'knowledge': 2, 'but': 2, 'most': 3, 'extreme': 2, 'conditions.': 1, 'recently,': 1, 'had': 1, 'little': 1, 'idea': 1, 'conditions': 2, 'for': 8, 'However,': 1, 'this': 1, 'division': 1, 'depends': 1, 'time': 4, 'being': 2, 'separate': 1, 'distinct.': 1, 'Under': 1, 'conditions,': 1, 'quantum': 1, 'allow': 1, 'behave': 1, 'another': 1, 'dimension': 1, 'space.': 3, 'removes': 1, 'distinction': 1, 'between': 1, 'space,': 1, 'means': 1, 'can': 3, 'also': 1, 'determine': 1, 'state.': 1, 'spontaneously': 2, 'create': 1, 'itself': 2, 'nothing.': 1, 'Moreover,': 1, 'calculate': 1, 'a': 11, 'probability': 3, 'different': 1, 'states.': 1, 'These': 1, 'predictions': 1, 'are': 7, 'excellent': 1, 'agreement': 1, 'with': 2, 'observations': 1, 'by': 4, 'WMAP': 1, 'satellite': 1, 'cosmic': 1, 'microwave': 1, 'background,': 1, 'which': 3, 'an': 4, 'imprint': 1, 'very': 3, 'early': 1, 'solved': 1, 'mystery': 1, 'creation.': 1, 'Maybe': 1, 'should': 3, 'patent': 1, 'charge': 1, 'royalties': 1, 'their': 1, 'existence.': 1, 'turn': 1, 'second': 1, 'big': 3, 'question:': 1, 'alone,': 1, 'believe': 1, 'arose': 1, 'Earth,': 2, 'so': 2, 'possible': 1, 'appear': 2, 'suitable': 1, 'planets,': 1, 'seem': 2, 'large': 1, 'number': 1, 'galaxy.': 1, 'don’t': 2, 'know': 1, 'how': 1, 'appeared.': 1, 'pieces': 1, 'observational': 1, 'evidence': 1, 'appearing.': 1, 'fossils': 1, 'algae': 1, '3.5': 1, 'Earth': 4, 'formed': 1, '4.6': 1, 'ago': 1, 'probably': 3, 'too': 1, 'hot': 1, 'half': 2, 'years.': 3, 'So': 1, 'appeared': 1, 'within': 2, 'possible,': 1, 'short': 1, 'compared': 1, '10-billion-year': 1, 'lifetime': 1, 'planet': 3, 'type.': 1, 'suggests': 1, 'appearing': 1, 'reasonably': 1, 'high.': 1, 'low,': 1, 'expected': 1, 'take': 1, 'ten': 1, 'available.': 1, 'On': 1, 'hand,': 1, 'visited': 1, 'aliens.': 1, 'am': 2, 'discounting': 1, 'reports': 2, 'UFOs.': 1, 'only': 3, 'cranks': 1, 'weirdos?': 1, 'government': 1, 'conspiracy': 1, 'suppress': 1, 'keep': 1, 'scientific': 1, 'aliens': 2, 'bring,': 1, 'seems': 2, 'singularly': 1, 'ineffective': 1, 'policy': 2, 'far.': 1, 'Furthermore,': 1, 'despite': 1, 'extensive': 1, 'search': 1, 'SETI': 1, 'project,': 1, 'haven’t': 1, 'heard': 1, 'any': 1, 'television': 1, 'quiz': 1, 'shows.': 1, 'indicates': 1, 'civilizations': 1, 'our': 6, 'stage': 1, 'development': 1, 'radius': 1, 'few': 1, 'hundred': 4, 'light': 1, 'Issuing': 1, 'insurance': 1, 'against': 1, 'abduction': 1, 'pretty': 1, 'safe': 1, 'bet.': 1, 'brings': 1, 'me': 2, 'last': 2, 'questions:': 1, 'race.': 1, 'intelligent': 1, 'beings': 1, 'galaxy,': 1, 'make': 1, 'sure': 1, 'survive': 1, 'continue.': 1, 'entering': 1, 'increasingly': 1, 'dangerous': 1, 'period': 1, 'history.': 1, 'Our': 2, 'population': 1, 'use': 1, 'finite': 1, 'resources': 1, 'growing': 1, 'exponentially,': 1, 'along': 1, 'technical': 1, 'ability': 1, 'change': 1, 'environment': 1, 'ill.': 1, 'genetic': 1, 'code': 1, 'still': 1, 'carries': 1, 'selfish': 1, 'aggressive': 1, 'instincts': 1, 'survival': 2, 'advantage': 1, 'It': 1, 'will': 1, 'difficult': 1, 'enough': 1, 'avoid': 1, 'disaster': 1, 'next': 3, 'years,': 2, 'let': 1, 'thousand': 1, 'million.': 1, 'chance': 1, 'long-term': 1, 'not': 2, 'remain': 1, 'inward-looking': 1, 'spread': 1, 'answers': 2, 'these': 2, 'show': 1, 'remarkable': 1, 'if': 1, 'want': 1, 'continue': 1, 'beyond': 1, 'That': 1, 'why': 1, 'favor': 1, 'manned': 1, '–': 2, 'say,': 1, 'personned': 1, 'flight.': 1, 'All': 1, 'my': 2, 'sought': 1, 'understand': 1, 'questions.': 1, 'lucky': 1, 'disability': 1, 'has': 2, 'serious': 1, 'handicap.': 1, 'Indeed,': 1, 'more': 1, 'people': 1, 'pursue': 1, 'quest': 1, 'knowledge.': 1, 'ultimate': 1, 'goal': 1, 'complete': 1, 'making': 1, 'progress.': 1, 'Thank': 1, 'you': 1, 'listening.': 1}\n"
     ]
    }
   ],
   "source": [
    "dict_counter = {}\n",
    "for word in text_as_list:\n",
    "    if dict_counter.get(word) != None:\n",
    "        dict_counter[word] = dict_counter[word] + 1\n",
    "    else:\n",
    "        dict_counter[word] = 1\n",
    "print(dict_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbfd1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = text_as_list.count(\"question\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_dict() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmydictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\n",
      "\u001b[0;31mTypeError\u001b[0m: from_dict() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(mydictionary,index=idx)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxies and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fact(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
