{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad882e02",
   "metadata": {},
   "source": [
    "#### Download the latest dataset of Pleiades as in [csv](https://atlantides.org/downloads/pleiades/dumps/pleiades-places-latest.csv.gz), extract the file, and store the csv in the same directory with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ae07f",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "We import pandas and we change three options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9e2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5fe6d7",
   "metadata": {},
   "source": [
    "#### Let's read the Pleades csv file and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d88685",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pleiades-places.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpleiades-places.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pleiades-places.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('pleiades-places.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f60a5",
   "metadata": {},
   "source": [
    "## iloc vs loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915f42b",
   "metadata": {},
   "source": [
    "Run the following to cells. Is there any difference in the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pleiades-places.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e006701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecb49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d308a",
   "metadata": {},
   "source": [
    "The answer is no because in the first case the `iloc` was looking for the $0^{th}$ row while the `loc` was looking for the row that its index has the _label_ 0. In our example, the the result is the same row.\n",
    "\n",
    "Let us read again the csv file but this time we are going to assign an index out of the existing columns and not let Pandas assign its own index. The csv file has a column entitled \"id\" which I will use as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66011979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pleiades-places.csv', index_col='id')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52483b",
   "metadata": {},
   "source": [
    "Run again the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1cd58",
   "metadata": {},
   "source": [
    "As you might expected, the `iloc` will find the $0^{th}$ row. Let us run now the `loc[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ecda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f1c77",
   "metadata": {},
   "source": [
    "You are getting an error message because the `loc` cannot find a row with an index \"0\". Since we changed the indices with Pleiades ids, there is no 0 in the indices. Notice now what is happening if we search for a row that has a Pleiades id as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1080408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[48210385]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2cf37",
   "metadata": {},
   "source": [
    "As you see the `loc` can find a row that has as an index the Pleiades ID we were searching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01bd37",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a73586",
   "metadata": {},
   "source": [
    "## Search in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189f4b4",
   "metadata": {},
   "source": [
    "There are multiple ways that we can query a pandas DataFrame. Let's start by reading the speech of Hawking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hawking-Questioning-the-Universe.txt', 'r') as f:\n",
    "    text_as_list = f.read().split(' ')\n",
    "    \n",
    "# and remove the punctuation    \n",
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b79ed7",
   "metadata": {},
   "source": [
    "Let us create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_counter = {}\n",
    "\n",
    "for i in text_as_list:\n",
    "    dict_counter[i] = text_as_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9c101",
   "metadata": {},
   "source": [
    "and now we will create a DataFrame with the dictionary dict_counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c07ad",
   "metadata": {},
   "source": [
    "before you run the next line, can you predict how many columns does the dataframe have and what is its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d19bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1c023",
   "metadata": {},
   "source": [
    "It is fair to conclude that having 0 and 1 as titles for the dataframe is not very helful. Let us change this. In the DataFrame below, I am making two columns. One with the words and one with their occurances. I name the columns accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'words': dict_counter.keys(), 'occurances': dict_counter.values()})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afaef9b",
   "metadata": {},
   "source": [
    "Notice that we did not write `dict_counter.items()` but I imported two columns, the keys and the values.\n",
    "\n",
    "Now, let's search in the words the item galaxy. What I wrote below is a filter that checks for the word \"galaxy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047541f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] == \"galaxy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca0f2e",
   "metadata": {},
   "source": [
    "Now I will create a new dataframe `df[]` and inside the square brackets I am going to put the filter `df['words'] == \"galaxy\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38185617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['words'] == \"galaxy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336775f",
   "metadata": {},
   "source": [
    "That's great! Yet let's say that I am not interesting in getting a DataFrame but just the occurances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['words'] == \"galaxy\"]['occurances']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9839284a",
   "metadata": {},
   "source": [
    "Let's put all this inside a `int()` in order to present it as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df[df['words'] == \"galaxy\"]['occurances'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84901183",
   "metadata": {},
   "source": [
    "Great! The word galaxy is attested two times!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c5795",
   "metadata": {},
   "source": [
    "Apropos, notice that the two lines below produce the same result. I simply moved the ['occurances'] after the first df:\n",
    "- `df[df['words'] == \"galaxy\"]['occurances']`\n",
    "- `df['occurances'][df['words'] == \"galaxy\"]`\n",
    "\n",
    "The former first makes a dataframe based on a filter and then checks for the columns occurances. The latter first gets the column occurances on which it applies later the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e8d7c",
   "metadata": {},
   "source": [
    "This line of code `int(df[df['words'] == \"galaxy\"]['occurances'])`is efficient but we can query our DataFrame in another way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8e0d0",
   "metadata": {},
   "source": [
    "### Looking for galaxies with `loc[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04dd55",
   "metadata": {},
   "source": [
    "As we saw above, the `loc[]` is looking for an index with the specific parameter. For example the `loc['galaxy']` is searching for the index named \"galaxy\". Yet, before we do that, let us see first what's the index of the DataFrame and how we can change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da98dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374814a2",
   "metadata": {},
   "source": [
    "The index is a number. Let's change that. The line below says make the column words as the index of the DataFrame.\n",
    "\n",
    "Note: if you run this code more than once, you will get an error message. If this is the case create a new cell and run `df.reset_index(inplace=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a93ef3",
   "metadata": {},
   "source": [
    "Yet, run the DataFrame again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc712bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268a6fa",
   "metadata": {},
   "source": [
    "The index changed back to the automatic index of pandas. Or actually, when we tried to make the column words as the index, we did it only temporarily. If we want to change the index permanently, we have to pass the parameter `inplace=True` that changes the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"words\", inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ef3f9",
   "metadata": {},
   "source": [
    "As you see, now no matter how many times you run `df.head(2)` the column \"words\" remains the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172fcf1",
   "metadata": {},
   "source": [
    "Let's return to the original question, how can we find the occurances of \"galaxy\" with `loc`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ae1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['galaxy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace95e3",
   "metadata": {},
   "source": [
    "Let's put that inside an int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df.loc['galaxy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87111ed1",
   "metadata": {},
   "source": [
    "Great! Two galaxies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb0226",
   "metadata": {},
   "source": [
    "Let's reset the index..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b1c9e",
   "metadata": {},
   "source": [
    " and let's see which code is more efficient. Is this better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df[df['words'] == \"galaxy\"]['occurances'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c102b2",
   "metadata": {},
   "source": [
    "or is this better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"words\", inplace=True)\n",
    "int(df.loc['galaxy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f5787",
   "metadata": {},
   "source": [
    "What do you prefer? There is no right or wrong answer here. It's just a matter of preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b2fff",
   "metadata": {},
   "source": [
    "Let's now search for \"galaxy\" or \"galaxies\". I think that the `loc` property is not very efficient in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1474585",
   "metadata": {},
   "source": [
    "First we have to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a013bb",
   "metadata": {},
   "source": [
    "Then let's write clearly our filters.\n",
    "- `df['words'] == \"galaxy\"`\n",
    "- `df['words'] == \"galaxies\"`\n",
    "\n",
    "Since the new dataframe has two filters we have to put them in parentheses with are connected with an OR (`|`). Now let's put it inside a `df[ ]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['words'] == \"galaxy\") | (df['words'] == \"galaxies\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdf9b4",
   "metadata": {},
   "source": [
    "At the end of the above code, I will add a `.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['words'] == \"galaxy\") | (df['words'] == \"galaxies\")].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e560ac9",
   "metadata": {},
   "source": [
    "As you see the `sum()` added the numbers but it concatenated the strings. Since we only need the column \"occurances,\" we have to add `['occurances']`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87215fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['words'] == \"galaxy\") | (df['words'] == \"galaxies\")][\"occurances\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a5b0e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
