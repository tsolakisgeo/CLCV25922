{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Hawking-Questioning-the-Universe.txt\", \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe\n"
     ]
    }
   ],
   "source": [
    "print(text[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The questions I would like to talk about are: one, where did we come from? How did the universe come into bein\n"
     ]
    }
   ],
   "source": [
    "print(text[51:163])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Hawking-Questioning-the-Universe.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "text_as_list = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43917315",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Hawking-Questioning-the-Universe.txt\", \"r\") as file:\n",
    "    text_as_list = file.read().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'are:',\n",
       " 'alone',\n",
       " 'alien',\n",
       " 'and',\n",
       " 'away',\n",
       " 'all',\n",
       " 'about',\n",
       " 'ago.',\n",
       " 'anything',\n",
       " 'and',\n",
       " 'all',\n",
       " 'at',\n",
       " 'and',\n",
       " 'all',\n",
       " 'about',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'allow',\n",
       " 'another',\n",
       " 'and',\n",
       " 'and',\n",
       " 'also',\n",
       " 'a',\n",
       " 'are',\n",
       " 'agreement',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'alone,',\n",
       " 'arose',\n",
       " 'appear',\n",
       " 'a',\n",
       " 'appeared.',\n",
       " 'appearing.',\n",
       " 'algae',\n",
       " 'ago.',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'about',\n",
       " 'appeared',\n",
       " 'a',\n",
       " 'a',\n",
       " 'appearing',\n",
       " 'available.',\n",
       " 'aliens.',\n",
       " 'am',\n",
       " 'appear',\n",
       " 'and',\n",
       " 'a',\n",
       " 'and',\n",
       " 'aliens',\n",
       " 'a',\n",
       " 'an',\n",
       " 'any',\n",
       " 'alien',\n",
       " 'are',\n",
       " 'alien',\n",
       " 'at',\n",
       " 'a',\n",
       " 'a',\n",
       " 'an',\n",
       " 'against',\n",
       " 'abduction',\n",
       " 'aliens',\n",
       " 'a',\n",
       " 'are',\n",
       " 'and',\n",
       " 'are',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'along',\n",
       " 'ability',\n",
       " 'and',\n",
       " 'aggressive',\n",
       " 'advantage',\n",
       " 'avoid',\n",
       " 'alone',\n",
       " 'answers',\n",
       " 'am',\n",
       " 'and',\n",
       " 'answers',\n",
       " 'a',\n",
       " 'a',\n",
       " 'and',\n",
       " 'are']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "for item in text_as_list:\n",
    "    if item.startswith(\"a\"):\n",
    "        words_begin_with_a.append(item)\n",
    "    else:\n",
    "        continue\n",
    "words_begin_with_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter2 = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if not text_as_list[i].startswith('u'):\n",
    "        counter2 += 1\n",
    "    i += 1\n",
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7da6a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does appear\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"universe\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38e92923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist1 = ['universe']\n",
    "# flag = 0\n",
    "# for i in text_as_list:\n",
    "#     for j in checklist1:\n",
    "#         if i==j:\n",
    "#             flag += 1\n",
    "#             break\n",
    "# if flag == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fbeabaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does not appear\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"alliens\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist2 = [\"alliens\"]\n",
    "# flag = 0\n",
    "# for i in text:\n",
    "#     for j in checklist2:\n",
    "#         if i == j:\n",
    "#             flag += 1\n",
    "#             break\n",
    "# if flag == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "469fec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't find the words\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"alliens\")\n",
    "j = text_as_list.count(\"International Space Station\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "elif j > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "903e4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist3 = [\"alliens\", \"International Space Station\"]\n",
    "# flag1 = 0\n",
    "# flag2 = 0\n",
    "# for i in text_as_list:\n",
    "#     for j in checklist3:\n",
    "#         if i == j[0]:\n",
    "#             flag1 += 1\n",
    "#         elif i == j[1]:\n",
    "#             flag2 += 1\n",
    "#             break\n",
    "# if flag1 == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# elif flag2 == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 'there',\n",
       " 2: 'is',\n",
       " 3: 'nothing',\n",
       " 4: 'bigger',\n",
       " 5: 'or',\n",
       " 6: 'older',\n",
       " 7: 'than',\n",
       " 8: 'the',\n",
       " 9: 'universe',\n",
       " 10: 'the',\n",
       " 11: 'questions',\n",
       " 12: 'i',\n",
       " 13: 'would',\n",
       " 14: 'like',\n",
       " 15: 'to',\n",
       " 16: 'talk',\n",
       " 17: 'about',\n",
       " 18: 'are',\n",
       " 19: 'one',\n",
       " 20: 'where',\n",
       " 21: 'did',\n",
       " 22: 'we',\n",
       " 23: 'come',\n",
       " 24: 'from',\n",
       " 25: 'how',\n",
       " 26: 'did',\n",
       " 27: 'the',\n",
       " 28: 'universe',\n",
       " 29: 'come',\n",
       " 30: 'into',\n",
       " 31: 'being',\n",
       " 32: 'are',\n",
       " 33: 'we',\n",
       " 34: 'alone',\n",
       " 35: 'in',\n",
       " 36: 'the',\n",
       " 37: 'universe',\n",
       " 38: 'is',\n",
       " 39: 'there',\n",
       " 40: 'alien',\n",
       " 41: 'life',\n",
       " 42: 'out',\n",
       " 43: 'there',\n",
       " 44: 'what',\n",
       " 45: 'is',\n",
       " 46: 'the',\n",
       " 47: 'future',\n",
       " 48: 'of',\n",
       " 49: 'the',\n",
       " 50: 'human',\n",
       " 51: 'race',\n",
       " 52: 'up',\n",
       " 53: 'until',\n",
       " 54: 'the',\n",
       " 55: '1920s',\n",
       " 56: 'everyone',\n",
       " 57: 'thought',\n",
       " 58: 'the',\n",
       " 59: 'universe',\n",
       " 60: 'was',\n",
       " 61: 'essentially',\n",
       " 62: 'static',\n",
       " 63: 'and',\n",
       " 64: 'unchanging',\n",
       " 65: 'in',\n",
       " 66: 'time',\n",
       " 67: 'then',\n",
       " 68: 'it',\n",
       " 69: 'was',\n",
       " 70: 'discovered',\n",
       " 71: 'that',\n",
       " 72: 'the',\n",
       " 73: 'universe',\n",
       " 74: 'was',\n",
       " 75: 'expanding',\n",
       " 76: 'distant',\n",
       " 77: 'galaxies',\n",
       " 78: 'were',\n",
       " 79: 'moving',\n",
       " 80: 'away',\n",
       " 81: 'from',\n",
       " 82: 'us',\n",
       " 83: 'this',\n",
       " 84: 'meant',\n",
       " 85: 'they',\n",
       " 86: 'must',\n",
       " 87: 'have',\n",
       " 88: 'been',\n",
       " 89: 'closer',\n",
       " 90: 'together',\n",
       " 91: 'in',\n",
       " 92: 'the',\n",
       " 93: 'past',\n",
       " 94: 'if',\n",
       " 95: 'we',\n",
       " 96: 'extrapolate',\n",
       " 97: 'back',\n",
       " 98: 'we',\n",
       " 99: 'find',\n",
       " 100: 'we',\n",
       " 101: 'must',\n",
       " 102: 'have',\n",
       " 103: 'all',\n",
       " 104: 'been',\n",
       " 105: 'on',\n",
       " 106: 'top',\n",
       " 107: 'of',\n",
       " 108: 'each',\n",
       " 109: 'other',\n",
       " 110: 'about',\n",
       " 111: '15',\n",
       " 112: 'billion',\n",
       " 113: 'years',\n",
       " 114: 'ago',\n",
       " 115: 'this',\n",
       " 116: 'was',\n",
       " 117: 'the',\n",
       " 118: 'big',\n",
       " 119: 'bang',\n",
       " 120: 'the',\n",
       " 121: 'beginning',\n",
       " 122: 'of',\n",
       " 123: 'the',\n",
       " 124: 'universe',\n",
       " 125: 'but',\n",
       " 126: 'was',\n",
       " 127: 'there',\n",
       " 128: 'anything',\n",
       " 129: 'before',\n",
       " 130: 'the',\n",
       " 131: 'big',\n",
       " 132: 'bang',\n",
       " 133: 'if',\n",
       " 134: 'not',\n",
       " 135: 'what',\n",
       " 136: 'created',\n",
       " 137: 'the',\n",
       " 138: 'universe',\n",
       " 139: 'why',\n",
       " 140: 'did',\n",
       " 141: 'the',\n",
       " 142: 'universe',\n",
       " 143: 'emerge',\n",
       " 144: 'from',\n",
       " 145: 'the',\n",
       " 146: 'big',\n",
       " 147: 'bang',\n",
       " 148: 'the',\n",
       " 149: 'way',\n",
       " 150: 'it',\n",
       " 151: 'did',\n",
       " 152: 'we',\n",
       " 153: 'used',\n",
       " 154: 'to',\n",
       " 155: 'think',\n",
       " 156: 'that',\n",
       " 157: 'the',\n",
       " 158: 'theory',\n",
       " 159: 'of',\n",
       " 160: 'the',\n",
       " 161: 'universe',\n",
       " 162: 'could',\n",
       " 163: 'be',\n",
       " 164: 'divided',\n",
       " 165: 'into',\n",
       " 166: 'two',\n",
       " 167: 'parts',\n",
       " 168: 'first',\n",
       " 169: 'there',\n",
       " 170: 'were',\n",
       " 171: 'the',\n",
       " 172: 'laws',\n",
       " 173: 'like',\n",
       " 174: 'maxwell’s',\n",
       " 175: 'equations',\n",
       " 176: 'and',\n",
       " 177: 'general',\n",
       " 178: 'relativity',\n",
       " 179: 'that',\n",
       " 180: 'determined',\n",
       " 181: 'the',\n",
       " 182: 'evolution',\n",
       " 183: 'of',\n",
       " 184: 'the',\n",
       " 185: 'universe',\n",
       " 186: 'given',\n",
       " 187: 'its',\n",
       " 188: 'state',\n",
       " 189: 'over',\n",
       " 190: 'all',\n",
       " 191: 'of',\n",
       " 192: 'space',\n",
       " 193: 'at',\n",
       " 194: 'one',\n",
       " 195: 'time',\n",
       " 196: 'and',\n",
       " 197: 'second',\n",
       " 198: 'there',\n",
       " 199: 'was',\n",
       " 200: 'no',\n",
       " 201: 'question',\n",
       " 202: 'of',\n",
       " 203: 'the',\n",
       " 204: 'initial',\n",
       " 205: 'state',\n",
       " 206: 'of',\n",
       " 207: 'the',\n",
       " 208: 'universe',\n",
       " 209: 'we',\n",
       " 210: 'have',\n",
       " 211: 'made',\n",
       " 212: 'good',\n",
       " 213: 'progress',\n",
       " 214: 'on',\n",
       " 215: 'the',\n",
       " 216: 'first',\n",
       " 217: 'part',\n",
       " 218: 'and',\n",
       " 219: 'now',\n",
       " 220: 'have',\n",
       " 221: 'the',\n",
       " 222: 'knowledge',\n",
       " 223: 'of',\n",
       " 224: 'the',\n",
       " 225: 'laws',\n",
       " 226: 'of',\n",
       " 227: 'evolution',\n",
       " 228: 'in',\n",
       " 229: 'all',\n",
       " 230: 'but',\n",
       " 231: 'the',\n",
       " 232: 'most',\n",
       " 233: 'extreme',\n",
       " 234: 'conditions',\n",
       " 235: 'but',\n",
       " 236: 'until',\n",
       " 237: 'recently',\n",
       " 238: 'we',\n",
       " 239: 'have',\n",
       " 240: 'had',\n",
       " 241: 'little',\n",
       " 242: 'idea',\n",
       " 243: 'about',\n",
       " 244: 'the',\n",
       " 245: 'initial',\n",
       " 246: 'conditions',\n",
       " 247: 'for',\n",
       " 248: 'the',\n",
       " 249: 'universe',\n",
       " 250: 'however',\n",
       " 251: 'this',\n",
       " 252: 'division',\n",
       " 253: 'into',\n",
       " 254: 'laws',\n",
       " 255: 'of',\n",
       " 256: 'evolution',\n",
       " 257: 'and',\n",
       " 258: 'initial',\n",
       " 259: 'conditions',\n",
       " 260: 'depends',\n",
       " 261: 'on',\n",
       " 262: 'time',\n",
       " 263: 'and',\n",
       " 264: 'space',\n",
       " 265: 'being',\n",
       " 266: 'separate',\n",
       " 267: 'and',\n",
       " 268: 'distinct',\n",
       " 269: 'under',\n",
       " 270: 'extreme',\n",
       " 271: 'conditions',\n",
       " 272: 'general',\n",
       " 273: 'relativity',\n",
       " 274: 'and',\n",
       " 275: 'quantum',\n",
       " 276: 'theory',\n",
       " 277: 'allow',\n",
       " 278: 'time',\n",
       " 279: 'to',\n",
       " 280: 'behave',\n",
       " 281: 'like',\n",
       " 282: 'another',\n",
       " 283: 'dimension',\n",
       " 284: 'of',\n",
       " 285: 'space',\n",
       " 286: 'this',\n",
       " 287: 'removes',\n",
       " 288: 'the',\n",
       " 289: 'distinction',\n",
       " 290: 'between',\n",
       " 291: 'time',\n",
       " 292: 'and',\n",
       " 293: 'space',\n",
       " 294: 'and',\n",
       " 295: 'means',\n",
       " 296: 'the',\n",
       " 297: 'laws',\n",
       " 298: 'of',\n",
       " 299: 'evolution',\n",
       " 300: 'can',\n",
       " 301: 'also',\n",
       " 302: 'determine',\n",
       " 303: 'the',\n",
       " 304: 'initial',\n",
       " 305: 'state',\n",
       " 306: 'the',\n",
       " 307: 'universe',\n",
       " 308: 'can',\n",
       " 309: 'spontaneously',\n",
       " 310: 'create',\n",
       " 311: 'itself',\n",
       " 312: 'out',\n",
       " 313: 'of',\n",
       " 314: 'nothing',\n",
       " 315: 'moreover',\n",
       " 316: 'we',\n",
       " 317: 'can',\n",
       " 318: 'calculate',\n",
       " 319: 'a',\n",
       " 320: 'probability',\n",
       " 321: 'that',\n",
       " 322: 'the',\n",
       " 323: 'universe',\n",
       " 324: 'was',\n",
       " 325: 'created',\n",
       " 326: 'in',\n",
       " 327: 'different',\n",
       " 328: 'states',\n",
       " 329: 'these',\n",
       " 330: 'predictions',\n",
       " 331: 'are',\n",
       " 332: 'in',\n",
       " 333: 'excellent',\n",
       " 334: 'agreement',\n",
       " 335: 'with',\n",
       " 336: 'observations',\n",
       " 337: 'by',\n",
       " 338: 'the',\n",
       " 339: 'wmap',\n",
       " 340: 'satellite',\n",
       " 341: 'of',\n",
       " 342: 'the',\n",
       " 343: 'cosmic',\n",
       " 344: 'microwave',\n",
       " 345: 'background',\n",
       " 346: 'which',\n",
       " 347: 'is',\n",
       " 348: 'an',\n",
       " 349: 'imprint',\n",
       " 350: 'of',\n",
       " 351: 'the',\n",
       " 352: 'very',\n",
       " 353: 'early',\n",
       " 354: 'universe',\n",
       " 355: 'we',\n",
       " 356: 'think',\n",
       " 357: 'we',\n",
       " 358: 'have',\n",
       " 359: 'solved',\n",
       " 360: 'the',\n",
       " 361: 'mystery',\n",
       " 362: 'of',\n",
       " 363: 'creation',\n",
       " 364: 'maybe',\n",
       " 365: 'we',\n",
       " 366: 'should',\n",
       " 367: 'patent',\n",
       " 368: 'the',\n",
       " 369: 'universe',\n",
       " 370: 'and',\n",
       " 371: 'charge',\n",
       " 372: 'everyone',\n",
       " 373: 'royalties',\n",
       " 374: 'for',\n",
       " 375: 'their',\n",
       " 376: 'existence',\n",
       " 377: 'i',\n",
       " 378: 'now',\n",
       " 379: 'turn',\n",
       " 380: 'to',\n",
       " 381: 'the',\n",
       " 382: 'second',\n",
       " 383: 'big',\n",
       " 384: 'question',\n",
       " 385: 'are',\n",
       " 386: 'we',\n",
       " 387: 'alone',\n",
       " 388: 'or',\n",
       " 389: 'is',\n",
       " 390: 'there',\n",
       " 391: 'other',\n",
       " 392: 'life',\n",
       " 393: 'in',\n",
       " 394: 'the',\n",
       " 395: 'universe',\n",
       " 396: 'we',\n",
       " 397: 'believe',\n",
       " 398: 'that',\n",
       " 399: 'life',\n",
       " 400: 'arose',\n",
       " 401: 'spontaneously',\n",
       " 402: 'on',\n",
       " 403: 'the',\n",
       " 404: 'earth',\n",
       " 405: 'so',\n",
       " 406: 'it',\n",
       " 407: 'must',\n",
       " 408: 'be',\n",
       " 409: 'possible',\n",
       " 410: 'for',\n",
       " 411: 'life',\n",
       " 412: 'to',\n",
       " 413: 'appear',\n",
       " 414: 'on',\n",
       " 415: 'other',\n",
       " 416: 'suitable',\n",
       " 417: 'planets',\n",
       " 418: 'of',\n",
       " 419: 'which',\n",
       " 420: 'there',\n",
       " 421: 'seem',\n",
       " 422: 'to',\n",
       " 423: 'be',\n",
       " 424: 'a',\n",
       " 425: 'large',\n",
       " 426: 'number',\n",
       " 427: 'in',\n",
       " 428: 'the',\n",
       " 429: 'galaxy',\n",
       " 430: 'but',\n",
       " 431: 'we',\n",
       " 432: 'don’t',\n",
       " 433: 'know',\n",
       " 434: 'how',\n",
       " 435: 'life',\n",
       " 436: 'first',\n",
       " 437: 'appeared',\n",
       " 438: 'we',\n",
       " 439: 'have',\n",
       " 440: 'two',\n",
       " 441: 'pieces',\n",
       " 442: 'of',\n",
       " 443: 'observational',\n",
       " 444: 'evidence',\n",
       " 445: 'on',\n",
       " 446: 'the',\n",
       " 447: 'probability',\n",
       " 448: 'of',\n",
       " 449: 'life',\n",
       " 450: 'appearing',\n",
       " 451: 'the',\n",
       " 452: 'first',\n",
       " 453: 'is',\n",
       " 454: 'that',\n",
       " 455: 'we',\n",
       " 456: 'have',\n",
       " 457: 'fossils',\n",
       " 458: 'of',\n",
       " 459: 'algae',\n",
       " 460: 'from',\n",
       " 461: '35',\n",
       " 462: 'billion',\n",
       " 463: 'years',\n",
       " 464: 'ago',\n",
       " 465: 'the',\n",
       " 466: 'earth',\n",
       " 467: 'was',\n",
       " 468: 'formed',\n",
       " 469: '46',\n",
       " 470: 'billion',\n",
       " 471: 'years',\n",
       " 472: 'ago',\n",
       " 473: 'and',\n",
       " 474: 'was',\n",
       " 475: 'probably',\n",
       " 476: 'too',\n",
       " 477: 'hot',\n",
       " 478: 'for',\n",
       " 479: 'about',\n",
       " 480: 'the',\n",
       " 481: 'first',\n",
       " 482: 'half',\n",
       " 483: 'billion',\n",
       " 484: 'years',\n",
       " 485: 'so',\n",
       " 486: 'life',\n",
       " 487: 'appeared',\n",
       " 488: 'on',\n",
       " 489: 'earth',\n",
       " 490: 'within',\n",
       " 491: 'half',\n",
       " 492: 'a',\n",
       " 493: 'billion',\n",
       " 494: 'years',\n",
       " 495: 'of',\n",
       " 496: 'it',\n",
       " 497: 'being',\n",
       " 498: 'possible',\n",
       " 499: 'which',\n",
       " 500: 'is',\n",
       " 501: 'short',\n",
       " 502: 'compared',\n",
       " 503: 'to',\n",
       " 504: 'the',\n",
       " 505: '10billionyear',\n",
       " 506: 'lifetime',\n",
       " 507: 'of',\n",
       " 508: 'a',\n",
       " 509: 'planet',\n",
       " 510: 'of',\n",
       " 511: 'earth',\n",
       " 512: 'type',\n",
       " 513: 'this',\n",
       " 514: 'suggests',\n",
       " 515: 'that',\n",
       " 516: 'the',\n",
       " 517: 'probability',\n",
       " 518: 'of',\n",
       " 519: 'life',\n",
       " 520: 'appearing',\n",
       " 521: 'is',\n",
       " 522: 'reasonably',\n",
       " 523: 'high',\n",
       " 524: 'if',\n",
       " 525: 'it',\n",
       " 526: 'was',\n",
       " 527: 'very',\n",
       " 528: 'low',\n",
       " 529: 'one',\n",
       " 530: 'would',\n",
       " 531: 'have',\n",
       " 532: 'expected',\n",
       " 533: 'it',\n",
       " 534: 'to',\n",
       " 535: 'take',\n",
       " 536: 'most',\n",
       " 537: 'of',\n",
       " 538: 'the',\n",
       " 539: 'ten',\n",
       " 540: 'billion',\n",
       " 541: 'years',\n",
       " 542: 'available',\n",
       " 543: 'on',\n",
       " 544: 'the',\n",
       " 545: 'other',\n",
       " 546: 'hand',\n",
       " 547: 'we',\n",
       " 548: 'don’t',\n",
       " 549: 'seem',\n",
       " 550: 'to',\n",
       " 551: 'have',\n",
       " 552: 'been',\n",
       " 553: 'visited',\n",
       " 554: 'by',\n",
       " 555: 'aliens',\n",
       " 556: 'i',\n",
       " 557: 'am',\n",
       " 558: 'discounting',\n",
       " 559: 'the',\n",
       " 560: 'reports',\n",
       " 561: 'of',\n",
       " 562: 'ufos',\n",
       " 563: 'why',\n",
       " 564: 'would',\n",
       " 565: 'they',\n",
       " 566: 'appear',\n",
       " 567: 'only',\n",
       " 568: 'to',\n",
       " 569: 'cranks',\n",
       " 570: 'and',\n",
       " 571: 'weirdos',\n",
       " 572: 'if',\n",
       " 573: 'there',\n",
       " 574: 'is',\n",
       " 575: 'a',\n",
       " 576: 'government',\n",
       " 577: 'conspiracy',\n",
       " 578: 'to',\n",
       " 579: 'suppress',\n",
       " 580: 'the',\n",
       " 581: 'reports',\n",
       " 582: 'and',\n",
       " 583: 'keep',\n",
       " 584: 'for',\n",
       " 585: 'itself',\n",
       " 586: 'the',\n",
       " 587: 'scientific',\n",
       " 588: 'knowledge',\n",
       " 589: 'the',\n",
       " 590: 'aliens',\n",
       " 591: 'bring',\n",
       " 592: 'it',\n",
       " 593: 'seems',\n",
       " 594: 'to',\n",
       " 595: 'have',\n",
       " 596: 'been',\n",
       " 597: 'a',\n",
       " 598: 'singularly',\n",
       " 599: 'ineffective',\n",
       " 600: 'policy',\n",
       " 601: 'so',\n",
       " 602: 'far',\n",
       " 603: 'furthermore',\n",
       " 604: 'despite',\n",
       " 605: 'an',\n",
       " 606: 'extensive',\n",
       " 607: 'search',\n",
       " 608: 'by',\n",
       " 609: 'the',\n",
       " 610: 'seti',\n",
       " 611: 'project',\n",
       " 612: 'we',\n",
       " 613: 'haven’t',\n",
       " 614: 'heard',\n",
       " 615: 'any',\n",
       " 616: 'alien',\n",
       " 617: 'television',\n",
       " 618: 'quiz',\n",
       " 619: 'shows',\n",
       " 620: 'this',\n",
       " 621: 'probably',\n",
       " 622: 'indicates',\n",
       " 623: 'that',\n",
       " 624: 'there',\n",
       " 625: 'are',\n",
       " 626: 'no',\n",
       " 627: 'alien',\n",
       " 628: 'civilizations',\n",
       " 629: 'at',\n",
       " 630: 'our',\n",
       " 631: 'stage',\n",
       " 632: 'of',\n",
       " 633: 'development',\n",
       " 634: 'within',\n",
       " 635: 'a',\n",
       " 636: 'radius',\n",
       " 637: 'of',\n",
       " 638: 'a',\n",
       " 639: 'few',\n",
       " 640: 'hundred',\n",
       " 641: 'light',\n",
       " 642: 'years',\n",
       " 643: 'issuing',\n",
       " 644: 'an',\n",
       " 645: 'insurance',\n",
       " 646: 'policy',\n",
       " 647: 'against',\n",
       " 648: 'abduction',\n",
       " 649: 'by',\n",
       " 650: 'aliens',\n",
       " 651: 'seems',\n",
       " 652: 'a',\n",
       " 653: 'pretty',\n",
       " 654: 'safe',\n",
       " 655: 'bet',\n",
       " 656: 'this',\n",
       " 657: 'brings',\n",
       " 658: 'me',\n",
       " 659: 'to',\n",
       " 660: 'the',\n",
       " 661: 'last',\n",
       " 662: 'of',\n",
       " 663: 'the',\n",
       " 664: 'big',\n",
       " 665: 'questions',\n",
       " 666: 'the',\n",
       " 667: 'future',\n",
       " 668: 'of',\n",
       " 669: 'the',\n",
       " 670: 'human',\n",
       " 671: 'race',\n",
       " 672: 'if',\n",
       " 673: 'we',\n",
       " 674: 'are',\n",
       " 675: 'the',\n",
       " 676: 'only',\n",
       " 677: 'intelligent',\n",
       " 678: 'beings',\n",
       " 679: 'in',\n",
       " 680: 'the',\n",
       " 681: 'galaxy',\n",
       " 682: 'we',\n",
       " 683: 'should',\n",
       " 684: 'make',\n",
       " 685: 'sure',\n",
       " 686: 'we',\n",
       " 687: 'survive',\n",
       " 688: 'and',\n",
       " 689: 'continue',\n",
       " 690: 'but',\n",
       " 691: 'we',\n",
       " 692: 'are',\n",
       " 693: 'entering',\n",
       " 694: 'an',\n",
       " 695: 'increasingly',\n",
       " 696: 'dangerous',\n",
       " 697: 'period',\n",
       " 698: 'of',\n",
       " 699: 'our',\n",
       " 700: 'history',\n",
       " 701: 'our',\n",
       " 702: 'population',\n",
       " 703: 'and',\n",
       " 704: 'our',\n",
       " 705: 'use',\n",
       " 706: 'of',\n",
       " 707: 'the',\n",
       " 708: 'finite',\n",
       " 709: 'resources',\n",
       " 710: 'of',\n",
       " 711: 'planet',\n",
       " 712: 'earth',\n",
       " 713: 'are',\n",
       " 714: 'growing',\n",
       " 715: 'exponentially',\n",
       " 716: 'along',\n",
       " 717: 'with',\n",
       " 718: 'our',\n",
       " 719: 'technical',\n",
       " 720: 'ability',\n",
       " 721: 'to',\n",
       " 722: 'change',\n",
       " 723: 'the',\n",
       " 724: 'environment',\n",
       " 725: 'for',\n",
       " 726: 'good',\n",
       " 727: 'or',\n",
       " 728: 'ill',\n",
       " 729: 'but',\n",
       " 730: 'our',\n",
       " 731: 'genetic',\n",
       " 732: 'code',\n",
       " 733: 'still',\n",
       " 734: 'carries',\n",
       " 735: 'the',\n",
       " 736: 'selfish',\n",
       " 737: 'and',\n",
       " 738: 'aggressive',\n",
       " 739: 'instincts',\n",
       " 740: 'that',\n",
       " 741: 'were',\n",
       " 742: 'of',\n",
       " 743: 'survival',\n",
       " 744: 'advantage',\n",
       " 745: 'in',\n",
       " 746: 'the',\n",
       " 747: 'past',\n",
       " 748: 'it',\n",
       " 749: 'will',\n",
       " 750: 'be',\n",
       " 751: 'difficult',\n",
       " 752: 'enough',\n",
       " 753: 'to',\n",
       " 754: 'avoid',\n",
       " 755: 'disaster',\n",
       " 756: 'in',\n",
       " 757: 'the',\n",
       " 758: 'next',\n",
       " 759: 'hundred',\n",
       " 760: 'years',\n",
       " 761: 'let',\n",
       " 762: 'alone',\n",
       " 763: 'the',\n",
       " 764: 'next',\n",
       " 765: 'thousand',\n",
       " 766: 'or',\n",
       " 767: 'million',\n",
       " 768: 'our',\n",
       " 769: 'only',\n",
       " 770: 'chance',\n",
       " 771: 'of',\n",
       " 772: 'longterm',\n",
       " 773: 'survival',\n",
       " 774: 'is',\n",
       " 775: 'not',\n",
       " 776: 'to',\n",
       " 777: 'remain',\n",
       " 778: 'inwardlooking',\n",
       " 779: 'on',\n",
       " 780: 'planet',\n",
       " 781: 'earth',\n",
       " 782: 'but',\n",
       " 783: 'to',\n",
       " 784: 'spread',\n",
       " 785: 'out',\n",
       " 786: 'into',\n",
       " 787: 'space',\n",
       " 788: 'the',\n",
       " 789: 'answers',\n",
       " 790: 'to',\n",
       " 791: 'these',\n",
       " 792: 'big',\n",
       " 793: 'questions',\n",
       " 794: 'show',\n",
       " 795: 'that',\n",
       " 796: 'we',\n",
       " 797: 'have',\n",
       " 798: 'made',\n",
       " 799: 'remarkable',\n",
       " 800: 'progress',\n",
       " 801: 'in',\n",
       " 802: 'the',\n",
       " 803: 'last',\n",
       " 804: 'hundred',\n",
       " 805: 'years',\n",
       " 806: 'but',\n",
       " 807: 'if',\n",
       " 808: 'we',\n",
       " 809: 'want',\n",
       " 810: 'to',\n",
       " 811: 'continue',\n",
       " 812: 'beyond',\n",
       " 813: 'the',\n",
       " 814: 'next',\n",
       " 815: 'hundred',\n",
       " 816: 'years',\n",
       " 817: 'our',\n",
       " 818: 'future',\n",
       " 819: 'is',\n",
       " 820: 'in',\n",
       " 821: 'space',\n",
       " 822: 'that',\n",
       " 823: 'is',\n",
       " 824: 'why',\n",
       " 825: 'i',\n",
       " 826: 'am',\n",
       " 827: 'in',\n",
       " 828: 'favor',\n",
       " 829: 'of',\n",
       " 830: 'manned',\n",
       " 831: '–',\n",
       " 832: 'or',\n",
       " 833: 'should',\n",
       " 834: 'i',\n",
       " 835: 'say',\n",
       " 836: 'personned',\n",
       " 837: '–',\n",
       " 838: 'space',\n",
       " 839: 'flight',\n",
       " 840: 'all',\n",
       " 841: 'of',\n",
       " 842: 'my',\n",
       " 843: 'life',\n",
       " 844: 'i',\n",
       " 845: 'have',\n",
       " 846: 'sought',\n",
       " 847: 'to',\n",
       " 848: 'understand',\n",
       " 849: 'the',\n",
       " 850: 'universe',\n",
       " 851: 'and',\n",
       " 852: 'find',\n",
       " 853: 'answers',\n",
       " 854: 'to',\n",
       " 855: 'these',\n",
       " 856: 'questions',\n",
       " 857: 'i',\n",
       " 858: 'have',\n",
       " 859: 'been',\n",
       " 860: 'very',\n",
       " 861: 'lucky',\n",
       " 862: 'that',\n",
       " 863: 'my',\n",
       " 864: 'disability',\n",
       " 865: 'has',\n",
       " 866: 'not',\n",
       " 867: 'been',\n",
       " 868: 'a',\n",
       " 869: 'serious',\n",
       " 870: 'handicap',\n",
       " 871: 'indeed',\n",
       " 872: 'it',\n",
       " 873: 'has',\n",
       " 874: 'probably',\n",
       " 875: 'given',\n",
       " 876: 'me',\n",
       " 877: 'more',\n",
       " 878: 'time',\n",
       " 879: 'than',\n",
       " 880: 'most',\n",
       " 881: 'people',\n",
       " 882: 'to',\n",
       " 883: 'pursue',\n",
       " 884: 'the',\n",
       " 885: 'quest',\n",
       " 886: 'for',\n",
       " 887: 'knowledge',\n",
       " 888: 'the',\n",
       " 889: 'ultimate',\n",
       " 890: 'goal',\n",
       " 891: 'is',\n",
       " 892: 'a',\n",
       " 893: 'complete',\n",
       " 894: 'theory',\n",
       " 895: 'of',\n",
       " 896: 'the',\n",
       " 897: 'universe',\n",
       " 898: 'and',\n",
       " 899: 'we',\n",
       " 900: 'are',\n",
       " 901: 'making',\n",
       " 902: 'good',\n",
       " 903: 'progress',\n",
       " 904: 'thank',\n",
       " 905: 'you',\n",
       " 906: 'for',\n",
       " 907: 'listening'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "def my_enumerate(sequence, start=1):\n",
    "    n = start\n",
    "    for elem in sequence:\n",
    "        yield n, elem\n",
    "        n += 1\n",
    "my_enumerate(text_as_list)\n",
    "mydictionary = dict(my_enumerate(text_as_list))\n",
    "print(len(mydictionary))\n",
    "mydictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e08b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'There': 0,\n",
       " 'is': 890,\n",
       " 'nothing': 2,\n",
       " 'bigger': 3,\n",
       " 'or': 831,\n",
       " 'older': 5,\n",
       " 'than': 878,\n",
       " 'the': 895,\n",
       " 'universe.': 353,\n",
       " 'The': 887,\n",
       " 'questions': 792,\n",
       " 'I': 856,\n",
       " 'would': 563,\n",
       " 'like': 280,\n",
       " 'to': 881,\n",
       " 'talk': 15,\n",
       " 'about': 478,\n",
       " 'are:': 17,\n",
       " 'one,': 18,\n",
       " 'where': 19,\n",
       " 'did': 139,\n",
       " 'we': 898,\n",
       " 'come': 28,\n",
       " 'from?': 23,\n",
       " 'How': 24,\n",
       " 'universe': 849,\n",
       " 'into': 785,\n",
       " 'being?': 30,\n",
       " 'Are': 31,\n",
       " 'alone': 761,\n",
       " 'in': 826,\n",
       " 'universe?': 394,\n",
       " 'Is': 37,\n",
       " 'there': 623,\n",
       " 'alien': 626,\n",
       " 'life': 842,\n",
       " 'out': 784,\n",
       " 'there?': 42,\n",
       " 'What': 43,\n",
       " 'future': 817,\n",
       " 'of': 894,\n",
       " 'human': 669,\n",
       " 'race?': 50,\n",
       " 'Up': 51,\n",
       " 'until': 235,\n",
       " '1920s,': 54,\n",
       " 'everyone': 371,\n",
       " 'thought': 56,\n",
       " 'was': 525,\n",
       " 'essentially': 60,\n",
       " 'static': 61,\n",
       " 'and': 897,\n",
       " 'unchanging': 63,\n",
       " 'time.': 194,\n",
       " 'Then': 66,\n",
       " 'it': 871,\n",
       " 'discovered': 69,\n",
       " 'that': 861,\n",
       " 'expanding.': 74,\n",
       " 'Distant': 75,\n",
       " 'galaxies': 76,\n",
       " 'were': 740,\n",
       " 'moving': 78,\n",
       " 'away': 79,\n",
       " 'from': 459,\n",
       " 'us.': 81,\n",
       " 'This': 655,\n",
       " 'meant': 83,\n",
       " 'they': 564,\n",
       " 'must': 406,\n",
       " 'have': 857,\n",
       " 'been': 866,\n",
       " 'closer': 88,\n",
       " 'together': 89,\n",
       " 'past.': 746,\n",
       " 'If': 671,\n",
       " 'extrapolate': 95,\n",
       " 'back,': 96,\n",
       " 'find': 851,\n",
       " 'all': 228,\n",
       " 'on': 778,\n",
       " 'top': 105,\n",
       " 'each': 107,\n",
       " 'other': 544,\n",
       " '15': 110,\n",
       " 'billion': 539,\n",
       " 'years': 540,\n",
       " 'ago.': 463,\n",
       " 'Big': 145,\n",
       " 'Bang,': 118,\n",
       " 'beginning': 120,\n",
       " 'But': 805,\n",
       " 'anything': 127,\n",
       " 'before': 128,\n",
       " 'Bang?': 131,\n",
       " 'not,': 133,\n",
       " 'what': 134,\n",
       " 'created': 324,\n",
       " 'Why': 562,\n",
       " 'emerge': 142,\n",
       " 'Bang': 146,\n",
       " 'way': 148,\n",
       " 'did?': 150,\n",
       " 'We': 437,\n",
       " 'used': 152,\n",
       " 'think': 355,\n",
       " 'theory': 893,\n",
       " 'could': 161,\n",
       " 'be': 749,\n",
       " 'divided': 163,\n",
       " 'two': 439,\n",
       " 'parts.': 166,\n",
       " 'First,': 167,\n",
       " 'laws': 296,\n",
       " 'Maxwell’s': 173,\n",
       " 'equations': 174,\n",
       " 'general': 271,\n",
       " 'relativity': 272,\n",
       " 'determined': 179,\n",
       " 'evolution': 298,\n",
       " 'universe,': 896,\n",
       " 'given': 874,\n",
       " 'its': 186,\n",
       " 'state': 204,\n",
       " 'over': 188,\n",
       " 'space': 837,\n",
       " 'at': 628,\n",
       " 'one': 528,\n",
       " 'And': 195,\n",
       " 'second,': 196,\n",
       " 'no': 625,\n",
       " 'question': 200,\n",
       " 'initial': 303,\n",
       " 'made': 797,\n",
       " 'good': 901,\n",
       " 'progress': 799,\n",
       " 'first': 480,\n",
       " 'part,': 216,\n",
       " 'now': 377,\n",
       " 'knowledge': 587,\n",
       " 'but': 781,\n",
       " 'most': 879,\n",
       " 'extreme': 269,\n",
       " 'conditions.': 233,\n",
       " 'recently,': 236,\n",
       " 'had': 239,\n",
       " 'little': 240,\n",
       " 'idea': 241,\n",
       " 'conditions': 258,\n",
       " 'for': 905,\n",
       " 'However,': 249,\n",
       " 'this': 250,\n",
       " 'division': 251,\n",
       " 'depends': 259,\n",
       " 'time': 877,\n",
       " 'being': 496,\n",
       " 'separate': 265,\n",
       " 'distinct.': 267,\n",
       " 'Under': 268,\n",
       " 'conditions,': 270,\n",
       " 'quantum': 274,\n",
       " 'allow': 276,\n",
       " 'behave': 279,\n",
       " 'another': 281,\n",
       " 'dimension': 282,\n",
       " 'space.': 820,\n",
       " 'removes': 286,\n",
       " 'distinction': 288,\n",
       " 'between': 289,\n",
       " 'space,': 292,\n",
       " 'means': 294,\n",
       " 'can': 316,\n",
       " 'also': 300,\n",
       " 'determine': 301,\n",
       " 'state.': 304,\n",
       " 'spontaneously': 400,\n",
       " 'create': 309,\n",
       " 'itself': 584,\n",
       " 'nothing.': 313,\n",
       " 'Moreover,': 314,\n",
       " 'calculate': 317,\n",
       " 'a': 891,\n",
       " 'probability': 516,\n",
       " 'different': 326,\n",
       " 'states.': 327,\n",
       " 'These': 328,\n",
       " 'predictions': 329,\n",
       " 'are': 899,\n",
       " 'excellent': 332,\n",
       " 'agreement': 333,\n",
       " 'with': 716,\n",
       " 'observations': 335,\n",
       " 'by': 648,\n",
       " 'WMAP': 338,\n",
       " 'satellite': 339,\n",
       " 'cosmic': 342,\n",
       " 'microwave': 343,\n",
       " 'background,': 344,\n",
       " 'which': 498,\n",
       " 'an': 693,\n",
       " 'imprint': 348,\n",
       " 'very': 859,\n",
       " 'early': 352,\n",
       " 'solved': 358,\n",
       " 'mystery': 360,\n",
       " 'creation.': 362,\n",
       " 'Maybe': 363,\n",
       " 'should': 832,\n",
       " 'patent': 366,\n",
       " 'charge': 370,\n",
       " 'royalties': 372,\n",
       " 'their': 374,\n",
       " 'existence.': 375,\n",
       " 'turn': 378,\n",
       " 'second': 381,\n",
       " 'big': 791,\n",
       " 'question:': 383,\n",
       " 'alone,': 386,\n",
       " 'believe': 396,\n",
       " 'arose': 399,\n",
       " 'Earth,': 780,\n",
       " 'so': 600,\n",
       " 'possible': 408,\n",
       " 'appear': 565,\n",
       " 'suitable': 415,\n",
       " 'planets,': 416,\n",
       " 'seem': 548,\n",
       " 'large': 424,\n",
       " 'number': 425,\n",
       " 'galaxy.': 428,\n",
       " 'don’t': 547,\n",
       " 'know': 432,\n",
       " 'how': 433,\n",
       " 'appeared.': 436,\n",
       " 'pieces': 440,\n",
       " 'observational': 442,\n",
       " 'evidence': 443,\n",
       " 'appearing.': 449,\n",
       " 'fossils': 456,\n",
       " 'algae': 458,\n",
       " '3.5': 460,\n",
       " 'Earth': 711,\n",
       " 'formed': 467,\n",
       " '4.6': 468,\n",
       " 'ago': 471,\n",
       " 'probably': 873,\n",
       " 'too': 475,\n",
       " 'hot': 476,\n",
       " 'half': 490,\n",
       " 'years.': 804,\n",
       " 'So': 484,\n",
       " 'appeared': 486,\n",
       " 'within': 633,\n",
       " 'possible,': 497,\n",
       " 'short': 500,\n",
       " 'compared': 501,\n",
       " '10-billion-year': 504,\n",
       " 'lifetime': 505,\n",
       " 'planet': 779,\n",
       " 'type.': 511,\n",
       " 'suggests': 513,\n",
       " 'appearing': 519,\n",
       " 'reasonably': 521,\n",
       " 'high.': 522,\n",
       " 'low,': 527,\n",
       " 'expected': 531,\n",
       " 'take': 534,\n",
       " 'ten': 538,\n",
       " 'available.': 541,\n",
       " 'On': 542,\n",
       " 'hand,': 545,\n",
       " 'visited': 552,\n",
       " 'aliens.': 554,\n",
       " 'am': 825,\n",
       " 'discounting': 557,\n",
       " 'reports': 580,\n",
       " 'UFOs.': 561,\n",
       " 'only': 768,\n",
       " 'cranks': 568,\n",
       " 'weirdos?': 570,\n",
       " 'government': 575,\n",
       " 'conspiracy': 576,\n",
       " 'suppress': 578,\n",
       " 'keep': 582,\n",
       " 'scientific': 586,\n",
       " 'aliens': 649,\n",
       " 'bring,': 590,\n",
       " 'seems': 650,\n",
       " 'singularly': 597,\n",
       " 'ineffective': 598,\n",
       " 'policy': 645,\n",
       " 'far.': 601,\n",
       " 'Furthermore,': 602,\n",
       " 'despite': 603,\n",
       " 'extensive': 605,\n",
       " 'search': 606,\n",
       " 'SETI': 609,\n",
       " 'project,': 610,\n",
       " 'haven’t': 612,\n",
       " 'heard': 613,\n",
       " 'any': 614,\n",
       " 'television': 616,\n",
       " 'quiz': 617,\n",
       " 'shows.': 618,\n",
       " 'indicates': 621,\n",
       " 'civilizations': 627,\n",
       " 'our': 816,\n",
       " 'stage': 630,\n",
       " 'development': 632,\n",
       " 'radius': 635,\n",
       " 'few': 638,\n",
       " 'hundred': 814,\n",
       " 'light': 640,\n",
       " 'Issuing': 642,\n",
       " 'insurance': 644,\n",
       " 'against': 646,\n",
       " 'abduction': 647,\n",
       " 'pretty': 652,\n",
       " 'safe': 653,\n",
       " 'bet.': 654,\n",
       " 'brings': 656,\n",
       " 'me': 875,\n",
       " 'last': 802,\n",
       " 'questions:': 664,\n",
       " 'race.': 670,\n",
       " 'intelligent': 676,\n",
       " 'beings': 677,\n",
       " 'galaxy,': 680,\n",
       " 'make': 683,\n",
       " 'sure': 684,\n",
       " 'survive': 686,\n",
       " 'continue.': 688,\n",
       " 'entering': 692,\n",
       " 'increasingly': 694,\n",
       " 'dangerous': 695,\n",
       " 'period': 696,\n",
       " 'history.': 699,\n",
       " 'Our': 767,\n",
       " 'population': 701,\n",
       " 'use': 704,\n",
       " 'finite': 707,\n",
       " 'resources': 708,\n",
       " 'growing': 713,\n",
       " 'exponentially,': 714,\n",
       " 'along': 715,\n",
       " 'technical': 718,\n",
       " 'ability': 719,\n",
       " 'change': 721,\n",
       " 'environment': 723,\n",
       " 'ill.': 727,\n",
       " 'genetic': 730,\n",
       " 'code': 731,\n",
       " 'still': 732,\n",
       " 'carries': 733,\n",
       " 'selfish': 735,\n",
       " 'aggressive': 737,\n",
       " 'instincts': 738,\n",
       " 'survival': 772,\n",
       " 'advantage': 743,\n",
       " 'It': 747,\n",
       " 'will': 748,\n",
       " 'difficult': 750,\n",
       " 'enough': 751,\n",
       " 'avoid': 753,\n",
       " 'disaster': 754,\n",
       " 'next': 813,\n",
       " 'years,': 815,\n",
       " 'let': 760,\n",
       " 'thousand': 764,\n",
       " 'million.': 766,\n",
       " 'chance': 769,\n",
       " 'long-term': 771,\n",
       " 'not': 865,\n",
       " 'remain': 776,\n",
       " 'inward-looking': 777,\n",
       " 'spread': 783,\n",
       " 'answers': 852,\n",
       " 'these': 854,\n",
       " 'show': 793,\n",
       " 'remarkable': 798,\n",
       " 'if': 806,\n",
       " 'want': 808,\n",
       " 'continue': 810,\n",
       " 'beyond': 811,\n",
       " 'That': 821,\n",
       " 'why': 823,\n",
       " 'favor': 827,\n",
       " 'manned': 829,\n",
       " '–': 836,\n",
       " 'say,': 834,\n",
       " 'personned': 835,\n",
       " 'flight.': 838,\n",
       " 'All': 839,\n",
       " 'my': 862,\n",
       " 'sought': 845,\n",
       " 'understand': 847,\n",
       " 'questions.': 855,\n",
       " 'lucky': 860,\n",
       " 'disability': 863,\n",
       " 'has': 872,\n",
       " 'serious': 868,\n",
       " 'handicap.': 869,\n",
       " 'Indeed,': 870,\n",
       " 'more': 876,\n",
       " 'people': 880,\n",
       " 'pursue': 882,\n",
       " 'quest': 884,\n",
       " 'knowledge.': 886,\n",
       " 'ultimate': 888,\n",
       " 'goal': 889,\n",
       " 'complete': 892,\n",
       " 'making': 900,\n",
       " 'progress.': 902,\n",
       " 'Thank': 903,\n",
       " 'you': 904,\n",
       " 'listening.': 906}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "counter = 0\n",
    "\n",
    "for i in text_as_list:\n",
    "    mydictionary[i] = counter\n",
    "    counter += 1\n",
    "\n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3ed1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'There': 0,\n",
       " 'is': 890,\n",
       " 'nothing': 2,\n",
       " 'bigger': 3,\n",
       " 'or': 831,\n",
       " 'older': 5,\n",
       " 'than': 878,\n",
       " 'the': 895,\n",
       " 'universe.': 353,\n",
       " 'The': 887,\n",
       " 'questions': 792,\n",
       " 'I': 856,\n",
       " 'would': 563,\n",
       " 'like': 280,\n",
       " 'to': 881,\n",
       " 'talk': 15,\n",
       " 'about': 478,\n",
       " 'are:': 17,\n",
       " 'one,': 18,\n",
       " 'where': 19,\n",
       " 'did': 139,\n",
       " 'we': 898,\n",
       " 'come': 28,\n",
       " 'from?': 23,\n",
       " 'How': 24,\n",
       " 'universe': 849,\n",
       " 'into': 785,\n",
       " 'being?': 30,\n",
       " 'Are': 31,\n",
       " 'alone': 761,\n",
       " 'in': 826,\n",
       " 'universe?': 394,\n",
       " 'Is': 37,\n",
       " 'there': 623,\n",
       " 'alien': 626,\n",
       " 'life': 842,\n",
       " 'out': 784,\n",
       " 'there?': 42,\n",
       " 'What': 43,\n",
       " 'future': 817,\n",
       " 'of': 894,\n",
       " 'human': 669,\n",
       " 'race?': 50,\n",
       " 'Up': 51,\n",
       " 'until': 235,\n",
       " '1920s,': 54,\n",
       " 'everyone': 371,\n",
       " 'thought': 56,\n",
       " 'was': 525,\n",
       " 'essentially': 60,\n",
       " 'static': 61,\n",
       " 'and': 897,\n",
       " 'unchanging': 63,\n",
       " 'time.': 194,\n",
       " 'Then': 66,\n",
       " 'it': 871,\n",
       " 'discovered': 69,\n",
       " 'that': 861,\n",
       " 'expanding.': 74,\n",
       " 'Distant': 75,\n",
       " 'galaxies': 76,\n",
       " 'were': 740,\n",
       " 'moving': 78,\n",
       " 'away': 79,\n",
       " 'from': 459,\n",
       " 'us.': 81,\n",
       " 'This': 655,\n",
       " 'meant': 83,\n",
       " 'they': 564,\n",
       " 'must': 406,\n",
       " 'have': 857,\n",
       " 'been': 866,\n",
       " 'closer': 88,\n",
       " 'together': 89,\n",
       " 'past.': 746,\n",
       " 'If': 671,\n",
       " 'extrapolate': 95,\n",
       " 'back,': 96,\n",
       " 'find': 851,\n",
       " 'all': 228,\n",
       " 'on': 778,\n",
       " 'top': 105,\n",
       " 'each': 107,\n",
       " 'other': 544,\n",
       " '15': 110,\n",
       " 'billion': 539,\n",
       " 'years': 540,\n",
       " 'ago.': 463,\n",
       " 'Big': 145,\n",
       " 'Bang,': 118,\n",
       " 'beginning': 120,\n",
       " 'But': 805,\n",
       " 'anything': 127,\n",
       " 'before': 128,\n",
       " 'Bang?': 131,\n",
       " 'not,': 133,\n",
       " 'what': 134,\n",
       " 'created': 324,\n",
       " 'Why': 562,\n",
       " 'emerge': 142,\n",
       " 'Bang': 146,\n",
       " 'way': 148,\n",
       " 'did?': 150,\n",
       " 'We': 437,\n",
       " 'used': 152,\n",
       " 'think': 355,\n",
       " 'theory': 893,\n",
       " 'could': 161,\n",
       " 'be': 749,\n",
       " 'divided': 163,\n",
       " 'two': 439,\n",
       " 'parts.': 166,\n",
       " 'First,': 167,\n",
       " 'laws': 296,\n",
       " 'Maxwell’s': 173,\n",
       " 'equations': 174,\n",
       " 'general': 271,\n",
       " 'relativity': 272,\n",
       " 'determined': 179,\n",
       " 'evolution': 298,\n",
       " 'universe,': 896,\n",
       " 'given': 874,\n",
       " 'its': 186,\n",
       " 'state': 204,\n",
       " 'over': 188,\n",
       " 'space': 837,\n",
       " 'at': 628,\n",
       " 'one': 528,\n",
       " 'And': 195,\n",
       " 'second,': 196,\n",
       " 'no': 625,\n",
       " 'question': 200,\n",
       " 'initial': 303,\n",
       " 'made': 797,\n",
       " 'good': 901,\n",
       " 'progress': 799,\n",
       " 'first': 480,\n",
       " 'part,': 216,\n",
       " 'now': 377,\n",
       " 'knowledge': 587,\n",
       " 'but': 781,\n",
       " 'most': 879,\n",
       " 'extreme': 269,\n",
       " 'conditions.': 233,\n",
       " 'recently,': 236,\n",
       " 'had': 239,\n",
       " 'little': 240,\n",
       " 'idea': 241,\n",
       " 'conditions': 258,\n",
       " 'for': 905,\n",
       " 'However,': 249,\n",
       " 'this': 250,\n",
       " 'division': 251,\n",
       " 'depends': 259,\n",
       " 'time': 877,\n",
       " 'being': 496,\n",
       " 'separate': 265,\n",
       " 'distinct.': 267,\n",
       " 'Under': 268,\n",
       " 'conditions,': 270,\n",
       " 'quantum': 274,\n",
       " 'allow': 276,\n",
       " 'behave': 279,\n",
       " 'another': 281,\n",
       " 'dimension': 282,\n",
       " 'space.': 820,\n",
       " 'removes': 286,\n",
       " 'distinction': 288,\n",
       " 'between': 289,\n",
       " 'space,': 292,\n",
       " 'means': 294,\n",
       " 'can': 316,\n",
       " 'also': 300,\n",
       " 'determine': 301,\n",
       " 'state.': 304,\n",
       " 'spontaneously': 400,\n",
       " 'create': 309,\n",
       " 'itself': 584,\n",
       " 'nothing.': 313,\n",
       " 'Moreover,': 314,\n",
       " 'calculate': 317,\n",
       " 'a': 891,\n",
       " 'probability': 516,\n",
       " 'different': 326,\n",
       " 'states.': 327,\n",
       " 'These': 328,\n",
       " 'predictions': 329,\n",
       " 'are': 899,\n",
       " 'excellent': 332,\n",
       " 'agreement': 333,\n",
       " 'with': 716,\n",
       " 'observations': 335,\n",
       " 'by': 648,\n",
       " 'WMAP': 338,\n",
       " 'satellite': 339,\n",
       " 'cosmic': 342,\n",
       " 'microwave': 343,\n",
       " 'background,': 344,\n",
       " 'which': 498,\n",
       " 'an': 693,\n",
       " 'imprint': 348,\n",
       " 'very': 859,\n",
       " 'early': 352,\n",
       " 'solved': 358,\n",
       " 'mystery': 360,\n",
       " 'creation.': 362,\n",
       " 'Maybe': 363,\n",
       " 'should': 832,\n",
       " 'patent': 366,\n",
       " 'charge': 370,\n",
       " 'royalties': 372,\n",
       " 'their': 374,\n",
       " 'existence.': 375,\n",
       " 'turn': 378,\n",
       " 'second': 381,\n",
       " 'big': 791,\n",
       " 'question:': 383,\n",
       " 'alone,': 386,\n",
       " 'believe': 396,\n",
       " 'arose': 399,\n",
       " 'Earth,': 780,\n",
       " 'so': 600,\n",
       " 'possible': 408,\n",
       " 'appear': 565,\n",
       " 'suitable': 415,\n",
       " 'planets,': 416,\n",
       " 'seem': 548,\n",
       " 'large': 424,\n",
       " 'number': 425,\n",
       " 'galaxy.': 428,\n",
       " 'don’t': 547,\n",
       " 'know': 432,\n",
       " 'how': 433,\n",
       " 'appeared.': 436,\n",
       " 'pieces': 440,\n",
       " 'observational': 442,\n",
       " 'evidence': 443,\n",
       " 'appearing.': 449,\n",
       " 'fossils': 456,\n",
       " 'algae': 458,\n",
       " '3.5': 460,\n",
       " 'Earth': 711,\n",
       " 'formed': 467,\n",
       " '4.6': 468,\n",
       " 'ago': 471,\n",
       " 'probably': 873,\n",
       " 'too': 475,\n",
       " 'hot': 476,\n",
       " 'half': 490,\n",
       " 'years.': 804,\n",
       " 'So': 484,\n",
       " 'appeared': 486,\n",
       " 'within': 633,\n",
       " 'possible,': 497,\n",
       " 'short': 500,\n",
       " 'compared': 501,\n",
       " '10-billion-year': 504,\n",
       " 'lifetime': 505,\n",
       " 'planet': 779,\n",
       " 'type.': 511,\n",
       " 'suggests': 513,\n",
       " 'appearing': 519,\n",
       " 'reasonably': 521,\n",
       " 'high.': 522,\n",
       " 'low,': 527,\n",
       " 'expected': 531,\n",
       " 'take': 534,\n",
       " 'ten': 538,\n",
       " 'available.': 541,\n",
       " 'On': 542,\n",
       " 'hand,': 545,\n",
       " 'visited': 552,\n",
       " 'aliens.': 554,\n",
       " 'am': 825,\n",
       " 'discounting': 557,\n",
       " 'reports': 580,\n",
       " 'UFOs.': 561,\n",
       " 'only': 768,\n",
       " 'cranks': 568,\n",
       " 'weirdos?': 570,\n",
       " 'government': 575,\n",
       " 'conspiracy': 576,\n",
       " 'suppress': 578,\n",
       " 'keep': 582,\n",
       " 'scientific': 586,\n",
       " 'aliens': 649,\n",
       " 'bring,': 590,\n",
       " 'seems': 650,\n",
       " 'singularly': 597,\n",
       " 'ineffective': 598,\n",
       " 'policy': 645,\n",
       " 'far.': 601,\n",
       " 'Furthermore,': 602,\n",
       " 'despite': 603,\n",
       " 'extensive': 605,\n",
       " 'search': 606,\n",
       " 'SETI': 609,\n",
       " 'project,': 610,\n",
       " 'haven’t': 612,\n",
       " 'heard': 613,\n",
       " 'any': 614,\n",
       " 'television': 616,\n",
       " 'quiz': 617,\n",
       " 'shows.': 618,\n",
       " 'indicates': 621,\n",
       " 'civilizations': 627,\n",
       " 'our': 816,\n",
       " 'stage': 630,\n",
       " 'development': 632,\n",
       " 'radius': 635,\n",
       " 'few': 638,\n",
       " 'hundred': 814,\n",
       " 'light': 640,\n",
       " 'Issuing': 642,\n",
       " 'insurance': 644,\n",
       " 'against': 646,\n",
       " 'abduction': 647,\n",
       " 'pretty': 652,\n",
       " 'safe': 653,\n",
       " 'bet.': 654,\n",
       " 'brings': 656,\n",
       " 'me': 875,\n",
       " 'last': 802,\n",
       " 'questions:': 664,\n",
       " 'race.': 670,\n",
       " 'intelligent': 676,\n",
       " 'beings': 677,\n",
       " 'galaxy,': 680,\n",
       " 'make': 683,\n",
       " 'sure': 684,\n",
       " 'survive': 686,\n",
       " 'continue.': 688,\n",
       " 'entering': 692,\n",
       " 'increasingly': 694,\n",
       " 'dangerous': 695,\n",
       " 'period': 696,\n",
       " 'history.': 699,\n",
       " 'Our': 767,\n",
       " 'population': 701,\n",
       " 'use': 704,\n",
       " 'finite': 707,\n",
       " 'resources': 708,\n",
       " 'growing': 713,\n",
       " 'exponentially,': 714,\n",
       " 'along': 715,\n",
       " 'technical': 718,\n",
       " 'ability': 719,\n",
       " 'change': 721,\n",
       " 'environment': 723,\n",
       " 'ill.': 727,\n",
       " 'genetic': 730,\n",
       " 'code': 731,\n",
       " 'still': 732,\n",
       " 'carries': 733,\n",
       " 'selfish': 735,\n",
       " 'aggressive': 737,\n",
       " 'instincts': 738,\n",
       " 'survival': 772,\n",
       " 'advantage': 743,\n",
       " 'It': 747,\n",
       " 'will': 748,\n",
       " 'difficult': 750,\n",
       " 'enough': 751,\n",
       " 'avoid': 753,\n",
       " 'disaster': 754,\n",
       " 'next': 813,\n",
       " 'years,': 815,\n",
       " 'let': 760,\n",
       " 'thousand': 764,\n",
       " 'million.': 766,\n",
       " 'chance': 769,\n",
       " 'long-term': 771,\n",
       " 'not': 865,\n",
       " 'remain': 776,\n",
       " 'inward-looking': 777,\n",
       " 'spread': 783,\n",
       " 'answers': 852,\n",
       " 'these': 854,\n",
       " 'show': 793,\n",
       " 'remarkable': 798,\n",
       " 'if': 806,\n",
       " 'want': 808,\n",
       " 'continue': 810,\n",
       " 'beyond': 811,\n",
       " 'That': 821,\n",
       " 'why': 823,\n",
       " 'favor': 827,\n",
       " 'manned': 829,\n",
       " '–': 836,\n",
       " 'say,': 834,\n",
       " 'personned': 835,\n",
       " 'flight.': 838,\n",
       " 'All': 839,\n",
       " 'my': 862,\n",
       " 'sought': 845,\n",
       " 'understand': 847,\n",
       " 'questions.': 855,\n",
       " 'lucky': 860,\n",
       " 'disability': 863,\n",
       " 'has': 872,\n",
       " 'serious': 868,\n",
       " 'handicap.': 869,\n",
       " 'Indeed,': 870,\n",
       " 'more': 876,\n",
       " 'people': 880,\n",
       " 'pursue': 882,\n",
       " 'quest': 884,\n",
       " 'knowledge.': 886,\n",
       " 'ultimate': 888,\n",
       " 'goal': 889,\n",
       " 'complete': 892,\n",
       " 'making': 900,\n",
       " 'progress.': 902,\n",
       " 'Thank': 903,\n",
       " 'you': 904,\n",
       " 'listening.': 906}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "\n",
    "for i,j in enumerate(text_as_list):\n",
    "    mydictionary[j] = i\n",
    "\n",
    "mydictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "newdictionary = {}\n",
    "for key, value in mydictionary.items():\n",
    "    if i:\n",
    "        newdictionary[value]=[key]\n",
    "print(len(newdictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydictionary = {}\n",
    "\n",
    "for i,j in enumerate(text_as_list):\n",
    "    mydictionary[i] = j\n",
    "\n",
    "mydictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": [
    "The new dictionary counts the number of instances that each unique value occurs while the old dictionary counts the number of unique instances that each value occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2483fe",
   "metadata": {},
   "source": [
    "# Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a117b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 10,\n",
       " 'is': 13,\n",
       " 'nothing': 2,\n",
       " 'bigger': 1,\n",
       " 'or': 5,\n",
       " 'older': 1,\n",
       " 'than': 2,\n",
       " 'the': 77,\n",
       " 'universe': 19,\n",
       " 'questions': 4,\n",
       " 'i': 7,\n",
       " 'would': 3,\n",
       " 'like': 3,\n",
       " 'to': 22,\n",
       " 'talk': 1,\n",
       " 'about': 4,\n",
       " 'are': 9,\n",
       " 'one': 3,\n",
       " 'where': 1,\n",
       " 'did': 4,\n",
       " 'we': 26,\n",
       " 'come': 2,\n",
       " 'from': 4,\n",
       " 'how': 2,\n",
       " 'into': 4,\n",
       " 'being': 3,\n",
       " 'alone': 3,\n",
       " 'in': 14,\n",
       " 'alien': 3,\n",
       " 'life': 9,\n",
       " 'out': 3,\n",
       " 'what': 2,\n",
       " 'future': 3,\n",
       " 'of': 39,\n",
       " 'human': 2,\n",
       " 'race': 2,\n",
       " 'up': 1,\n",
       " 'until': 2,\n",
       " '1920s': 1,\n",
       " 'everyone': 2,\n",
       " 'thought': 1,\n",
       " 'was': 10,\n",
       " 'essentially': 1,\n",
       " 'static': 1,\n",
       " 'and': 19,\n",
       " 'unchanging': 1,\n",
       " 'time': 6,\n",
       " 'then': 1,\n",
       " 'it': 9,\n",
       " 'discovered': 1,\n",
       " 'that': 12,\n",
       " 'expanding': 1,\n",
       " 'distant': 1,\n",
       " 'galaxies': 1,\n",
       " 'were': 3,\n",
       " 'moving': 1,\n",
       " 'away': 1,\n",
       " 'us': 1,\n",
       " 'this': 7,\n",
       " 'meant': 1,\n",
       " 'they': 2,\n",
       " 'must': 3,\n",
       " 'have': 14,\n",
       " 'been': 6,\n",
       " 'closer': 1,\n",
       " 'together': 1,\n",
       " 'past': 2,\n",
       " 'if': 6,\n",
       " 'extrapolate': 1,\n",
       " 'back': 1,\n",
       " 'find': 2,\n",
       " 'all': 4,\n",
       " 'on': 9,\n",
       " 'top': 1,\n",
       " 'each': 1,\n",
       " 'other': 4,\n",
       " '15': 1,\n",
       " 'billion': 6,\n",
       " 'years': 10,\n",
       " 'ago': 3,\n",
       " 'big': 6,\n",
       " 'bang': 3,\n",
       " 'beginning': 1,\n",
       " 'but': 8,\n",
       " 'anything': 1,\n",
       " 'before': 1,\n",
       " 'not': 3,\n",
       " 'created': 2,\n",
       " 'why': 3,\n",
       " 'emerge': 1,\n",
       " 'way': 1,\n",
       " 'used': 1,\n",
       " 'think': 2,\n",
       " 'theory': 3,\n",
       " 'could': 1,\n",
       " 'be': 4,\n",
       " 'divided': 1,\n",
       " 'two': 2,\n",
       " 'parts': 1,\n",
       " 'first': 5,\n",
       " 'laws': 4,\n",
       " 'maxwell’s': 1,\n",
       " 'equations': 1,\n",
       " 'general': 2,\n",
       " 'relativity': 2,\n",
       " 'determined': 1,\n",
       " 'evolution': 4,\n",
       " 'given': 2,\n",
       " 'its': 1,\n",
       " 'state': 3,\n",
       " 'over': 1,\n",
       " 'space': 7,\n",
       " 'at': 2,\n",
       " 'second': 2,\n",
       " 'no': 2,\n",
       " 'question': 2,\n",
       " 'initial': 4,\n",
       " 'made': 2,\n",
       " 'good': 3,\n",
       " 'progress': 3,\n",
       " 'part': 1,\n",
       " 'now': 2,\n",
       " 'knowledge': 3,\n",
       " 'most': 3,\n",
       " 'extreme': 2,\n",
       " 'conditions': 4,\n",
       " 'recently': 1,\n",
       " 'had': 1,\n",
       " 'little': 1,\n",
       " 'idea': 1,\n",
       " 'for': 8,\n",
       " 'however': 1,\n",
       " 'division': 1,\n",
       " 'depends': 1,\n",
       " 'separate': 1,\n",
       " 'distinct': 1,\n",
       " 'under': 1,\n",
       " 'quantum': 1,\n",
       " 'allow': 1,\n",
       " 'behave': 1,\n",
       " 'another': 1,\n",
       " 'dimension': 1,\n",
       " 'removes': 1,\n",
       " 'distinction': 1,\n",
       " 'between': 1,\n",
       " 'means': 1,\n",
       " 'can': 3,\n",
       " 'also': 1,\n",
       " 'determine': 1,\n",
       " 'spontaneously': 2,\n",
       " 'create': 1,\n",
       " 'itself': 2,\n",
       " 'moreover': 1,\n",
       " 'calculate': 1,\n",
       " 'a': 11,\n",
       " 'probability': 3,\n",
       " 'different': 1,\n",
       " 'states': 1,\n",
       " 'these': 3,\n",
       " 'predictions': 1,\n",
       " 'excellent': 1,\n",
       " 'agreement': 1,\n",
       " 'with': 2,\n",
       " 'observations': 1,\n",
       " 'by': 4,\n",
       " 'wmap': 1,\n",
       " 'satellite': 1,\n",
       " 'cosmic': 1,\n",
       " 'microwave': 1,\n",
       " 'background': 1,\n",
       " 'which': 3,\n",
       " 'an': 4,\n",
       " 'imprint': 1,\n",
       " 'very': 3,\n",
       " 'early': 1,\n",
       " 'solved': 1,\n",
       " 'mystery': 1,\n",
       " 'creation': 1,\n",
       " 'maybe': 1,\n",
       " 'should': 3,\n",
       " 'patent': 1,\n",
       " 'charge': 1,\n",
       " 'royalties': 1,\n",
       " 'their': 1,\n",
       " 'existence': 1,\n",
       " 'turn': 1,\n",
       " 'believe': 1,\n",
       " 'arose': 1,\n",
       " 'earth': 6,\n",
       " 'so': 3,\n",
       " 'possible': 2,\n",
       " 'appear': 2,\n",
       " 'suitable': 1,\n",
       " 'planets': 1,\n",
       " 'seem': 2,\n",
       " 'large': 1,\n",
       " 'number': 1,\n",
       " 'galaxy': 2,\n",
       " 'don’t': 2,\n",
       " 'know': 1,\n",
       " 'appeared': 2,\n",
       " 'pieces': 1,\n",
       " 'observational': 1,\n",
       " 'evidence': 1,\n",
       " 'appearing': 2,\n",
       " 'fossils': 1,\n",
       " 'algae': 1,\n",
       " '35': 1,\n",
       " 'formed': 1,\n",
       " '46': 1,\n",
       " 'probably': 3,\n",
       " 'too': 1,\n",
       " 'hot': 1,\n",
       " 'half': 2,\n",
       " 'within': 2,\n",
       " 'short': 1,\n",
       " 'compared': 1,\n",
       " '10billionyear': 1,\n",
       " 'lifetime': 1,\n",
       " 'planet': 3,\n",
       " 'type': 1,\n",
       " 'suggests': 1,\n",
       " 'reasonably': 1,\n",
       " 'high': 1,\n",
       " 'low': 1,\n",
       " 'expected': 1,\n",
       " 'take': 1,\n",
       " 'ten': 1,\n",
       " 'available': 1,\n",
       " 'hand': 1,\n",
       " 'visited': 1,\n",
       " 'aliens': 3,\n",
       " 'am': 2,\n",
       " 'discounting': 1,\n",
       " 'reports': 2,\n",
       " 'ufos': 1,\n",
       " 'only': 3,\n",
       " 'cranks': 1,\n",
       " 'weirdos': 1,\n",
       " 'government': 1,\n",
       " 'conspiracy': 1,\n",
       " 'suppress': 1,\n",
       " 'keep': 1,\n",
       " 'scientific': 1,\n",
       " 'bring': 1,\n",
       " 'seems': 2,\n",
       " 'singularly': 1,\n",
       " 'ineffective': 1,\n",
       " 'policy': 2,\n",
       " 'far': 1,\n",
       " 'furthermore': 1,\n",
       " 'despite': 1,\n",
       " 'extensive': 1,\n",
       " 'search': 1,\n",
       " 'seti': 1,\n",
       " 'project': 1,\n",
       " 'haven’t': 1,\n",
       " 'heard': 1,\n",
       " 'any': 1,\n",
       " 'television': 1,\n",
       " 'quiz': 1,\n",
       " 'shows': 1,\n",
       " 'indicates': 1,\n",
       " 'civilizations': 1,\n",
       " 'our': 8,\n",
       " 'stage': 1,\n",
       " 'development': 1,\n",
       " 'radius': 1,\n",
       " 'few': 1,\n",
       " 'hundred': 4,\n",
       " 'light': 1,\n",
       " 'issuing': 1,\n",
       " 'insurance': 1,\n",
       " 'against': 1,\n",
       " 'abduction': 1,\n",
       " 'pretty': 1,\n",
       " 'safe': 1,\n",
       " 'bet': 1,\n",
       " 'brings': 1,\n",
       " 'me': 2,\n",
       " 'last': 2,\n",
       " 'intelligent': 1,\n",
       " 'beings': 1,\n",
       " 'make': 1,\n",
       " 'sure': 1,\n",
       " 'survive': 1,\n",
       " 'continue': 2,\n",
       " 'entering': 1,\n",
       " 'increasingly': 1,\n",
       " 'dangerous': 1,\n",
       " 'period': 1,\n",
       " 'history': 1,\n",
       " 'population': 1,\n",
       " 'use': 1,\n",
       " 'finite': 1,\n",
       " 'resources': 1,\n",
       " 'growing': 1,\n",
       " 'exponentially': 1,\n",
       " 'along': 1,\n",
       " 'technical': 1,\n",
       " 'ability': 1,\n",
       " 'change': 1,\n",
       " 'environment': 1,\n",
       " 'ill': 1,\n",
       " 'genetic': 1,\n",
       " 'code': 1,\n",
       " 'still': 1,\n",
       " 'carries': 1,\n",
       " 'selfish': 1,\n",
       " 'aggressive': 1,\n",
       " 'instincts': 1,\n",
       " 'survival': 2,\n",
       " 'advantage': 1,\n",
       " 'will': 1,\n",
       " 'difficult': 1,\n",
       " 'enough': 1,\n",
       " 'avoid': 1,\n",
       " 'disaster': 1,\n",
       " 'next': 3,\n",
       " 'let': 1,\n",
       " 'thousand': 1,\n",
       " 'million': 1,\n",
       " 'chance': 1,\n",
       " 'longterm': 1,\n",
       " 'remain': 1,\n",
       " 'inwardlooking': 1,\n",
       " 'spread': 1,\n",
       " 'answers': 2,\n",
       " 'show': 1,\n",
       " 'remarkable': 1,\n",
       " 'want': 1,\n",
       " 'beyond': 1,\n",
       " 'favor': 1,\n",
       " 'manned': 1,\n",
       " '–': 2,\n",
       " 'say': 1,\n",
       " 'personned': 1,\n",
       " 'flight': 1,\n",
       " 'my': 2,\n",
       " 'sought': 1,\n",
       " 'understand': 1,\n",
       " 'lucky': 1,\n",
       " 'disability': 1,\n",
       " 'has': 2,\n",
       " 'serious': 1,\n",
       " 'handicap': 1,\n",
       " 'indeed': 1,\n",
       " 'more': 1,\n",
       " 'people': 1,\n",
       " 'pursue': 1,\n",
       " 'quest': 1,\n",
       " 'ultimate': 1,\n",
       " 'goal': 1,\n",
       " 'complete': 1,\n",
       " 'making': 1,\n",
       " 'thank': 1,\n",
       " 'you': 1,\n",
       " 'listening': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_counter = {}\n",
    "for i in text_as_list:\n",
    "    dict_counter[i] = text_as_list.count(i)\n",
    "dict_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m text_as_list:\n\u001b[1;32m      6\u001b[0m         text_as_list\u001b[38;5;241m.\u001b[39mcount(i)\n\u001b[0;32m----> 7\u001b[0m         n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m my_enumerate(text_as_list)\n\u001b[1;32m      9\u001b[0m dict_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((text_as_list))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "dict_counter = {}\n",
    "for key, value in mydictionary.items():\n",
    "    if i:\n",
    "        dict_counter [value]=[key]\n",
    "    for i in text_as_list:\n",
    "        text_as_list.count(i)\n",
    "        n += 1\n",
    "my_enumerate(text_as_list)\n",
    "dict_counter = dict((text_as_list))\n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"question\")\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b724569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_counter[\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [154]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmydictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:1677\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly recognize index or columns for orient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[1;32m    667\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(mydictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a03638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(mydictionary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1b0d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>903</td>\n",
       "      <td>progress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>904</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>905</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>906</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>907</td>\n",
       "      <td>listening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1\n",
       "0      1      there\n",
       "1      2         is\n",
       "2      3    nothing\n",
       "3      4     bigger\n",
       "4      5         or\n",
       "..   ...        ...\n",
       "902  903   progress\n",
       "903  904      thank\n",
       "904  905        you\n",
       "905  906        for\n",
       "906  907  listening\n",
       "\n",
       "[907 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1\n",
       "0  1  there"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6849cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        3\n",
       "3        4\n",
       "4        5\n",
       "      ... \n",
       "902    903\n",
       "903    904\n",
       "904    905\n",
       "905    906\n",
       "906    907\n",
       "Name: 0, Length: 907, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fadb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxy and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a81bbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5164c098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "1          \n",
       "galaxy  429\n",
       "galaxy  681"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['galaxy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n*fact(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(fact(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
