{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Hawking-Questioning-the-Universe.txt\", \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe\n"
     ]
    }
   ],
   "source": [
    "print(text[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The questions I would like to talk about are: one, where did we come from? How did the universe come into bein\n"
     ]
    }
   ],
   "source": [
    "print(text[51:163])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Hawking-Questioning-the-Universe.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "text_as_list = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'are:',\n",
       " 'alone',\n",
       " 'alien',\n",
       " 'and',\n",
       " 'away',\n",
       " 'all',\n",
       " 'about',\n",
       " 'ago.',\n",
       " 'anything',\n",
       " 'and',\n",
       " 'all',\n",
       " 'at',\n",
       " 'and',\n",
       " 'all',\n",
       " 'about',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'allow',\n",
       " 'another',\n",
       " 'and',\n",
       " 'and',\n",
       " 'also',\n",
       " 'a',\n",
       " 'are',\n",
       " 'agreement',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'alone,',\n",
       " 'arose',\n",
       " 'appear',\n",
       " 'a',\n",
       " 'appeared.',\n",
       " 'appearing.',\n",
       " 'algae',\n",
       " 'ago.',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'about',\n",
       " 'appeared',\n",
       " 'a',\n",
       " 'a',\n",
       " 'appearing',\n",
       " 'available.',\n",
       " 'aliens.',\n",
       " 'am',\n",
       " 'appear',\n",
       " 'and',\n",
       " 'a',\n",
       " 'and',\n",
       " 'aliens',\n",
       " 'a',\n",
       " 'an',\n",
       " 'any',\n",
       " 'alien',\n",
       " 'are',\n",
       " 'alien',\n",
       " 'at',\n",
       " 'a',\n",
       " 'a',\n",
       " 'an',\n",
       " 'against',\n",
       " 'abduction',\n",
       " 'aliens',\n",
       " 'a',\n",
       " 'are',\n",
       " 'and',\n",
       " 'are',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'along',\n",
       " 'ability',\n",
       " 'and',\n",
       " 'aggressive',\n",
       " 'advantage',\n",
       " 'avoid',\n",
       " 'alone',\n",
       " 'answers',\n",
       " 'am',\n",
       " 'and',\n",
       " 'answers',\n",
       " 'a',\n",
       " 'a',\n",
       " 'and',\n",
       " 'are']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "for item in text_as_list:\n",
    "    if item.startswith(\"a\"):\n",
    "        words_begin_with_a.append(item)\n",
    "    else:\n",
    "        continue\n",
    "words_begin_with_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter2 = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if not text_as_list[i].startswith('u'):\n",
    "        counter2 += 1\n",
    "    i += 1\n",
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7da6a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does appear\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"universe\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38e92923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist1 = ['universe']\n",
    "# flag = 0\n",
    "# for i in text_as_list:\n",
    "#     for j in checklist1:\n",
    "#         if i==j:\n",
    "#             flag += 1\n",
    "#             break\n",
    "# if flag == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fbeabaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does not appear\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"alliens\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist2 = [\"alliens\"]\n",
    "# flag = 0\n",
    "# for i in text:\n",
    "#     for j in checklist2:\n",
    "#         if i == j:\n",
    "#             flag += 1\n",
    "#             break\n",
    "# if flag == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"The word does not appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "469fec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't find the words\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"alliens\")\n",
    "j = text_as_list.count(\"International Space Station\")\n",
    "if i > 0:\n",
    "    print(\"The word does appear\")\n",
    "elif j > 0:\n",
    "    print(\"The word does appear\")\n",
    "else:\n",
    "    print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "903e4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checklist3 = [\"alliens\", \"International Space Station\"]\n",
    "# flag1 = 0\n",
    "# flag2 = 0\n",
    "# for i in text_as_list:\n",
    "#     for j in checklist3:\n",
    "#         if i == j[0]:\n",
    "#             flag1 += 1\n",
    "#         elif i == j[1]:\n",
    "#             flag2 += 1\n",
    "#             break\n",
    "# if flag1 == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# elif flag2 == 1:\n",
    "#     print(\"The word does appear\")\n",
    "# else:\n",
    "#     print(\"I didn't find the words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydictionary = {}\n",
    "def my_enumerate(sequence, start=1):\n",
    "    n = start\n",
    "    for elem in sequence:\n",
    "        yield n, elem\n",
    "        n += 1\n",
    "my_enumerate(text_as_list)\n",
    "mydictionary = dict(my_enumerate(text_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "newdictionary = {}\n",
    "for key, value in mydictionary.items():\n",
    "    if i:\n",
    "        newdictionary[value]=[key]\n",
    "print(len(newdictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": [
    "The new dictionary counts the number of instances that each unique value occurs while the old dictionary counts the number of unique instances that each value occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2483fe",
   "metadata": {},
   "source": [
    "# Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "39a117b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 10,\n",
       " 'is': 13,\n",
       " 'nothing': 2,\n",
       " 'bigger': 1,\n",
       " 'or': 5,\n",
       " 'older': 1,\n",
       " 'than': 2,\n",
       " 'the': 77,\n",
       " 'universe': 19,\n",
       " 'questions': 4,\n",
       " 'i': 7,\n",
       " 'would': 3,\n",
       " 'like': 3,\n",
       " 'to': 22,\n",
       " 'talk': 1,\n",
       " 'about': 4,\n",
       " 'are': 9,\n",
       " 'one': 3,\n",
       " 'where': 1,\n",
       " 'did': 4,\n",
       " 'we': 26,\n",
       " 'come': 2,\n",
       " 'from': 4,\n",
       " 'how': 2,\n",
       " 'into': 4,\n",
       " 'being': 3,\n",
       " 'alone': 3,\n",
       " 'in': 14,\n",
       " 'alien': 3,\n",
       " 'life': 9,\n",
       " 'out': 3,\n",
       " 'what': 2,\n",
       " 'future': 3,\n",
       " 'of': 39,\n",
       " 'human': 2,\n",
       " 'race': 2,\n",
       " 'up': 1,\n",
       " 'until': 2,\n",
       " '1920s': 1,\n",
       " 'everyone': 2,\n",
       " 'thought': 1,\n",
       " 'was': 10,\n",
       " 'essentially': 1,\n",
       " 'static': 1,\n",
       " 'and': 19,\n",
       " 'unchanging': 1,\n",
       " 'time': 6,\n",
       " 'then': 1,\n",
       " 'it': 9,\n",
       " 'discovered': 1,\n",
       " 'that': 12,\n",
       " 'expanding': 1,\n",
       " 'distant': 1,\n",
       " 'galaxies': 1,\n",
       " 'were': 3,\n",
       " 'moving': 1,\n",
       " 'away': 1,\n",
       " 'us': 1,\n",
       " 'this': 7,\n",
       " 'meant': 1,\n",
       " 'they': 2,\n",
       " 'must': 3,\n",
       " 'have': 14,\n",
       " 'been': 6,\n",
       " 'closer': 1,\n",
       " 'together': 1,\n",
       " 'past': 2,\n",
       " 'if': 6,\n",
       " 'extrapolate': 1,\n",
       " 'back': 1,\n",
       " 'find': 2,\n",
       " 'all': 4,\n",
       " 'on': 9,\n",
       " 'top': 1,\n",
       " 'each': 1,\n",
       " 'other': 4,\n",
       " '15': 1,\n",
       " 'billion': 6,\n",
       " 'years': 10,\n",
       " 'ago': 3,\n",
       " 'big': 6,\n",
       " 'bang': 3,\n",
       " 'beginning': 1,\n",
       " 'but': 8,\n",
       " 'anything': 1,\n",
       " 'before': 1,\n",
       " 'not': 3,\n",
       " 'created': 2,\n",
       " 'why': 3,\n",
       " 'emerge': 1,\n",
       " 'way': 1,\n",
       " 'used': 1,\n",
       " 'think': 2,\n",
       " 'theory': 3,\n",
       " 'could': 1,\n",
       " 'be': 4,\n",
       " 'divided': 1,\n",
       " 'two': 2,\n",
       " 'parts': 1,\n",
       " 'first': 5,\n",
       " 'laws': 4,\n",
       " 'maxwell’s': 1,\n",
       " 'equations': 1,\n",
       " 'general': 2,\n",
       " 'relativity': 2,\n",
       " 'determined': 1,\n",
       " 'evolution': 4,\n",
       " 'given': 2,\n",
       " 'its': 1,\n",
       " 'state': 3,\n",
       " 'over': 1,\n",
       " 'space': 7,\n",
       " 'at': 2,\n",
       " 'second': 2,\n",
       " 'no': 2,\n",
       " 'question': 2,\n",
       " 'initial': 4,\n",
       " 'made': 2,\n",
       " 'good': 3,\n",
       " 'progress': 3,\n",
       " 'part': 1,\n",
       " 'now': 2,\n",
       " 'knowledge': 3,\n",
       " 'most': 3,\n",
       " 'extreme': 2,\n",
       " 'conditions': 4,\n",
       " 'recently': 1,\n",
       " 'had': 1,\n",
       " 'little': 1,\n",
       " 'idea': 1,\n",
       " 'for': 8,\n",
       " 'however': 1,\n",
       " 'division': 1,\n",
       " 'depends': 1,\n",
       " 'separate': 1,\n",
       " 'distinct': 1,\n",
       " 'under': 1,\n",
       " 'quantum': 1,\n",
       " 'allow': 1,\n",
       " 'behave': 1,\n",
       " 'another': 1,\n",
       " 'dimension': 1,\n",
       " 'removes': 1,\n",
       " 'distinction': 1,\n",
       " 'between': 1,\n",
       " 'means': 1,\n",
       " 'can': 3,\n",
       " 'also': 1,\n",
       " 'determine': 1,\n",
       " 'spontaneously': 2,\n",
       " 'create': 1,\n",
       " 'itself': 2,\n",
       " 'moreover': 1,\n",
       " 'calculate': 1,\n",
       " 'a': 11,\n",
       " 'probability': 3,\n",
       " 'different': 1,\n",
       " 'states': 1,\n",
       " 'these': 3,\n",
       " 'predictions': 1,\n",
       " 'excellent': 1,\n",
       " 'agreement': 1,\n",
       " 'with': 2,\n",
       " 'observations': 1,\n",
       " 'by': 4,\n",
       " 'wmap': 1,\n",
       " 'satellite': 1,\n",
       " 'cosmic': 1,\n",
       " 'microwave': 1,\n",
       " 'background': 1,\n",
       " 'which': 3,\n",
       " 'an': 4,\n",
       " 'imprint': 1,\n",
       " 'very': 3,\n",
       " 'early': 1,\n",
       " 'solved': 1,\n",
       " 'mystery': 1,\n",
       " 'creation': 1,\n",
       " 'maybe': 1,\n",
       " 'should': 3,\n",
       " 'patent': 1,\n",
       " 'charge': 1,\n",
       " 'royalties': 1,\n",
       " 'their': 1,\n",
       " 'existence': 1,\n",
       " 'turn': 1,\n",
       " 'believe': 1,\n",
       " 'arose': 1,\n",
       " 'earth': 6,\n",
       " 'so': 3,\n",
       " 'possible': 2,\n",
       " 'appear': 2,\n",
       " 'suitable': 1,\n",
       " 'planets': 1,\n",
       " 'seem': 2,\n",
       " 'large': 1,\n",
       " 'number': 1,\n",
       " 'galaxy': 2,\n",
       " 'don’t': 2,\n",
       " 'know': 1,\n",
       " 'appeared': 2,\n",
       " 'pieces': 1,\n",
       " 'observational': 1,\n",
       " 'evidence': 1,\n",
       " 'appearing': 2,\n",
       " 'fossils': 1,\n",
       " 'algae': 1,\n",
       " '35': 1,\n",
       " 'formed': 1,\n",
       " '46': 1,\n",
       " 'probably': 3,\n",
       " 'too': 1,\n",
       " 'hot': 1,\n",
       " 'half': 2,\n",
       " 'within': 2,\n",
       " 'short': 1,\n",
       " 'compared': 1,\n",
       " '10billionyear': 1,\n",
       " 'lifetime': 1,\n",
       " 'planet': 3,\n",
       " 'type': 1,\n",
       " 'suggests': 1,\n",
       " 'reasonably': 1,\n",
       " 'high': 1,\n",
       " 'low': 1,\n",
       " 'expected': 1,\n",
       " 'take': 1,\n",
       " 'ten': 1,\n",
       " 'available': 1,\n",
       " 'hand': 1,\n",
       " 'visited': 1,\n",
       " 'aliens': 3,\n",
       " 'am': 2,\n",
       " 'discounting': 1,\n",
       " 'reports': 2,\n",
       " 'ufos': 1,\n",
       " 'only': 3,\n",
       " 'cranks': 1,\n",
       " 'weirdos': 1,\n",
       " 'government': 1,\n",
       " 'conspiracy': 1,\n",
       " 'suppress': 1,\n",
       " 'keep': 1,\n",
       " 'scientific': 1,\n",
       " 'bring': 1,\n",
       " 'seems': 2,\n",
       " 'singularly': 1,\n",
       " 'ineffective': 1,\n",
       " 'policy': 2,\n",
       " 'far': 1,\n",
       " 'furthermore': 1,\n",
       " 'despite': 1,\n",
       " 'extensive': 1,\n",
       " 'search': 1,\n",
       " 'seti': 1,\n",
       " 'project': 1,\n",
       " 'haven’t': 1,\n",
       " 'heard': 1,\n",
       " 'any': 1,\n",
       " 'television': 1,\n",
       " 'quiz': 1,\n",
       " 'shows': 1,\n",
       " 'indicates': 1,\n",
       " 'civilizations': 1,\n",
       " 'our': 8,\n",
       " 'stage': 1,\n",
       " 'development': 1,\n",
       " 'radius': 1,\n",
       " 'few': 1,\n",
       " 'hundred': 4,\n",
       " 'light': 1,\n",
       " 'issuing': 1,\n",
       " 'insurance': 1,\n",
       " 'against': 1,\n",
       " 'abduction': 1,\n",
       " 'pretty': 1,\n",
       " 'safe': 1,\n",
       " 'bet': 1,\n",
       " 'brings': 1,\n",
       " 'me': 2,\n",
       " 'last': 2,\n",
       " 'intelligent': 1,\n",
       " 'beings': 1,\n",
       " 'make': 1,\n",
       " 'sure': 1,\n",
       " 'survive': 1,\n",
       " 'continue': 2,\n",
       " 'entering': 1,\n",
       " 'increasingly': 1,\n",
       " 'dangerous': 1,\n",
       " 'period': 1,\n",
       " 'history': 1,\n",
       " 'population': 1,\n",
       " 'use': 1,\n",
       " 'finite': 1,\n",
       " 'resources': 1,\n",
       " 'growing': 1,\n",
       " 'exponentially': 1,\n",
       " 'along': 1,\n",
       " 'technical': 1,\n",
       " 'ability': 1,\n",
       " 'change': 1,\n",
       " 'environment': 1,\n",
       " 'ill': 1,\n",
       " 'genetic': 1,\n",
       " 'code': 1,\n",
       " 'still': 1,\n",
       " 'carries': 1,\n",
       " 'selfish': 1,\n",
       " 'aggressive': 1,\n",
       " 'instincts': 1,\n",
       " 'survival': 2,\n",
       " 'advantage': 1,\n",
       " 'will': 1,\n",
       " 'difficult': 1,\n",
       " 'enough': 1,\n",
       " 'avoid': 1,\n",
       " 'disaster': 1,\n",
       " 'next': 3,\n",
       " 'let': 1,\n",
       " 'thousand': 1,\n",
       " 'million': 1,\n",
       " 'chance': 1,\n",
       " 'longterm': 1,\n",
       " 'remain': 1,\n",
       " 'inwardlooking': 1,\n",
       " 'spread': 1,\n",
       " 'answers': 2,\n",
       " 'show': 1,\n",
       " 'remarkable': 1,\n",
       " 'want': 1,\n",
       " 'beyond': 1,\n",
       " 'favor': 1,\n",
       " 'manned': 1,\n",
       " '–': 2,\n",
       " 'say': 1,\n",
       " 'personned': 1,\n",
       " 'flight': 1,\n",
       " 'my': 2,\n",
       " 'sought': 1,\n",
       " 'understand': 1,\n",
       " 'lucky': 1,\n",
       " 'disability': 1,\n",
       " 'has': 2,\n",
       " 'serious': 1,\n",
       " 'handicap': 1,\n",
       " 'indeed': 1,\n",
       " 'more': 1,\n",
       " 'people': 1,\n",
       " 'pursue': 1,\n",
       " 'quest': 1,\n",
       " 'ultimate': 1,\n",
       " 'goal': 1,\n",
       " 'complete': 1,\n",
       " 'making': 1,\n",
       " 'thank': 1,\n",
       " 'you': 1,\n",
       " 'listening': 1}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_counter = {}\n",
    "for i in text_as_list:\n",
    "    dict_counter[i] = text_as_list.count(i)\n",
    "dict_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_counter = {}\n",
    "for key, value in mydictionary.items():\n",
    "    if i:\n",
    "        dict_counter [value]=[key]\n",
    "    for i in text_as_list:\n",
    "        text_as_list.count(i)\n",
    "        n += 1\n",
    "my_enumerate(text_as_list)\n",
    "dict_counter = dict((text_as_list))\n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "i = text_as_list.count(\"question\")\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [154]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmydictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:1677\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly recognize index or columns for orient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[1;32m    667\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(mydictionary)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [153]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxies and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    if n == 1:\n",
    "        return n\n",
    "    else:\n",
    "        return n*fact(n-1)\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(fact(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <=1:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
