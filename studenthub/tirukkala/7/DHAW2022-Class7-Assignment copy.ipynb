{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe. The questions I would like to talk about are: one, where did we come from? How did the universe come into being? Are we alone in the universe? Is there alien life out there? What is the future of the human race? Up until the 1920s, everyone thought the universe was essentially static and unchanging in time. Then it was discovered that the universe was expanding. Distant galaxies were moving away from us. This meant they must have been closer together in the past. If we extrapolate back, we find we must have all been on top of each other about 15 billion years ago. This was the Big Bang, the beginning of the universe. But was there anything before the Big Bang? If not, what created the universe? Why did the universe emerge from the Big Bang the way it did? We used to think that the theory of the universe could be divided into two parts. First, there were the laws like Maxwell’s equations and general relativity that determined the evolution of the universe, given its state over all of space at one time. And second, there was no question of the initial state of the universe. We have made good progress on the first part, and now have the knowledge of the laws of evolution in all but the most extreme conditions. But until recently, we have had little idea about the initial conditions for the universe. However, this division into laws of evolution and initial conditions depends on time and space being separate and distinct. Under extreme conditions, general relativity and quantum theory allow time to behave like another dimension of space. This removes the distinction between time and space, and means the laws of evolution can also determine the initial state. The universe can spontaneously create itself out of nothing. Moreover, we can calculate a probability that the universe was created in different states. These predictions are in excellent agreement with observations by the WMAP satellite of the cosmic microwave background, which is an imprint of the very early universe. We think we have solved the mystery of creation. Maybe we should patent the universe and charge everyone royalties for their existence. I now turn to the second big question: are we alone, or is there other life in the universe? We believe that life arose spontaneously on the Earth, so it must be possible for life to appear on other suitable planets, of which there seem to be a large number in the galaxy. But we don’t know how life first appeared. We have two pieces of observational evidence on the probability of life appearing. The first is that we have fossils of algae from 3.5 billion years ago. The Earth was formed 4.6 billion years ago and was probably too hot for about the first half billion years. So life appeared on Earth within half a billion years of it being possible, which is short compared to the 10-billion-year lifetime of a planet of Earth type. This suggests that the probability of life appearing is reasonably high. If it was very low, one would have expected it to take most of the ten billion years available. On the other hand, we don’t seem to have been visited by aliens. I am discounting the reports of UFOs. Why would they appear only to cranks and weirdos? If there is a government conspiracy to suppress the reports and keep for itself the scientific knowledge the aliens bring, it seems to have been a singularly ineffective policy so far. Furthermore, despite an extensive search by the SETI project, we haven’t heard any alien television quiz shows. This probably indicates that there are no alien civilizations at our stage of development within a radius of a few hundred light years. Issuing an insurance policy against abduction by aliens seems a pretty safe bet. This brings me to the last of the big questions: the future of the human race. If we are the only intelligent beings in the galaxy, we should make sure we survive and continue. But we are entering an increasingly dangerous period of our history. Our population and our use of the finite resources of planet Earth are growing exponentially, along with our technical ability to change the environment for good or ill. But our genetic code still carries the selfish and aggressive instincts that were of survival advantage in the past. It will be difficult enough to avoid disaster in the next hundred years, let alone the next thousand or million. Our only chance of long-term survival is not to remain inward-looking on planet Earth, but to spread out into space. The answers to these big questions show that we have made remarkable progress in the last hundred years. But if we want to continue beyond the next hundred years, our future is in space. That is why I am in favor of manned – or should I say, personned – space flight. All of my life I have sought to understand the universe and find answers to these questions. I have been very lucky that my disability has not been a serious handicap. Indeed, it has probably given me more time than most people to pursue the quest for knowledge. The ultimate goal is a complete theory of the universe, and we are making good progress. Thank you for listening.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "print(f.read(50))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The questions I would like to talk about are: one, where did we come from? How did the universe come into being\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "f.read(52)\n",
    "print(f.read(111))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe.', 'The', 'questions', 'I', 'would', 'like', 'to', 'talk', 'about', 'are:', 'one,', 'where', 'did', 'we', 'come', 'from?', 'How', 'did', 'the', 'universe', 'come', 'into', 'being?', 'Are', 'we', 'alone', 'in', 'the', 'universe?', 'Is', 'there', 'alien', 'life', 'out', 'there?', 'What', 'is', 'the', 'future', 'of', 'the', 'human', 'race?', 'Up', 'until', 'the', '1920s,', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time.', 'Then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding.', 'Distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us.', 'This', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past.', 'If', 'we', 'extrapolate', 'back,', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago.', 'This', 'was', 'the', 'Big', 'Bang,', 'the', 'beginning', 'of', 'the', 'universe.', 'But', 'was', 'there', 'anything', 'before', 'the', 'Big', 'Bang?', 'If', 'not,', 'what', 'created', 'the', 'universe?', 'Why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'Big', 'Bang', 'the', 'way', 'it', 'did?', 'We', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts.', 'First,', 'there', 'were', 'the', 'laws', 'like', 'Maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe,', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time.', 'And', 'second,', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe.', 'We', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part,', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions.', 'But', 'until', 'recently,', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe.', 'However,', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct.', 'Under', 'extreme', 'conditions,', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space.', 'This', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space,', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state.', 'The', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing.', 'Moreover,', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states.', 'These', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'WMAP', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background,', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe.', 'We', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation.', 'Maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence.', 'I', 'now', 'turn', 'to', 'the', 'second', 'big', 'question:', 'are', 'we', 'alone,', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe?', 'We', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'Earth,', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets,', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy.', 'But', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared.', 'We', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing.', 'The', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '3.5', 'billion', 'years', 'ago.', 'The', 'Earth', 'was', 'formed', '4.6', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years.', 'So', 'life', 'appeared', 'on', 'Earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible,', 'which', 'is', 'short', 'compared', 'to', 'the', '10-billion-year', 'lifetime', 'of', 'a', 'planet', 'of', 'Earth', 'type.', 'This', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high.', 'If', 'it', 'was', 'very', 'low,', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available.', 'On', 'the', 'other', 'hand,', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens.', 'I', 'am', 'discounting', 'the', 'reports', 'of', 'UFOs.', 'Why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos?', 'If', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring,', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far.', 'Furthermore,', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'SETI', 'project,', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows.', 'This', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years.', 'Issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet.', 'This', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions:', 'the', 'future', 'of', 'the', 'human', 'race.', 'If', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy,', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue.', 'But', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history.', 'Our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'Earth', 'are', 'growing', 'exponentially,', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill.', 'But', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past.', 'It', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years,', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million.', 'Our', 'only', 'chance', 'of', 'long-term', 'survival', 'is', 'not', 'to', 'remain', 'inward-looking', 'on', 'planet', 'Earth,', 'but', 'to', 'spread', 'out', 'into', 'space.', 'The', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years.', 'But', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years,', 'our', 'future', 'is', 'in', 'space.', 'That', 'is', 'why', 'I', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'I', 'say,', 'personned', '–', 'space', 'flight.', 'All', 'of', 'my', 'life', 'I', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions.', 'I', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap.', 'Indeed,', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge.', 'The', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe,', 'and', 'we', 'are', 'making', 'good', 'progress.', 'Thank', 'you', 'for', 'listening.']\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "text = f.read()\n",
    "text_as_list = text.split(\" \")\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'are', 'are', 'alone', 'alien', 'and', 'away', 'all', 'about', 'ago', 'anything', 'and', 'all', 'at', 'and', 'and', 'all', 'about', 'and', 'and', 'and', 'and', 'allow', 'another', 'and', 'and', 'also', 'a', 'are', 'agreement', 'an', 'and', 'are', 'alone', 'arose', 'appear', 'a', 'appeared', 'appearing', 'algae', 'ago', 'ago', 'and', 'about', 'appeared', 'a', 'a', 'appearing', 'available', 'aliens', 'am', 'appear', 'and', 'a', 'and', 'aliens', 'a', 'an', 'any', 'alien', 'are', 'alien', 'at', 'a', 'a', 'an', 'against', 'abduction', 'aliens', 'a', 'are', 'and', 'are', 'an', 'and', 'are', 'along', 'ability', 'and', 'aggressive', 'advantage', 'avoid', 'alone', 'answers', 'am', 'all', 'and', 'answers', 'a', 'a', 'and', 'are']\n"
     ]
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "\n",
    "for words in text_as_list:\n",
    "    if words.startswith(\"a\"):\n",
    "        words_begin_with_a.append(words)\n",
    "\n",
    "print(words_begin_with_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "other_counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter+=1\n",
    "    else:\n",
    "        other_counter+=1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "print(other_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38e92923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = text_as_list.count(\"universe\")\n",
    "if a>0:\n",
    "    True\n",
    "    print(\"True\")\n",
    "else:\n",
    "    False\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does not appear\n",
      "I didn't find the words\n"
     ]
    }
   ],
   "source": [
    "a = text_as_list.count(\"alliens\")\n",
    "b = text_as_list.count(\"the word does not appear\")\n",
    "if a==0:\n",
    "    print(\"The word does not appear\")\n",
    "    if b==0:\n",
    "        print(\"I didn't find the words\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d9304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 624, 'is': 891, 'nothing': 314, 'bigger': 4, 'or': 832, 'older': 6, 'than': 879, 'the': 896, 'universe': 897, 'questions': 856, 'i': 857, 'would': 564, 'like': 281, 'to': 882, 'talk': 16, 'about': 479, 'are': 900, 'one': 529, 'where': 20, 'did': 151, 'we': 899, 'come': 29, 'from': 460, 'how': 434, 'into': 786, 'being': 497, 'alone': 762, 'in': 827, 'alien': 627, 'life': 843, 'out': 785, 'what': 135, 'future': 818, 'of': 895, 'human': 670, 'race': 671, 'up': 52, 'until': 236, '1920s': 55, 'everyone': 372, 'thought': 57, 'was': 526, 'essentially': 61, 'static': 62, 'and': 898, 'unchanging': 64, 'time': 878, 'then': 67, 'it': 872, 'discovered': 70, 'that': 862, 'expanding': 75, 'distant': 76, 'galaxies': 77, 'were': 741, 'moving': 79, 'away': 80, 'us': 82, 'this': 656, 'meant': 84, 'they': 565, 'must': 407, 'have': 858, 'been': 867, 'closer': 89, 'together': 90, 'past': 747, 'if': 807, 'extrapolate': 96, 'back': 97, 'find': 852, 'all': 840, 'on': 779, 'top': 106, 'each': 108, 'other': 545, '15': 111, 'billion': 540, 'years': 816, 'ago': 472, 'big': 792, 'bang': 147, 'beginning': 121, 'but': 806, 'anything': 128, 'before': 129, 'not': 866, 'created': 325, 'why': 824, 'emerge': 143, 'way': 149, 'used': 153, 'think': 356, 'theory': 894, 'could': 162, 'be': 750, 'divided': 164, 'two': 440, 'parts': 167, 'first': 481, 'laws': 297, 'maxwell’s': 174, 'equations': 175, 'general': 272, 'relativity': 273, 'determined': 180, 'evolution': 299, 'given': 875, 'its': 187, 'state': 305, 'over': 189, 'space': 838, 'at': 629, 'second': 382, 'no': 626, 'question': 384, 'initial': 304, 'made': 798, 'good': 902, 'progress': 903, 'part': 217, 'now': 378, 'knowledge': 887, 'most': 880, 'extreme': 270, 'conditions': 271, 'recently': 237, 'had': 240, 'little': 241, 'idea': 242, 'for': 906, 'however': 250, 'division': 252, 'depends': 260, 'separate': 266, 'distinct': 268, 'under': 269, 'quantum': 275, 'allow': 277, 'behave': 280, 'another': 282, 'dimension': 283, 'removes': 287, 'distinction': 289, 'between': 290, 'means': 295, 'can': 317, 'also': 301, 'determine': 302, 'spontaneously': 401, 'create': 310, 'itself': 585, 'moreover': 315, 'calculate': 318, 'a': 892, 'probability': 517, 'different': 327, 'states': 328, 'these': 855, 'predictions': 330, 'excellent': 333, 'agreement': 334, 'with': 717, 'observations': 336, 'by': 649, 'wmap': 339, 'satellite': 340, 'cosmic': 343, 'microwave': 344, 'background': 345, 'which': 499, 'an': 694, 'imprint': 349, 'very': 860, 'early': 353, 'solved': 359, 'mystery': 361, 'creation': 363, 'maybe': 364, 'should': 833, 'patent': 367, 'charge': 371, 'royalties': 373, 'their': 375, 'existence': 376, 'turn': 379, 'believe': 397, 'arose': 400, 'earth': 781, 'so': 601, 'possible': 498, 'appear': 566, 'suitable': 416, 'planets': 417, 'seem': 549, 'large': 425, 'number': 426, 'galaxy': 681, 'don’t': 548, 'know': 433, 'appeared': 487, 'pieces': 441, 'observational': 443, 'evidence': 444, 'appearing': 520, 'fossils': 457, 'algae': 459, '35': 461, 'formed': 468, '46': 469, 'probably': 874, 'too': 476, 'hot': 477, 'half': 491, 'within': 634, 'short': 501, 'compared': 502, '10billionyear': 505, 'lifetime': 506, 'planet': 780, 'type': 512, 'suggests': 514, 'reasonably': 522, 'high': 523, 'low': 528, 'expected': 532, 'take': 535, 'ten': 539, 'available': 542, 'hand': 546, 'visited': 553, 'aliens': 650, 'am': 826, 'discounting': 558, 'reports': 581, 'ufos': 562, 'only': 769, 'cranks': 569, 'weirdos': 571, 'government': 576, 'conspiracy': 577, 'suppress': 579, 'keep': 583, 'scientific': 587, 'bring': 591, 'seems': 651, 'singularly': 598, 'ineffective': 599, 'policy': 646, 'far': 602, 'furthermore': 603, 'despite': 604, 'extensive': 606, 'search': 607, 'seti': 610, 'project': 611, 'haven’t': 613, 'heard': 614, 'any': 615, 'television': 617, 'quiz': 618, 'shows': 619, 'indicates': 622, 'civilizations': 628, 'our': 817, 'stage': 631, 'development': 633, 'radius': 636, 'few': 639, 'hundred': 815, 'light': 641, 'issuing': 643, 'insurance': 645, 'against': 647, 'abduction': 648, 'pretty': 653, 'safe': 654, 'bet': 655, 'brings': 657, 'me': 876, 'last': 803, 'intelligent': 677, 'beings': 678, 'make': 684, 'sure': 685, 'survive': 687, 'continue': 811, 'entering': 693, 'increasingly': 695, 'dangerous': 696, 'period': 697, 'history': 700, 'population': 702, 'use': 705, 'finite': 708, 'resources': 709, 'growing': 714, 'exponentially': 715, 'along': 716, 'technical': 719, 'ability': 720, 'change': 722, 'environment': 724, 'ill': 728, 'genetic': 731, 'code': 732, 'still': 733, 'carries': 734, 'selfish': 736, 'aggressive': 738, 'instincts': 739, 'survival': 773, 'advantage': 744, 'will': 749, 'difficult': 751, 'enough': 752, 'avoid': 754, 'disaster': 755, 'next': 814, 'let': 761, 'thousand': 765, 'million': 767, 'chance': 770, 'longterm': 772, 'remain': 777, 'inwardlooking': 778, 'spread': 784, 'answers': 853, 'show': 794, 'remarkable': 799, 'want': 809, 'beyond': 812, 'favor': 828, 'manned': 830, '–': 837, 'say': 835, 'personned': 836, 'flight': 839, 'my': 863, 'sought': 846, 'understand': 848, 'lucky': 861, 'disability': 864, 'has': 873, 'serious': 869, 'handicap': 870, 'indeed': 871, 'more': 877, 'people': 881, 'pursue': 883, 'quest': 885, 'ultimate': 889, 'goal': 890, 'complete': 893, 'making': 901, 'thank': 904, 'you': 905, 'listening': 907}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "a = 1\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[i] = a\n",
    "    a+=1\n",
    "    \n",
    "    \n",
    "print(dic)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'there', 2: 'is', 3: 'nothing', 4: 'bigger', 5: 'or', 6: 'older', 7: 'than', 8: 'the', 9: 'universe', 10: 'the', 11: 'questions', 12: 'i', 13: 'would', 14: 'like', 15: 'to', 16: 'talk', 17: 'about', 18: 'are', 19: 'one', 20: 'where', 21: 'did', 22: 'we', 23: 'come', 24: 'from', 25: 'how', 26: 'did', 27: 'the', 28: 'universe', 29: 'come', 30: 'into', 31: 'being', 32: 'are', 33: 'we', 34: 'alone', 35: 'in', 36: 'the', 37: 'universe', 38: 'is', 39: 'there', 40: 'alien', 41: 'life', 42: 'out', 43: 'there', 44: 'what', 45: 'is', 46: 'the', 47: 'future', 48: 'of', 49: 'the', 50: 'human', 51: 'race', 52: 'up', 53: 'until', 54: 'the', 55: '1920s', 56: 'everyone', 57: 'thought', 58: 'the', 59: 'universe', 60: 'was', 61: 'essentially', 62: 'static', 63: 'and', 64: 'unchanging', 65: 'in', 66: 'time', 67: 'then', 68: 'it', 69: 'was', 70: 'discovered', 71: 'that', 72: 'the', 73: 'universe', 74: 'was', 75: 'expanding', 76: 'distant', 77: 'galaxies', 78: 'were', 79: 'moving', 80: 'away', 81: 'from', 82: 'us', 83: 'this', 84: 'meant', 85: 'they', 86: 'must', 87: 'have', 88: 'been', 89: 'closer', 90: 'together', 91: 'in', 92: 'the', 93: 'past', 94: 'if', 95: 'we', 96: 'extrapolate', 97: 'back', 98: 'we', 99: 'find', 100: 'we', 101: 'must', 102: 'have', 103: 'all', 104: 'been', 105: 'on', 106: 'top', 107: 'of', 108: 'each', 109: 'other', 110: 'about', 111: '15', 112: 'billion', 113: 'years', 114: 'ago', 115: 'this', 116: 'was', 117: 'the', 118: 'big', 119: 'bang', 120: 'the', 121: 'beginning', 122: 'of', 123: 'the', 124: 'universe', 125: 'but', 126: 'was', 127: 'there', 128: 'anything', 129: 'before', 130: 'the', 131: 'big', 132: 'bang', 133: 'if', 134: 'not', 135: 'what', 136: 'created', 137: 'the', 138: 'universe', 139: 'why', 140: 'did', 141: 'the', 142: 'universe', 143: 'emerge', 144: 'from', 145: 'the', 146: 'big', 147: 'bang', 148: 'the', 149: 'way', 150: 'it', 151: 'did', 152: 'we', 153: 'used', 154: 'to', 155: 'think', 156: 'that', 157: 'the', 158: 'theory', 159: 'of', 160: 'the', 161: 'universe', 162: 'could', 163: 'be', 164: 'divided', 165: 'into', 166: 'two', 167: 'parts', 168: 'first', 169: 'there', 170: 'were', 171: 'the', 172: 'laws', 173: 'like', 174: 'maxwell’s', 175: 'equations', 176: 'and', 177: 'general', 178: 'relativity', 179: 'that', 180: 'determined', 181: 'the', 182: 'evolution', 183: 'of', 184: 'the', 185: 'universe', 186: 'given', 187: 'its', 188: 'state', 189: 'over', 190: 'all', 191: 'of', 192: 'space', 193: 'at', 194: 'one', 195: 'time', 196: 'and', 197: 'second', 198: 'there', 199: 'was', 200: 'no', 201: 'question', 202: 'of', 203: 'the', 204: 'initial', 205: 'state', 206: 'of', 207: 'the', 208: 'universe', 209: 'we', 210: 'have', 211: 'made', 212: 'good', 213: 'progress', 214: 'on', 215: 'the', 216: 'first', 217: 'part', 218: 'and', 219: 'now', 220: 'have', 221: 'the', 222: 'knowledge', 223: 'of', 224: 'the', 225: 'laws', 226: 'of', 227: 'evolution', 228: 'in', 229: 'all', 230: 'but', 231: 'the', 232: 'most', 233: 'extreme', 234: 'conditions', 235: 'but', 236: 'until', 237: 'recently', 238: 'we', 239: 'have', 240: 'had', 241: 'little', 242: 'idea', 243: 'about', 244: 'the', 245: 'initial', 246: 'conditions', 247: 'for', 248: 'the', 249: 'universe', 250: 'however', 251: 'this', 252: 'division', 253: 'into', 254: 'laws', 255: 'of', 256: 'evolution', 257: 'and', 258: 'initial', 259: 'conditions', 260: 'depends', 261: 'on', 262: 'time', 263: 'and', 264: 'space', 265: 'being', 266: 'separate', 267: 'and', 268: 'distinct', 269: 'under', 270: 'extreme', 271: 'conditions', 272: 'general', 273: 'relativity', 274: 'and', 275: 'quantum', 276: 'theory', 277: 'allow', 278: 'time', 279: 'to', 280: 'behave', 281: 'like', 282: 'another', 283: 'dimension', 284: 'of', 285: 'space', 286: 'this', 287: 'removes', 288: 'the', 289: 'distinction', 290: 'between', 291: 'time', 292: 'and', 293: 'space', 294: 'and', 295: 'means', 296: 'the', 297: 'laws', 298: 'of', 299: 'evolution', 300: 'can', 301: 'also', 302: 'determine', 303: 'the', 304: 'initial', 305: 'state', 306: 'the', 307: 'universe', 308: 'can', 309: 'spontaneously', 310: 'create', 311: 'itself', 312: 'out', 313: 'of', 314: 'nothing', 315: 'moreover', 316: 'we', 317: 'can', 318: 'calculate', 319: 'a', 320: 'probability', 321: 'that', 322: 'the', 323: 'universe', 324: 'was', 325: 'created', 326: 'in', 327: 'different', 328: 'states', 329: 'these', 330: 'predictions', 331: 'are', 332: 'in', 333: 'excellent', 334: 'agreement', 335: 'with', 336: 'observations', 337: 'by', 338: 'the', 339: 'wmap', 340: 'satellite', 341: 'of', 342: 'the', 343: 'cosmic', 344: 'microwave', 345: 'background', 346: 'which', 347: 'is', 348: 'an', 349: 'imprint', 350: 'of', 351: 'the', 352: 'very', 353: 'early', 354: 'universe', 355: 'we', 356: 'think', 357: 'we', 358: 'have', 359: 'solved', 360: 'the', 361: 'mystery', 362: 'of', 363: 'creation', 364: 'maybe', 365: 'we', 366: 'should', 367: 'patent', 368: 'the', 369: 'universe', 370: 'and', 371: 'charge', 372: 'everyone', 373: 'royalties', 374: 'for', 375: 'their', 376: 'existence', 377: 'i', 378: 'now', 379: 'turn', 380: 'to', 381: 'the', 382: 'second', 383: 'big', 384: 'question', 385: 'are', 386: 'we', 387: 'alone', 388: 'or', 389: 'is', 390: 'there', 391: 'other', 392: 'life', 393: 'in', 394: 'the', 395: 'universe', 396: 'we', 397: 'believe', 398: 'that', 399: 'life', 400: 'arose', 401: 'spontaneously', 402: 'on', 403: 'the', 404: 'earth', 405: 'so', 406: 'it', 407: 'must', 408: 'be', 409: 'possible', 410: 'for', 411: 'life', 412: 'to', 413: 'appear', 414: 'on', 415: 'other', 416: 'suitable', 417: 'planets', 418: 'of', 419: 'which', 420: 'there', 421: 'seem', 422: 'to', 423: 'be', 424: 'a', 425: 'large', 426: 'number', 427: 'in', 428: 'the', 429: 'galaxy', 430: 'but', 431: 'we', 432: 'don’t', 433: 'know', 434: 'how', 435: 'life', 436: 'first', 437: 'appeared', 438: 'we', 439: 'have', 440: 'two', 441: 'pieces', 442: 'of', 443: 'observational', 444: 'evidence', 445: 'on', 446: 'the', 447: 'probability', 448: 'of', 449: 'life', 450: 'appearing', 451: 'the', 452: 'first', 453: 'is', 454: 'that', 455: 'we', 456: 'have', 457: 'fossils', 458: 'of', 459: 'algae', 460: 'from', 461: '35', 462: 'billion', 463: 'years', 464: 'ago', 465: 'the', 466: 'earth', 467: 'was', 468: 'formed', 469: '46', 470: 'billion', 471: 'years', 472: 'ago', 473: 'and', 474: 'was', 475: 'probably', 476: 'too', 477: 'hot', 478: 'for', 479: 'about', 480: 'the', 481: 'first', 482: 'half', 483: 'billion', 484: 'years', 485: 'so', 486: 'life', 487: 'appeared', 488: 'on', 489: 'earth', 490: 'within', 491: 'half', 492: 'a', 493: 'billion', 494: 'years', 495: 'of', 496: 'it', 497: 'being', 498: 'possible', 499: 'which', 500: 'is', 501: 'short', 502: 'compared', 503: 'to', 504: 'the', 505: '10billionyear', 506: 'lifetime', 507: 'of', 508: 'a', 509: 'planet', 510: 'of', 511: 'earth', 512: 'type', 513: 'this', 514: 'suggests', 515: 'that', 516: 'the', 517: 'probability', 518: 'of', 519: 'life', 520: 'appearing', 521: 'is', 522: 'reasonably', 523: 'high', 524: 'if', 525: 'it', 526: 'was', 527: 'very', 528: 'low', 529: 'one', 530: 'would', 531: 'have', 532: 'expected', 533: 'it', 534: 'to', 535: 'take', 536: 'most', 537: 'of', 538: 'the', 539: 'ten', 540: 'billion', 541: 'years', 542: 'available', 543: 'on', 544: 'the', 545: 'other', 546: 'hand', 547: 'we', 548: 'don’t', 549: 'seem', 550: 'to', 551: 'have', 552: 'been', 553: 'visited', 554: 'by', 555: 'aliens', 556: 'i', 557: 'am', 558: 'discounting', 559: 'the', 560: 'reports', 561: 'of', 562: 'ufos', 563: 'why', 564: 'would', 565: 'they', 566: 'appear', 567: 'only', 568: 'to', 569: 'cranks', 570: 'and', 571: 'weirdos', 572: 'if', 573: 'there', 574: 'is', 575: 'a', 576: 'government', 577: 'conspiracy', 578: 'to', 579: 'suppress', 580: 'the', 581: 'reports', 582: 'and', 583: 'keep', 584: 'for', 585: 'itself', 586: 'the', 587: 'scientific', 588: 'knowledge', 589: 'the', 590: 'aliens', 591: 'bring', 592: 'it', 593: 'seems', 594: 'to', 595: 'have', 596: 'been', 597: 'a', 598: 'singularly', 599: 'ineffective', 600: 'policy', 601: 'so', 602: 'far', 603: 'furthermore', 604: 'despite', 605: 'an', 606: 'extensive', 607: 'search', 608: 'by', 609: 'the', 610: 'seti', 611: 'project', 612: 'we', 613: 'haven’t', 614: 'heard', 615: 'any', 616: 'alien', 617: 'television', 618: 'quiz', 619: 'shows', 620: 'this', 621: 'probably', 622: 'indicates', 623: 'that', 624: 'there', 625: 'are', 626: 'no', 627: 'alien', 628: 'civilizations', 629: 'at', 630: 'our', 631: 'stage', 632: 'of', 633: 'development', 634: 'within', 635: 'a', 636: 'radius', 637: 'of', 638: 'a', 639: 'few', 640: 'hundred', 641: 'light', 642: 'years', 643: 'issuing', 644: 'an', 645: 'insurance', 646: 'policy', 647: 'against', 648: 'abduction', 649: 'by', 650: 'aliens', 651: 'seems', 652: 'a', 653: 'pretty', 654: 'safe', 655: 'bet', 656: 'this', 657: 'brings', 658: 'me', 659: 'to', 660: 'the', 661: 'last', 662: 'of', 663: 'the', 664: 'big', 665: 'questions', 666: 'the', 667: 'future', 668: 'of', 669: 'the', 670: 'human', 671: 'race', 672: 'if', 673: 'we', 674: 'are', 675: 'the', 676: 'only', 677: 'intelligent', 678: 'beings', 679: 'in', 680: 'the', 681: 'galaxy', 682: 'we', 683: 'should', 684: 'make', 685: 'sure', 686: 'we', 687: 'survive', 688: 'and', 689: 'continue', 690: 'but', 691: 'we', 692: 'are', 693: 'entering', 694: 'an', 695: 'increasingly', 696: 'dangerous', 697: 'period', 698: 'of', 699: 'our', 700: 'history', 701: 'our', 702: 'population', 703: 'and', 704: 'our', 705: 'use', 706: 'of', 707: 'the', 708: 'finite', 709: 'resources', 710: 'of', 711: 'planet', 712: 'earth', 713: 'are', 714: 'growing', 715: 'exponentially', 716: 'along', 717: 'with', 718: 'our', 719: 'technical', 720: 'ability', 721: 'to', 722: 'change', 723: 'the', 724: 'environment', 725: 'for', 726: 'good', 727: 'or', 728: 'ill', 729: 'but', 730: 'our', 731: 'genetic', 732: 'code', 733: 'still', 734: 'carries', 735: 'the', 736: 'selfish', 737: 'and', 738: 'aggressive', 739: 'instincts', 740: 'that', 741: 'were', 742: 'of', 743: 'survival', 744: 'advantage', 745: 'in', 746: 'the', 747: 'past', 748: 'it', 749: 'will', 750: 'be', 751: 'difficult', 752: 'enough', 753: 'to', 754: 'avoid', 755: 'disaster', 756: 'in', 757: 'the', 758: 'next', 759: 'hundred', 760: 'years', 761: 'let', 762: 'alone', 763: 'the', 764: 'next', 765: 'thousand', 766: 'or', 767: 'million', 768: 'our', 769: 'only', 770: 'chance', 771: 'of', 772: 'longterm', 773: 'survival', 774: 'is', 775: 'not', 776: 'to', 777: 'remain', 778: 'inwardlooking', 779: 'on', 780: 'planet', 781: 'earth', 782: 'but', 783: 'to', 784: 'spread', 785: 'out', 786: 'into', 787: 'space', 788: 'the', 789: 'answers', 790: 'to', 791: 'these', 792: 'big', 793: 'questions', 794: 'show', 795: 'that', 796: 'we', 797: 'have', 798: 'made', 799: 'remarkable', 800: 'progress', 801: 'in', 802: 'the', 803: 'last', 804: 'hundred', 805: 'years', 806: 'but', 807: 'if', 808: 'we', 809: 'want', 810: 'to', 811: 'continue', 812: 'beyond', 813: 'the', 814: 'next', 815: 'hundred', 816: 'years', 817: 'our', 818: 'future', 819: 'is', 820: 'in', 821: 'space', 822: 'that', 823: 'is', 824: 'why', 825: 'i', 826: 'am', 827: 'in', 828: 'favor', 829: 'of', 830: 'manned', 831: '–', 832: 'or', 833: 'should', 834: 'i', 835: 'say', 836: 'personned', 837: '–', 838: 'space', 839: 'flight', 840: 'all', 841: 'of', 842: 'my', 843: 'life', 844: 'i', 845: 'have', 846: 'sought', 847: 'to', 848: 'understand', 849: 'the', 850: 'universe', 851: 'and', 852: 'find', 853: 'answers', 854: 'to', 855: 'these', 856: 'questions', 857: 'i', 858: 'have', 859: 'been', 860: 'very', 861: 'lucky', 862: 'that', 863: 'my', 864: 'disability', 865: 'has', 866: 'not', 867: 'been', 868: 'a', 869: 'serious', 870: 'handicap', 871: 'indeed', 872: 'it', 873: 'has', 874: 'probably', 875: 'given', 876: 'me', 877: 'more', 878: 'time', 879: 'than', 880: 'most', 881: 'people', 882: 'to', 883: 'pursue', 884: 'the', 885: 'quest', 886: 'for', 887: 'knowledge', 888: 'the', 889: 'ultimate', 890: 'goal', 891: 'is', 892: 'a', 893: 'complete', 894: 'theory', 895: 'of', 896: 'the', 897: 'universe', 898: 'and', 899: 'we', 900: 'are', 901: 'making', 902: 'good', 903: 'progress', 904: 'thank', 905: 'you', 906: 'for', 907: 'listening'}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "a = 1\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[a] = i\n",
    "    a+=1\n",
    "    \n",
    "    \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c902a269",
   "metadata": {},
   "source": [
    "#### Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 10, 'is': 13, 'nothing': 2, 'bigger': 1, 'or': 5, 'older': 1, 'than': 2, 'the': 77, 'universe': 19, 'questions': 4, 'i': 7, 'would': 3, 'like': 3, 'to': 22, 'talk': 1, 'about': 4, 'are': 9, 'one': 3, 'where': 1, 'did': 4, 'we': 26, 'come': 2, 'from': 4, 'how': 2, 'into': 4, 'being': 3, 'alone': 3, 'in': 14, 'alien': 3, 'life': 9, 'out': 3, 'what': 2, 'future': 3, 'of': 39, 'human': 2, 'race': 2, 'up': 1, 'until': 2, '1920s': 1, 'everyone': 2, 'thought': 1, 'was': 10, 'essentially': 1, 'static': 1, 'and': 19, 'unchanging': 1, 'time': 6, 'then': 1, 'it': 9, 'discovered': 1, 'that': 12, 'expanding': 1, 'distant': 1, 'galaxies': 1, 'were': 3, 'moving': 1, 'away': 1, 'us': 1, 'this': 7, 'meant': 1, 'they': 2, 'must': 3, 'have': 14, 'been': 6, 'closer': 1, 'together': 1, 'past': 2, 'if': 6, 'extrapolate': 1, 'back': 1, 'find': 2, 'all': 4, 'on': 9, 'top': 1, 'each': 1, 'other': 4, '15': 1, 'billion': 6, 'years': 10, 'ago': 3, 'big': 6, 'bang': 3, 'beginning': 1, 'but': 8, 'anything': 1, 'before': 1, 'not': 3, 'created': 2, 'why': 3, 'emerge': 1, 'way': 1, 'used': 1, 'think': 2, 'theory': 3, 'could': 1, 'be': 4, 'divided': 1, 'two': 2, 'parts': 1, 'first': 5, 'laws': 4, 'maxwell’s': 1, 'equations': 1, 'general': 2, 'relativity': 2, 'determined': 1, 'evolution': 4, 'given': 2, 'its': 1, 'state': 3, 'over': 1, 'space': 7, 'at': 2, 'second': 2, 'no': 2, 'question': 2, 'initial': 4, 'made': 2, 'good': 3, 'progress': 3, 'part': 1, 'now': 2, 'knowledge': 3, 'most': 3, 'extreme': 2, 'conditions': 4, 'recently': 1, 'had': 1, 'little': 1, 'idea': 1, 'for': 8, 'however': 1, 'division': 1, 'depends': 1, 'separate': 1, 'distinct': 1, 'under': 1, 'quantum': 1, 'allow': 1, 'behave': 1, 'another': 1, 'dimension': 1, 'removes': 1, 'distinction': 1, 'between': 1, 'means': 1, 'can': 3, 'also': 1, 'determine': 1, 'spontaneously': 2, 'create': 1, 'itself': 2, 'moreover': 1, 'calculate': 1, 'a': 11, 'probability': 3, 'different': 1, 'states': 1, 'these': 3, 'predictions': 1, 'excellent': 1, 'agreement': 1, 'with': 2, 'observations': 1, 'by': 4, 'wmap': 1, 'satellite': 1, 'cosmic': 1, 'microwave': 1, 'background': 1, 'which': 3, 'an': 4, 'imprint': 1, 'very': 3, 'early': 1, 'solved': 1, 'mystery': 1, 'creation': 1, 'maybe': 1, 'should': 3, 'patent': 1, 'charge': 1, 'royalties': 1, 'their': 1, 'existence': 1, 'turn': 1, 'believe': 1, 'arose': 1, 'earth': 6, 'so': 3, 'possible': 2, 'appear': 2, 'suitable': 1, 'planets': 1, 'seem': 2, 'large': 1, 'number': 1, 'galaxy': 2, 'don’t': 2, 'know': 1, 'appeared': 2, 'pieces': 1, 'observational': 1, 'evidence': 1, 'appearing': 2, 'fossils': 1, 'algae': 1, '35': 1, 'formed': 1, '46': 1, 'probably': 3, 'too': 1, 'hot': 1, 'half': 2, 'within': 2, 'short': 1, 'compared': 1, '10billionyear': 1, 'lifetime': 1, 'planet': 3, 'type': 1, 'suggests': 1, 'reasonably': 1, 'high': 1, 'low': 1, 'expected': 1, 'take': 1, 'ten': 1, 'available': 1, 'hand': 1, 'visited': 1, 'aliens': 3, 'am': 2, 'discounting': 1, 'reports': 2, 'ufos': 1, 'only': 3, 'cranks': 1, 'weirdos': 1, 'government': 1, 'conspiracy': 1, 'suppress': 1, 'keep': 1, 'scientific': 1, 'bring': 1, 'seems': 2, 'singularly': 1, 'ineffective': 1, 'policy': 2, 'far': 1, 'furthermore': 1, 'despite': 1, 'extensive': 1, 'search': 1, 'seti': 1, 'project': 1, 'haven’t': 1, 'heard': 1, 'any': 1, 'television': 1, 'quiz': 1, 'shows': 1, 'indicates': 1, 'civilizations': 1, 'our': 8, 'stage': 1, 'development': 1, 'radius': 1, 'few': 1, 'hundred': 4, 'light': 1, 'issuing': 1, 'insurance': 1, 'against': 1, 'abduction': 1, 'pretty': 1, 'safe': 1, 'bet': 1, 'brings': 1, 'me': 2, 'last': 2, 'intelligent': 1, 'beings': 1, 'make': 1, 'sure': 1, 'survive': 1, 'continue': 2, 'entering': 1, 'increasingly': 1, 'dangerous': 1, 'period': 1, 'history': 1, 'population': 1, 'use': 1, 'finite': 1, 'resources': 1, 'growing': 1, 'exponentially': 1, 'along': 1, 'technical': 1, 'ability': 1, 'change': 1, 'environment': 1, 'ill': 1, 'genetic': 1, 'code': 1, 'still': 1, 'carries': 1, 'selfish': 1, 'aggressive': 1, 'instincts': 1, 'survival': 2, 'advantage': 1, 'will': 1, 'difficult': 1, 'enough': 1, 'avoid': 1, 'disaster': 1, 'next': 3, 'let': 1, 'thousand': 1, 'million': 1, 'chance': 1, 'longterm': 1, 'remain': 1, 'inwardlooking': 1, 'spread': 1, 'answers': 2, 'show': 1, 'remarkable': 1, 'want': 1, 'beyond': 1, 'favor': 1, 'manned': 1, '–': 2, 'say': 1, 'personned': 1, 'flight': 1, 'my': 2, 'sought': 1, 'understand': 1, 'lucky': 1, 'disability': 1, 'has': 2, 'serious': 1, 'handicap': 1, 'indeed': 1, 'more': 1, 'people': 1, 'pursue': 1, 'quest': 1, 'ultimate': 1, 'goal': 1, 'complete': 1, 'making': 1, 'thank': 1, 'you': 1, 'listening': 1}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[i] = text_as_list.count(i)\n",
    "    \n",
    "    \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbfd1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 10, 'is': 13, 'nothing': 2, 'bigger': 1, 'or': 5, 'older': 1, 'than': 2, 'the': 77, 'universe': 19, 'questions': 4, 'i': 7, 'would': 3, 'like': 3, 'to': 22, 'talk': 1, 'about': 4, 'are': 9, 'one': 3, 'where': 1, 'did': 4, 'we': 26, 'come': 2, 'from': 4, 'how': 2, 'into': 4, 'being': 3, 'alone': 3, 'in': 14, 'alien': 3, 'life': 9, 'out': 3, 'what': 2, 'future': 3, 'of': 39, 'human': 2, 'race': 2, 'up': 1, 'until': 2, '1920s': 1, 'everyone': 2, 'thought': 1, 'was': 10, 'essentially': 1, 'static': 1, 'and': 19, 'unchanging': 1, 'time': 6, 'then': 1, 'it': 9, 'discovered': 1, 'that': 12, 'expanding': 1, 'distant': 1, 'galaxies': 1, 'were': 3, 'moving': 1, 'away': 1, 'us': 1, 'this': 7, 'meant': 1, 'they': 2, 'must': 3, 'have': 14, 'been': 6, 'closer': 1, 'together': 1, 'past': 2, 'if': 6, 'extrapolate': 1, 'back': 1, 'find': 2, 'all': 4, 'on': 9, 'top': 1, 'each': 1, 'other': 4, '15': 1, 'billion': 6, 'years': 10, 'ago': 3, 'big': 6, 'bang': 3, 'beginning': 1, 'but': 8, 'anything': 1, 'before': 1, 'not': 3, 'created': 2, 'why': 3, 'emerge': 1, 'way': 1, 'used': 1, 'think': 2, 'theory': 3, 'could': 1, 'be': 4, 'divided': 1, 'two': 2, 'parts': 1, 'first': 5, 'laws': 4, 'maxwell’s': 1, 'equations': 1, 'general': 2, 'relativity': 2, 'determined': 1, 'evolution': 4, 'given': 2, 'its': 1, 'state': 3, 'over': 1, 'space': 7, 'at': 2, 'second': 2, 'no': 2, 'question': 2, 'initial': 4, 'made': 2, 'good': 3, 'progress': 3, 'part': 1, 'now': 2, 'knowledge': 3, 'most': 3, 'extreme': 2, 'conditions': 4, 'recently': 1, 'had': 1, 'little': 1, 'idea': 1, 'for': 8, 'however': 1, 'division': 1, 'depends': 1, 'separate': 1, 'distinct': 1, 'under': 1, 'quantum': 1, 'allow': 1, 'behave': 1, 'another': 1, 'dimension': 1, 'removes': 1, 'distinction': 1, 'between': 1, 'means': 1, 'can': 3, 'also': 1, 'determine': 1, 'spontaneously': 2, 'create': 1, 'itself': 2, 'moreover': 1, 'calculate': 1, 'a': 11, 'probability': 3, 'different': 1, 'states': 1, 'these': 3, 'predictions': 1, 'excellent': 1, 'agreement': 1, 'with': 2, 'observations': 1, 'by': 4, 'wmap': 1, 'satellite': 1, 'cosmic': 1, 'microwave': 1, 'background': 1, 'which': 3, 'an': 4, 'imprint': 1, 'very': 3, 'early': 1, 'solved': 1, 'mystery': 1, 'creation': 1, 'maybe': 1, 'should': 3, 'patent': 1, 'charge': 1, 'royalties': 1, 'their': 1, 'existence': 1, 'turn': 1, 'believe': 1, 'arose': 1, 'earth': 6, 'so': 3, 'possible': 2, 'appear': 2, 'suitable': 1, 'planets': 1, 'seem': 2, 'large': 1, 'number': 1, 'galaxy': 2, 'don’t': 2, 'know': 1, 'appeared': 2, 'pieces': 1, 'observational': 1, 'evidence': 1, 'appearing': 2, 'fossils': 1, 'algae': 1, '35': 1, 'formed': 1, '46': 1, 'probably': 3, 'too': 1, 'hot': 1, 'half': 2, 'within': 2, 'short': 1, 'compared': 1, '10billionyear': 1, 'lifetime': 1, 'planet': 3, 'type': 1, 'suggests': 1, 'reasonably': 1, 'high': 1, 'low': 1, 'expected': 1, 'take': 1, 'ten': 1, 'available': 1, 'hand': 1, 'visited': 1, 'aliens': 3, 'am': 2, 'discounting': 1, 'reports': 2, 'ufos': 1, 'only': 3, 'cranks': 1, 'weirdos': 1, 'government': 1, 'conspiracy': 1, 'suppress': 1, 'keep': 1, 'scientific': 1, 'bring': 1, 'seems': 2, 'singularly': 1, 'ineffective': 1, 'policy': 2, 'far': 1, 'furthermore': 1, 'despite': 1, 'extensive': 1, 'search': 1, 'seti': 1, 'project': 1, 'haven’t': 1, 'heard': 1, 'any': 1, 'television': 1, 'quiz': 1, 'shows': 1, 'indicates': 1, 'civilizations': 1, 'our': 8, 'stage': 1, 'development': 1, 'radius': 1, 'few': 1, 'hundred': 4, 'light': 1, 'issuing': 1, 'insurance': 1, 'against': 1, 'abduction': 1, 'pretty': 1, 'safe': 1, 'bet': 1, 'brings': 1, 'me': 2, 'last': 2, 'intelligent': 1, 'beings': 1, 'make': 1, 'sure': 1, 'survive': 1, 'continue': 2, 'entering': 1, 'increasingly': 1, 'dangerous': 1, 'period': 1, 'history': 1, 'population': 1, 'use': 1, 'finite': 1, 'resources': 1, 'growing': 1, 'exponentially': 1, 'along': 1, 'technical': 1, 'ability': 1, 'change': 1, 'environment': 1, 'ill': 1, 'genetic': 1, 'code': 1, 'still': 1, 'carries': 1, 'selfish': 1, 'aggressive': 1, 'instincts': 1, 'survival': 2, 'advantage': 1, 'will': 1, 'difficult': 1, 'enough': 1, 'avoid': 1, 'disaster': 1, 'next': 3, 'let': 1, 'thousand': 1, 'million': 1, 'chance': 1, 'longterm': 1, 'remain': 1, 'inwardlooking': 1, 'spread': 1, 'answers': 2, 'show': 1, 'remarkable': 1, 'want': 1, 'beyond': 1, 'favor': 1, 'manned': 1, '–': 2, 'say': 1, 'personned': 1, 'flight': 1, 'my': 2, 'sought': 1, 'understand': 1, 'lucky': 1, 'disability': 1, 'has': 2, 'serious': 1, 'handicap': 1, 'indeed': 1, 'more': 1, 'people': 1, 'pursue': 1, 'quest': 1, 'ultimate': 1, 'goal': 1, 'complete': 1, 'making': 1, 'thank': 1, 'you': 1, 'listening': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(dic[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[1;32m    667\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(dic)\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxies and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    if n==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * fact(n-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(fact(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if (n<=1):\n",
    "        return n\n",
    "    return fib (n-2) + fib(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
