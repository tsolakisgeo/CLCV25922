{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e8fff",
   "metadata": {},
   "source": [
    "#### Open and read the file `Hawking-Questioning-the-Universe.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b90bb97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe. The questions I would like to talk about are: one, where did we come from? How did the universe come into being? Are we alone in the universe? Is there alien life out there? What is the future of the human race? Up until the 1920s, everyone thought the universe was essentially static and unchanging in time. Then it was discovered that the universe was expanding. Distant galaxies were moving away from us. This meant they must have been closer together in the past. If we extrapolate back, we find we must have all been on top of each other about 15 billion years ago. This was the Big Bang, the beginning of the universe. But was there anything before the Big Bang? If not, what created the universe? Why did the universe emerge from the Big Bang the way it did? We used to think that the theory of the universe could be divided into two parts. First, there were the laws like Maxwell’s equations and general relativity that determined the evolution of the universe, given its state over all of space at one time. And second, there was no question of the initial state of the universe. We have made good progress on the first part, and now have the knowledge of the laws of evolution in all but the most extreme conditions. But until recently, we have had little idea about the initial conditions for the universe. However, this division into laws of evolution and initial conditions depends on time and space being separate and distinct. Under extreme conditions, general relativity and quantum theory allow time to behave like another dimension of space. This removes the distinction between time and space, and means the laws of evolution can also determine the initial state. The universe can spontaneously create itself out of nothing. Moreover, we can calculate a probability that the universe was created in different states. These predictions are in excellent agreement with observations by the WMAP satellite of the cosmic microwave background, which is an imprint of the very early universe. We think we have solved the mystery of creation. Maybe we should patent the universe and charge everyone royalties for their existence. I now turn to the second big question: are we alone, or is there other life in the universe? We believe that life arose spontaneously on the Earth, so it must be possible for life to appear on other suitable planets, of which there seem to be a large number in the galaxy. But we don’t know how life first appeared. We have two pieces of observational evidence on the probability of life appearing. The first is that we have fossils of algae from 3.5 billion years ago. The Earth was formed 4.6 billion years ago and was probably too hot for about the first half billion years. So life appeared on Earth within half a billion years of it being possible, which is short compared to the 10-billion-year lifetime of a planet of Earth type. This suggests that the probability of life appearing is reasonably high. If it was very low, one would have expected it to take most of the ten billion years available. On the other hand, we don’t seem to have been visited by aliens. I am discounting the reports of UFOs. Why would they appear only to cranks and weirdos? If there is a government conspiracy to suppress the reports and keep for itself the scientific knowledge the aliens bring, it seems to have been a singularly ineffective policy so far. Furthermore, despite an extensive search by the SETI project, we haven’t heard any alien television quiz shows. This probably indicates that there are no alien civilizations at our stage of development within a radius of a few hundred light years. Issuing an insurance policy against abduction by aliens seems a pretty safe bet. This brings me to the last of the big questions: the future of the human race. If we are the only intelligent beings in the galaxy, we should make sure we survive and continue. But we are entering an increasingly dangerous period of our history. Our population and our use of the finite resources of planet Earth are growing exponentially, along with our technical ability to change the environment for good or ill. But our genetic code still carries the selfish and aggressive instincts that were of survival advantage in the past. It will be difficult enough to avoid disaster in the next hundred years, let alone the next thousand or million. Our only chance of long-term survival is not to remain inward-looking on planet Earth, but to spread out into space. The answers to these big questions show that we have made remarkable progress in the last hundred years. But if we want to continue beyond the next hundred years, our future is in space. That is why I am in favor of manned – or should I say, personned – space flight. All of my life I have sought to understand the universe and find answers to these questions. I have been very lucky that my disability has not been a serious handicap. Indeed, it has probably given me more time than most people to pursue the quest for knowledge. The ultimate goal is a complete theory of the universe, and we are making good progress. Thank you for listening.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbdd3f",
   "metadata": {},
   "source": [
    "#### Print the first 50 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47076f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is nothing bigger or older than the universe\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "print(f.read(50))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea983c9d",
   "metadata": {},
   "source": [
    "#### Print from the 52nd to the 163rd character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269fa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The questions I would like to talk about are: one, where did we come from? How did the universe come into being\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "f.read(52)\n",
    "print(f.read(111))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87597c50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade631c5",
   "metadata": {},
   "source": [
    "#### Open the file `Hawking-Questioning-the-Universe.txt` and create a list named `text_as_list` where every word is an element of the list. \n",
    "\n",
    "Hint: there are two ways to do it. Either with `.readlines()` or with `.split()`. I encourage you to google how both work, but I suggest to adopt the latter.\n",
    "\n",
    "Hint: if you want to split the text so every word is an element of a list, what should be the parameter of the `split()` method? Read more [here](https://www.w3schools.com/python/ref_string_split.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bbb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'nothing', 'bigger', 'or', 'older', 'than', 'the', 'universe.', 'The', 'questions', 'I', 'would', 'like', 'to', 'talk', 'about', 'are:', 'one,', 'where', 'did', 'we', 'come', 'from?', 'How', 'did', 'the', 'universe', 'come', 'into', 'being?', 'Are', 'we', 'alone', 'in', 'the', 'universe?', 'Is', 'there', 'alien', 'life', 'out', 'there?', 'What', 'is', 'the', 'future', 'of', 'the', 'human', 'race?', 'Up', 'until', 'the', '1920s,', 'everyone', 'thought', 'the', 'universe', 'was', 'essentially', 'static', 'and', 'unchanging', 'in', 'time.', 'Then', 'it', 'was', 'discovered', 'that', 'the', 'universe', 'was', 'expanding.', 'Distant', 'galaxies', 'were', 'moving', 'away', 'from', 'us.', 'This', 'meant', 'they', 'must', 'have', 'been', 'closer', 'together', 'in', 'the', 'past.', 'If', 'we', 'extrapolate', 'back,', 'we', 'find', 'we', 'must', 'have', 'all', 'been', 'on', 'top', 'of', 'each', 'other', 'about', '15', 'billion', 'years', 'ago.', 'This', 'was', 'the', 'Big', 'Bang,', 'the', 'beginning', 'of', 'the', 'universe.', 'But', 'was', 'there', 'anything', 'before', 'the', 'Big', 'Bang?', 'If', 'not,', 'what', 'created', 'the', 'universe?', 'Why', 'did', 'the', 'universe', 'emerge', 'from', 'the', 'Big', 'Bang', 'the', 'way', 'it', 'did?', 'We', 'used', 'to', 'think', 'that', 'the', 'theory', 'of', 'the', 'universe', 'could', 'be', 'divided', 'into', 'two', 'parts.', 'First,', 'there', 'were', 'the', 'laws', 'like', 'Maxwell’s', 'equations', 'and', 'general', 'relativity', 'that', 'determined', 'the', 'evolution', 'of', 'the', 'universe,', 'given', 'its', 'state', 'over', 'all', 'of', 'space', 'at', 'one', 'time.', 'And', 'second,', 'there', 'was', 'no', 'question', 'of', 'the', 'initial', 'state', 'of', 'the', 'universe.', 'We', 'have', 'made', 'good', 'progress', 'on', 'the', 'first', 'part,', 'and', 'now', 'have', 'the', 'knowledge', 'of', 'the', 'laws', 'of', 'evolution', 'in', 'all', 'but', 'the', 'most', 'extreme', 'conditions.', 'But', 'until', 'recently,', 'we', 'have', 'had', 'little', 'idea', 'about', 'the', 'initial', 'conditions', 'for', 'the', 'universe.', 'However,', 'this', 'division', 'into', 'laws', 'of', 'evolution', 'and', 'initial', 'conditions', 'depends', 'on', 'time', 'and', 'space', 'being', 'separate', 'and', 'distinct.', 'Under', 'extreme', 'conditions,', 'general', 'relativity', 'and', 'quantum', 'theory', 'allow', 'time', 'to', 'behave', 'like', 'another', 'dimension', 'of', 'space.', 'This', 'removes', 'the', 'distinction', 'between', 'time', 'and', 'space,', 'and', 'means', 'the', 'laws', 'of', 'evolution', 'can', 'also', 'determine', 'the', 'initial', 'state.', 'The', 'universe', 'can', 'spontaneously', 'create', 'itself', 'out', 'of', 'nothing.', 'Moreover,', 'we', 'can', 'calculate', 'a', 'probability', 'that', 'the', 'universe', 'was', 'created', 'in', 'different', 'states.', 'These', 'predictions', 'are', 'in', 'excellent', 'agreement', 'with', 'observations', 'by', 'the', 'WMAP', 'satellite', 'of', 'the', 'cosmic', 'microwave', 'background,', 'which', 'is', 'an', 'imprint', 'of', 'the', 'very', 'early', 'universe.', 'We', 'think', 'we', 'have', 'solved', 'the', 'mystery', 'of', 'creation.', 'Maybe', 'we', 'should', 'patent', 'the', 'universe', 'and', 'charge', 'everyone', 'royalties', 'for', 'their', 'existence.', 'I', 'now', 'turn', 'to', 'the', 'second', 'big', 'question:', 'are', 'we', 'alone,', 'or', 'is', 'there', 'other', 'life', 'in', 'the', 'universe?', 'We', 'believe', 'that', 'life', 'arose', 'spontaneously', 'on', 'the', 'Earth,', 'so', 'it', 'must', 'be', 'possible', 'for', 'life', 'to', 'appear', 'on', 'other', 'suitable', 'planets,', 'of', 'which', 'there', 'seem', 'to', 'be', 'a', 'large', 'number', 'in', 'the', 'galaxy.', 'But', 'we', 'don’t', 'know', 'how', 'life', 'first', 'appeared.', 'We', 'have', 'two', 'pieces', 'of', 'observational', 'evidence', 'on', 'the', 'probability', 'of', 'life', 'appearing.', 'The', 'first', 'is', 'that', 'we', 'have', 'fossils', 'of', 'algae', 'from', '3.5', 'billion', 'years', 'ago.', 'The', 'Earth', 'was', 'formed', '4.6', 'billion', 'years', 'ago', 'and', 'was', 'probably', 'too', 'hot', 'for', 'about', 'the', 'first', 'half', 'billion', 'years.', 'So', 'life', 'appeared', 'on', 'Earth', 'within', 'half', 'a', 'billion', 'years', 'of', 'it', 'being', 'possible,', 'which', 'is', 'short', 'compared', 'to', 'the', '10-billion-year', 'lifetime', 'of', 'a', 'planet', 'of', 'Earth', 'type.', 'This', 'suggests', 'that', 'the', 'probability', 'of', 'life', 'appearing', 'is', 'reasonably', 'high.', 'If', 'it', 'was', 'very', 'low,', 'one', 'would', 'have', 'expected', 'it', 'to', 'take', 'most', 'of', 'the', 'ten', 'billion', 'years', 'available.', 'On', 'the', 'other', 'hand,', 'we', 'don’t', 'seem', 'to', 'have', 'been', 'visited', 'by', 'aliens.', 'I', 'am', 'discounting', 'the', 'reports', 'of', 'UFOs.', 'Why', 'would', 'they', 'appear', 'only', 'to', 'cranks', 'and', 'weirdos?', 'If', 'there', 'is', 'a', 'government', 'conspiracy', 'to', 'suppress', 'the', 'reports', 'and', 'keep', 'for', 'itself', 'the', 'scientific', 'knowledge', 'the', 'aliens', 'bring,', 'it', 'seems', 'to', 'have', 'been', 'a', 'singularly', 'ineffective', 'policy', 'so', 'far.', 'Furthermore,', 'despite', 'an', 'extensive', 'search', 'by', 'the', 'SETI', 'project,', 'we', 'haven’t', 'heard', 'any', 'alien', 'television', 'quiz', 'shows.', 'This', 'probably', 'indicates', 'that', 'there', 'are', 'no', 'alien', 'civilizations', 'at', 'our', 'stage', 'of', 'development', 'within', 'a', 'radius', 'of', 'a', 'few', 'hundred', 'light', 'years.', 'Issuing', 'an', 'insurance', 'policy', 'against', 'abduction', 'by', 'aliens', 'seems', 'a', 'pretty', 'safe', 'bet.', 'This', 'brings', 'me', 'to', 'the', 'last', 'of', 'the', 'big', 'questions:', 'the', 'future', 'of', 'the', 'human', 'race.', 'If', 'we', 'are', 'the', 'only', 'intelligent', 'beings', 'in', 'the', 'galaxy,', 'we', 'should', 'make', 'sure', 'we', 'survive', 'and', 'continue.', 'But', 'we', 'are', 'entering', 'an', 'increasingly', 'dangerous', 'period', 'of', 'our', 'history.', 'Our', 'population', 'and', 'our', 'use', 'of', 'the', 'finite', 'resources', 'of', 'planet', 'Earth', 'are', 'growing', 'exponentially,', 'along', 'with', 'our', 'technical', 'ability', 'to', 'change', 'the', 'environment', 'for', 'good', 'or', 'ill.', 'But', 'our', 'genetic', 'code', 'still', 'carries', 'the', 'selfish', 'and', 'aggressive', 'instincts', 'that', 'were', 'of', 'survival', 'advantage', 'in', 'the', 'past.', 'It', 'will', 'be', 'difficult', 'enough', 'to', 'avoid', 'disaster', 'in', 'the', 'next', 'hundred', 'years,', 'let', 'alone', 'the', 'next', 'thousand', 'or', 'million.', 'Our', 'only', 'chance', 'of', 'long-term', 'survival', 'is', 'not', 'to', 'remain', 'inward-looking', 'on', 'planet', 'Earth,', 'but', 'to', 'spread', 'out', 'into', 'space.', 'The', 'answers', 'to', 'these', 'big', 'questions', 'show', 'that', 'we', 'have', 'made', 'remarkable', 'progress', 'in', 'the', 'last', 'hundred', 'years.', 'But', 'if', 'we', 'want', 'to', 'continue', 'beyond', 'the', 'next', 'hundred', 'years,', 'our', 'future', 'is', 'in', 'space.', 'That', 'is', 'why', 'I', 'am', 'in', 'favor', 'of', 'manned', '–', 'or', 'should', 'I', 'say,', 'personned', '–', 'space', 'flight.', 'All', 'of', 'my', 'life', 'I', 'have', 'sought', 'to', 'understand', 'the', 'universe', 'and', 'find', 'answers', 'to', 'these', 'questions.', 'I', 'have', 'been', 'very', 'lucky', 'that', 'my', 'disability', 'has', 'not', 'been', 'a', 'serious', 'handicap.', 'Indeed,', 'it', 'has', 'probably', 'given', 'me', 'more', 'time', 'than', 'most', 'people', 'to', 'pursue', 'the', 'quest', 'for', 'knowledge.', 'The', 'ultimate', 'goal', 'is', 'a', 'complete', 'theory', 'of', 'the', 'universe,', 'and', 'we', 'are', 'making', 'good', 'progress.', 'Thank', 'you', 'for', 'listening.']\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Hawking-Questioning-the-Universe.txt\", \"r\")\n",
    "text = f.read()\n",
    "text_as_list = text.split(\" \")\n",
    "print(text_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810560f",
   "metadata": {},
   "source": [
    "#### This code will remove the punctuation from your list and applies the lower() method that returns a string where all characters are lower case. Simple run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc5de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text_as_list = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in text_as_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555565af",
   "metadata": {},
   "source": [
    "#### Create a new list `words_begin_with_a` and append all words of the `text_as_list` that begin with a small _a_.\n",
    "\n",
    "Hint: you have to define first an empty list.\n",
    "\n",
    "Hint: in order to find if a string starts with one or more letters, you should use the method `.startswith()`. Read more [here](https://www.w3schools.com/python/ref_string_startswith.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef97035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'are', 'are', 'alone', 'alien', 'and', 'away', 'all', 'about', 'ago', 'anything', 'and', 'all', 'at', 'and', 'and', 'all', 'about', 'and', 'and', 'and', 'and', 'allow', 'another', 'and', 'and', 'also', 'a', 'are', 'agreement', 'an', 'and', 'are', 'alone', 'arose', 'appear', 'a', 'appeared', 'appearing', 'algae', 'ago', 'ago', 'and', 'about', 'appeared', 'a', 'a', 'appearing', 'available', 'aliens', 'am', 'appear', 'and', 'a', 'and', 'aliens', 'a', 'an', 'any', 'alien', 'are', 'alien', 'at', 'a', 'a', 'an', 'against', 'abduction', 'aliens', 'a', 'are', 'and', 'are', 'an', 'and', 'are', 'along', 'ability', 'and', 'aggressive', 'advantage', 'avoid', 'alone', 'answers', 'am', 'all', 'and', 'answers', 'a', 'a', 'and', 'are']\n"
     ]
    }
   ],
   "source": [
    "words_begin_with_a = []\n",
    "\n",
    "for words in text_as_list:\n",
    "    if words.startswith(\"a\"):\n",
    "        words_begin_with_a.append(words)\n",
    "\n",
    "print(words_begin_with_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e30",
   "metadata": {},
   "source": [
    "Answer: 310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015adc25",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words starts with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87dba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter = 0\n",
    "other_counter = 0\n",
    "\n",
    "while i<len(text_as_list):\n",
    "    if text_as_list[i].startswith('u'):\n",
    "        counter+=1\n",
    "    else:\n",
    "        other_counter+=1\n",
    "    i += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032371cb",
   "metadata": {},
   "source": [
    "Answer: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57461070",
   "metadata": {},
   "source": [
    "#### Create a counter and use a while loop to counter how many words do NOT start with a _u_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfcc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877\n"
     ]
    }
   ],
   "source": [
    "print(other_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0008d",
   "metadata": {},
   "source": [
    "Answer: 877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52679f74",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"universe\" appears in the text. Feel free to google how we test if a word is _in_ a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38e92923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = text_as_list.count(\"universe\")\n",
    "if a>0:\n",
    "    True\n",
    "    print(\"True\")\n",
    "else:\n",
    "    False\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acdf",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not print \"the word does not appear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03093ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word does not appear\n",
      "I didn't find the words\n"
     ]
    }
   ],
   "source": [
    "a = text_as_list.count(\"alliens\")\n",
    "b = text_as_list.count(\"the word does not appear\")\n",
    "if a==0:\n",
    "    print(\"The word does not appear\")\n",
    "    if b==0:\n",
    "        print(\"I didn't find the words\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f2002",
   "metadata": {},
   "source": [
    "#### Write an if statement that checkes if the word \"alliens\" appears in the text. If not, check if the word \"International Space Station\" appears in the text. If neither is in the text, print \"I didn't find the words\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d9304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8b465d",
   "metadata": {},
   "source": [
    "#### Take the text_as_list and create a dictionary named `mydictionary`. The words of the text should be the keys of the dictionary and the index of the word the values of the keys.\n",
    "\n",
    "Hint: there is a method in Python that adds a counter to an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ca15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 624, 'is': 891, 'nothing': 314, 'bigger': 4, 'or': 832, 'older': 6, 'than': 879, 'the': 896, 'universe': 897, 'questions': 856, 'i': 857, 'would': 564, 'like': 281, 'to': 882, 'talk': 16, 'about': 479, 'are': 900, 'one': 529, 'where': 20, 'did': 151, 'we': 899, 'come': 29, 'from': 460, 'how': 434, 'into': 786, 'being': 497, 'alone': 762, 'in': 827, 'alien': 627, 'life': 843, 'out': 785, 'what': 135, 'future': 818, 'of': 895, 'human': 670, 'race': 671, 'up': 52, 'until': 236, '1920s': 55, 'everyone': 372, 'thought': 57, 'was': 526, 'essentially': 61, 'static': 62, 'and': 898, 'unchanging': 64, 'time': 878, 'then': 67, 'it': 872, 'discovered': 70, 'that': 862, 'expanding': 75, 'distant': 76, 'galaxies': 77, 'were': 741, 'moving': 79, 'away': 80, 'us': 82, 'this': 656, 'meant': 84, 'they': 565, 'must': 407, 'have': 858, 'been': 867, 'closer': 89, 'together': 90, 'past': 747, 'if': 807, 'extrapolate': 96, 'back': 97, 'find': 852, 'all': 840, 'on': 779, 'top': 106, 'each': 108, 'other': 545, '15': 111, 'billion': 540, 'years': 816, 'ago': 472, 'big': 792, 'bang': 147, 'beginning': 121, 'but': 806, 'anything': 128, 'before': 129, 'not': 866, 'created': 325, 'why': 824, 'emerge': 143, 'way': 149, 'used': 153, 'think': 356, 'theory': 894, 'could': 162, 'be': 750, 'divided': 164, 'two': 440, 'parts': 167, 'first': 481, 'laws': 297, 'maxwell’s': 174, 'equations': 175, 'general': 272, 'relativity': 273, 'determined': 180, 'evolution': 299, 'given': 875, 'its': 187, 'state': 305, 'over': 189, 'space': 838, 'at': 629, 'second': 382, 'no': 626, 'question': 384, 'initial': 304, 'made': 798, 'good': 902, 'progress': 903, 'part': 217, 'now': 378, 'knowledge': 887, 'most': 880, 'extreme': 270, 'conditions': 271, 'recently': 237, 'had': 240, 'little': 241, 'idea': 242, 'for': 906, 'however': 250, 'division': 252, 'depends': 260, 'separate': 266, 'distinct': 268, 'under': 269, 'quantum': 275, 'allow': 277, 'behave': 280, 'another': 282, 'dimension': 283, 'removes': 287, 'distinction': 289, 'between': 290, 'means': 295, 'can': 317, 'also': 301, 'determine': 302, 'spontaneously': 401, 'create': 310, 'itself': 585, 'moreover': 315, 'calculate': 318, 'a': 892, 'probability': 517, 'different': 327, 'states': 328, 'these': 855, 'predictions': 330, 'excellent': 333, 'agreement': 334, 'with': 717, 'observations': 336, 'by': 649, 'wmap': 339, 'satellite': 340, 'cosmic': 343, 'microwave': 344, 'background': 345, 'which': 499, 'an': 694, 'imprint': 349, 'very': 860, 'early': 353, 'solved': 359, 'mystery': 361, 'creation': 363, 'maybe': 364, 'should': 833, 'patent': 367, 'charge': 371, 'royalties': 373, 'their': 375, 'existence': 376, 'turn': 379, 'believe': 397, 'arose': 400, 'earth': 781, 'so': 601, 'possible': 498, 'appear': 566, 'suitable': 416, 'planets': 417, 'seem': 549, 'large': 425, 'number': 426, 'galaxy': 681, 'don’t': 548, 'know': 433, 'appeared': 487, 'pieces': 441, 'observational': 443, 'evidence': 444, 'appearing': 520, 'fossils': 457, 'algae': 459, '35': 461, 'formed': 468, '46': 469, 'probably': 874, 'too': 476, 'hot': 477, 'half': 491, 'within': 634, 'short': 501, 'compared': 502, '10billionyear': 505, 'lifetime': 506, 'planet': 780, 'type': 512, 'suggests': 514, 'reasonably': 522, 'high': 523, 'low': 528, 'expected': 532, 'take': 535, 'ten': 539, 'available': 542, 'hand': 546, 'visited': 553, 'aliens': 650, 'am': 826, 'discounting': 558, 'reports': 581, 'ufos': 562, 'only': 769, 'cranks': 569, 'weirdos': 571, 'government': 576, 'conspiracy': 577, 'suppress': 579, 'keep': 583, 'scientific': 587, 'bring': 591, 'seems': 651, 'singularly': 598, 'ineffective': 599, 'policy': 646, 'far': 602, 'furthermore': 603, 'despite': 604, 'extensive': 606, 'search': 607, 'seti': 610, 'project': 611, 'haven’t': 613, 'heard': 614, 'any': 615, 'television': 617, 'quiz': 618, 'shows': 619, 'indicates': 622, 'civilizations': 628, 'our': 817, 'stage': 631, 'development': 633, 'radius': 636, 'few': 639, 'hundred': 815, 'light': 641, 'issuing': 643, 'insurance': 645, 'against': 647, 'abduction': 648, 'pretty': 653, 'safe': 654, 'bet': 655, 'brings': 657, 'me': 876, 'last': 803, 'intelligent': 677, 'beings': 678, 'make': 684, 'sure': 685, 'survive': 687, 'continue': 811, 'entering': 693, 'increasingly': 695, 'dangerous': 696, 'period': 697, 'history': 700, 'population': 702, 'use': 705, 'finite': 708, 'resources': 709, 'growing': 714, 'exponentially': 715, 'along': 716, 'technical': 719, 'ability': 720, 'change': 722, 'environment': 724, 'ill': 728, 'genetic': 731, 'code': 732, 'still': 733, 'carries': 734, 'selfish': 736, 'aggressive': 738, 'instincts': 739, 'survival': 773, 'advantage': 744, 'will': 749, 'difficult': 751, 'enough': 752, 'avoid': 754, 'disaster': 755, 'next': 814, 'let': 761, 'thousand': 765, 'million': 767, 'chance': 770, 'longterm': 772, 'remain': 777, 'inwardlooking': 778, 'spread': 784, 'answers': 853, 'show': 794, 'remarkable': 799, 'want': 809, 'beyond': 812, 'favor': 828, 'manned': 830, '–': 837, 'say': 835, 'personned': 836, 'flight': 839, 'my': 863, 'sought': 846, 'understand': 848, 'lucky': 861, 'disability': 864, 'has': 873, 'serious': 869, 'handicap': 870, 'indeed': 871, 'more': 877, 'people': 881, 'pursue': 883, 'quest': 885, 'ultimate': 889, 'goal': 890, 'complete': 893, 'making': 901, 'thank': 904, 'you': 905, 'listening': 907}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "a = 1\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[i] = a\n",
    "    a+=1\n",
    "    \n",
    "    \n",
    "print(dic)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydictionary = {}\n",
    "\n",
    "for i,j in enumerate(text_as_list):\n",
    "    mydictionary[j] = i\n",
    "    \n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3c45",
   "metadata": {},
   "source": [
    "#### Create the same dictonary but now index of  words in the text should be the dictionary's keys and the words should be the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d54fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'there', 2: 'is', 3: 'nothing', 4: 'bigger', 5: 'or', 6: 'older', 7: 'than', 8: 'the', 9: 'universe', 10: 'the', 11: 'questions', 12: 'i', 13: 'would', 14: 'like', 15: 'to', 16: 'talk', 17: 'about', 18: 'are', 19: 'one', 20: 'where', 21: 'did', 22: 'we', 23: 'come', 24: 'from', 25: 'how', 26: 'did', 27: 'the', 28: 'universe', 29: 'come', 30: 'into', 31: 'being', 32: 'are', 33: 'we', 34: 'alone', 35: 'in', 36: 'the', 37: 'universe', 38: 'is', 39: 'there', 40: 'alien', 41: 'life', 42: 'out', 43: 'there', 44: 'what', 45: 'is', 46: 'the', 47: 'future', 48: 'of', 49: 'the', 50: 'human', 51: 'race', 52: 'up', 53: 'until', 54: 'the', 55: '1920s', 56: 'everyone', 57: 'thought', 58: 'the', 59: 'universe', 60: 'was', 61: 'essentially', 62: 'static', 63: 'and', 64: 'unchanging', 65: 'in', 66: 'time', 67: 'then', 68: 'it', 69: 'was', 70: 'discovered', 71: 'that', 72: 'the', 73: 'universe', 74: 'was', 75: 'expanding', 76: 'distant', 77: 'galaxies', 78: 'were', 79: 'moving', 80: 'away', 81: 'from', 82: 'us', 83: 'this', 84: 'meant', 85: 'they', 86: 'must', 87: 'have', 88: 'been', 89: 'closer', 90: 'together', 91: 'in', 92: 'the', 93: 'past', 94: 'if', 95: 'we', 96: 'extrapolate', 97: 'back', 98: 'we', 99: 'find', 100: 'we', 101: 'must', 102: 'have', 103: 'all', 104: 'been', 105: 'on', 106: 'top', 107: 'of', 108: 'each', 109: 'other', 110: 'about', 111: '15', 112: 'billion', 113: 'years', 114: 'ago', 115: 'this', 116: 'was', 117: 'the', 118: 'big', 119: 'bang', 120: 'the', 121: 'beginning', 122: 'of', 123: 'the', 124: 'universe', 125: 'but', 126: 'was', 127: 'there', 128: 'anything', 129: 'before', 130: 'the', 131: 'big', 132: 'bang', 133: 'if', 134: 'not', 135: 'what', 136: 'created', 137: 'the', 138: 'universe', 139: 'why', 140: 'did', 141: 'the', 142: 'universe', 143: 'emerge', 144: 'from', 145: 'the', 146: 'big', 147: 'bang', 148: 'the', 149: 'way', 150: 'it', 151: 'did', 152: 'we', 153: 'used', 154: 'to', 155: 'think', 156: 'that', 157: 'the', 158: 'theory', 159: 'of', 160: 'the', 161: 'universe', 162: 'could', 163: 'be', 164: 'divided', 165: 'into', 166: 'two', 167: 'parts', 168: 'first', 169: 'there', 170: 'were', 171: 'the', 172: 'laws', 173: 'like', 174: 'maxwell’s', 175: 'equations', 176: 'and', 177: 'general', 178: 'relativity', 179: 'that', 180: 'determined', 181: 'the', 182: 'evolution', 183: 'of', 184: 'the', 185: 'universe', 186: 'given', 187: 'its', 188: 'state', 189: 'over', 190: 'all', 191: 'of', 192: 'space', 193: 'at', 194: 'one', 195: 'time', 196: 'and', 197: 'second', 198: 'there', 199: 'was', 200: 'no', 201: 'question', 202: 'of', 203: 'the', 204: 'initial', 205: 'state', 206: 'of', 207: 'the', 208: 'universe', 209: 'we', 210: 'have', 211: 'made', 212: 'good', 213: 'progress', 214: 'on', 215: 'the', 216: 'first', 217: 'part', 218: 'and', 219: 'now', 220: 'have', 221: 'the', 222: 'knowledge', 223: 'of', 224: 'the', 225: 'laws', 226: 'of', 227: 'evolution', 228: 'in', 229: 'all', 230: 'but', 231: 'the', 232: 'most', 233: 'extreme', 234: 'conditions', 235: 'but', 236: 'until', 237: 'recently', 238: 'we', 239: 'have', 240: 'had', 241: 'little', 242: 'idea', 243: 'about', 244: 'the', 245: 'initial', 246: 'conditions', 247: 'for', 248: 'the', 249: 'universe', 250: 'however', 251: 'this', 252: 'division', 253: 'into', 254: 'laws', 255: 'of', 256: 'evolution', 257: 'and', 258: 'initial', 259: 'conditions', 260: 'depends', 261: 'on', 262: 'time', 263: 'and', 264: 'space', 265: 'being', 266: 'separate', 267: 'and', 268: 'distinct', 269: 'under', 270: 'extreme', 271: 'conditions', 272: 'general', 273: 'relativity', 274: 'and', 275: 'quantum', 276: 'theory', 277: 'allow', 278: 'time', 279: 'to', 280: 'behave', 281: 'like', 282: 'another', 283: 'dimension', 284: 'of', 285: 'space', 286: 'this', 287: 'removes', 288: 'the', 289: 'distinction', 290: 'between', 291: 'time', 292: 'and', 293: 'space', 294: 'and', 295: 'means', 296: 'the', 297: 'laws', 298: 'of', 299: 'evolution', 300: 'can', 301: 'also', 302: 'determine', 303: 'the', 304: 'initial', 305: 'state', 306: 'the', 307: 'universe', 308: 'can', 309: 'spontaneously', 310: 'create', 311: 'itself', 312: 'out', 313: 'of', 314: 'nothing', 315: 'moreover', 316: 'we', 317: 'can', 318: 'calculate', 319: 'a', 320: 'probability', 321: 'that', 322: 'the', 323: 'universe', 324: 'was', 325: 'created', 326: 'in', 327: 'different', 328: 'states', 329: 'these', 330: 'predictions', 331: 'are', 332: 'in', 333: 'excellent', 334: 'agreement', 335: 'with', 336: 'observations', 337: 'by', 338: 'the', 339: 'wmap', 340: 'satellite', 341: 'of', 342: 'the', 343: 'cosmic', 344: 'microwave', 345: 'background', 346: 'which', 347: 'is', 348: 'an', 349: 'imprint', 350: 'of', 351: 'the', 352: 'very', 353: 'early', 354: 'universe', 355: 'we', 356: 'think', 357: 'we', 358: 'have', 359: 'solved', 360: 'the', 361: 'mystery', 362: 'of', 363: 'creation', 364: 'maybe', 365: 'we', 366: 'should', 367: 'patent', 368: 'the', 369: 'universe', 370: 'and', 371: 'charge', 372: 'everyone', 373: 'royalties', 374: 'for', 375: 'their', 376: 'existence', 377: 'i', 378: 'now', 379: 'turn', 380: 'to', 381: 'the', 382: 'second', 383: 'big', 384: 'question', 385: 'are', 386: 'we', 387: 'alone', 388: 'or', 389: 'is', 390: 'there', 391: 'other', 392: 'life', 393: 'in', 394: 'the', 395: 'universe', 396: 'we', 397: 'believe', 398: 'that', 399: 'life', 400: 'arose', 401: 'spontaneously', 402: 'on', 403: 'the', 404: 'earth', 405: 'so', 406: 'it', 407: 'must', 408: 'be', 409: 'possible', 410: 'for', 411: 'life', 412: 'to', 413: 'appear', 414: 'on', 415: 'other', 416: 'suitable', 417: 'planets', 418: 'of', 419: 'which', 420: 'there', 421: 'seem', 422: 'to', 423: 'be', 424: 'a', 425: 'large', 426: 'number', 427: 'in', 428: 'the', 429: 'galaxy', 430: 'but', 431: 'we', 432: 'don’t', 433: 'know', 434: 'how', 435: 'life', 436: 'first', 437: 'appeared', 438: 'we', 439: 'have', 440: 'two', 441: 'pieces', 442: 'of', 443: 'observational', 444: 'evidence', 445: 'on', 446: 'the', 447: 'probability', 448: 'of', 449: 'life', 450: 'appearing', 451: 'the', 452: 'first', 453: 'is', 454: 'that', 455: 'we', 456: 'have', 457: 'fossils', 458: 'of', 459: 'algae', 460: 'from', 461: '35', 462: 'billion', 463: 'years', 464: 'ago', 465: 'the', 466: 'earth', 467: 'was', 468: 'formed', 469: '46', 470: 'billion', 471: 'years', 472: 'ago', 473: 'and', 474: 'was', 475: 'probably', 476: 'too', 477: 'hot', 478: 'for', 479: 'about', 480: 'the', 481: 'first', 482: 'half', 483: 'billion', 484: 'years', 485: 'so', 486: 'life', 487: 'appeared', 488: 'on', 489: 'earth', 490: 'within', 491: 'half', 492: 'a', 493: 'billion', 494: 'years', 495: 'of', 496: 'it', 497: 'being', 498: 'possible', 499: 'which', 500: 'is', 501: 'short', 502: 'compared', 503: 'to', 504: 'the', 505: '10billionyear', 506: 'lifetime', 507: 'of', 508: 'a', 509: 'planet', 510: 'of', 511: 'earth', 512: 'type', 513: 'this', 514: 'suggests', 515: 'that', 516: 'the', 517: 'probability', 518: 'of', 519: 'life', 520: 'appearing', 521: 'is', 522: 'reasonably', 523: 'high', 524: 'if', 525: 'it', 526: 'was', 527: 'very', 528: 'low', 529: 'one', 530: 'would', 531: 'have', 532: 'expected', 533: 'it', 534: 'to', 535: 'take', 536: 'most', 537: 'of', 538: 'the', 539: 'ten', 540: 'billion', 541: 'years', 542: 'available', 543: 'on', 544: 'the', 545: 'other', 546: 'hand', 547: 'we', 548: 'don’t', 549: 'seem', 550: 'to', 551: 'have', 552: 'been', 553: 'visited', 554: 'by', 555: 'aliens', 556: 'i', 557: 'am', 558: 'discounting', 559: 'the', 560: 'reports', 561: 'of', 562: 'ufos', 563: 'why', 564: 'would', 565: 'they', 566: 'appear', 567: 'only', 568: 'to', 569: 'cranks', 570: 'and', 571: 'weirdos', 572: 'if', 573: 'there', 574: 'is', 575: 'a', 576: 'government', 577: 'conspiracy', 578: 'to', 579: 'suppress', 580: 'the', 581: 'reports', 582: 'and', 583: 'keep', 584: 'for', 585: 'itself', 586: 'the', 587: 'scientific', 588: 'knowledge', 589: 'the', 590: 'aliens', 591: 'bring', 592: 'it', 593: 'seems', 594: 'to', 595: 'have', 596: 'been', 597: 'a', 598: 'singularly', 599: 'ineffective', 600: 'policy', 601: 'so', 602: 'far', 603: 'furthermore', 604: 'despite', 605: 'an', 606: 'extensive', 607: 'search', 608: 'by', 609: 'the', 610: 'seti', 611: 'project', 612: 'we', 613: 'haven’t', 614: 'heard', 615: 'any', 616: 'alien', 617: 'television', 618: 'quiz', 619: 'shows', 620: 'this', 621: 'probably', 622: 'indicates', 623: 'that', 624: 'there', 625: 'are', 626: 'no', 627: 'alien', 628: 'civilizations', 629: 'at', 630: 'our', 631: 'stage', 632: 'of', 633: 'development', 634: 'within', 635: 'a', 636: 'radius', 637: 'of', 638: 'a', 639: 'few', 640: 'hundred', 641: 'light', 642: 'years', 643: 'issuing', 644: 'an', 645: 'insurance', 646: 'policy', 647: 'against', 648: 'abduction', 649: 'by', 650: 'aliens', 651: 'seems', 652: 'a', 653: 'pretty', 654: 'safe', 655: 'bet', 656: 'this', 657: 'brings', 658: 'me', 659: 'to', 660: 'the', 661: 'last', 662: 'of', 663: 'the', 664: 'big', 665: 'questions', 666: 'the', 667: 'future', 668: 'of', 669: 'the', 670: 'human', 671: 'race', 672: 'if', 673: 'we', 674: 'are', 675: 'the', 676: 'only', 677: 'intelligent', 678: 'beings', 679: 'in', 680: 'the', 681: 'galaxy', 682: 'we', 683: 'should', 684: 'make', 685: 'sure', 686: 'we', 687: 'survive', 688: 'and', 689: 'continue', 690: 'but', 691: 'we', 692: 'are', 693: 'entering', 694: 'an', 695: 'increasingly', 696: 'dangerous', 697: 'period', 698: 'of', 699: 'our', 700: 'history', 701: 'our', 702: 'population', 703: 'and', 704: 'our', 705: 'use', 706: 'of', 707: 'the', 708: 'finite', 709: 'resources', 710: 'of', 711: 'planet', 712: 'earth', 713: 'are', 714: 'growing', 715: 'exponentially', 716: 'along', 717: 'with', 718: 'our', 719: 'technical', 720: 'ability', 721: 'to', 722: 'change', 723: 'the', 724: 'environment', 725: 'for', 726: 'good', 727: 'or', 728: 'ill', 729: 'but', 730: 'our', 731: 'genetic', 732: 'code', 733: 'still', 734: 'carries', 735: 'the', 736: 'selfish', 737: 'and', 738: 'aggressive', 739: 'instincts', 740: 'that', 741: 'were', 742: 'of', 743: 'survival', 744: 'advantage', 745: 'in', 746: 'the', 747: 'past', 748: 'it', 749: 'will', 750: 'be', 751: 'difficult', 752: 'enough', 753: 'to', 754: 'avoid', 755: 'disaster', 756: 'in', 757: 'the', 758: 'next', 759: 'hundred', 760: 'years', 761: 'let', 762: 'alone', 763: 'the', 764: 'next', 765: 'thousand', 766: 'or', 767: 'million', 768: 'our', 769: 'only', 770: 'chance', 771: 'of', 772: 'longterm', 773: 'survival', 774: 'is', 775: 'not', 776: 'to', 777: 'remain', 778: 'inwardlooking', 779: 'on', 780: 'planet', 781: 'earth', 782: 'but', 783: 'to', 784: 'spread', 785: 'out', 786: 'into', 787: 'space', 788: 'the', 789: 'answers', 790: 'to', 791: 'these', 792: 'big', 793: 'questions', 794: 'show', 795: 'that', 796: 'we', 797: 'have', 798: 'made', 799: 'remarkable', 800: 'progress', 801: 'in', 802: 'the', 803: 'last', 804: 'hundred', 805: 'years', 806: 'but', 807: 'if', 808: 'we', 809: 'want', 810: 'to', 811: 'continue', 812: 'beyond', 813: 'the', 814: 'next', 815: 'hundred', 816: 'years', 817: 'our', 818: 'future', 819: 'is', 820: 'in', 821: 'space', 822: 'that', 823: 'is', 824: 'why', 825: 'i', 826: 'am', 827: 'in', 828: 'favor', 829: 'of', 830: 'manned', 831: '–', 832: 'or', 833: 'should', 834: 'i', 835: 'say', 836: 'personned', 837: '–', 838: 'space', 839: 'flight', 840: 'all', 841: 'of', 842: 'my', 843: 'life', 844: 'i', 845: 'have', 846: 'sought', 847: 'to', 848: 'understand', 849: 'the', 850: 'universe', 851: 'and', 852: 'find', 853: 'answers', 854: 'to', 855: 'these', 856: 'questions', 857: 'i', 858: 'have', 859: 'been', 860: 'very', 861: 'lucky', 862: 'that', 863: 'my', 864: 'disability', 865: 'has', 866: 'not', 867: 'been', 868: 'a', 869: 'serious', 870: 'handicap', 871: 'indeed', 872: 'it', 873: 'has', 874: 'probably', 875: 'given', 876: 'me', 877: 'more', 878: 'time', 879: 'than', 880: 'most', 881: 'people', 882: 'to', 883: 'pursue', 884: 'the', 885: 'quest', 886: 'for', 887: 'knowledge', 888: 'the', 889: 'ultimate', 890: 'goal', 891: 'is', 892: 'a', 893: 'complete', 894: 'theory', 895: 'of', 896: 'the', 897: 'universe', 898: 'and', 899: 'we', 900: 'are', 901: 'making', 902: 'good', 903: 'progress', 904: 'thank', 905: 'you', 906: 'for', 907: 'listening'}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "a = 1\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[a] = i\n",
    "    a+=1\n",
    "    \n",
    "    \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5da2c8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_as_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m mydictionary \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtext_as_list\u001b[49m):\n\u001b[1;32m      4\u001b[0m     mydictionary[i] \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mydictionary))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_as_list' is not defined"
     ]
    }
   ],
   "source": [
    "mydictionary = {}\n",
    "\n",
    "for i,j in enumerate(text_as_list):\n",
    "    mydictionary[i] = j\n",
    "    \n",
    "print(len(mydictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48403e",
   "metadata": {},
   "source": [
    "#### Why the lenghts of the two dictionaries are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473cd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c902a269",
   "metadata": {},
   "source": [
    "#### Create a dictionary `dict_counter` that takes as keys the words of text_as_list. The values of each key should be the number that each words is attested in the list.\n",
    "\n",
    "Hint: Check the [`count()` method](https://www.w3schools.com/python/ref_list_count.asp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c7eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'There': 1, 'is': 12, 'nothing': 1, 'bigger': 1, 'or': 5, 'older': 1, 'than': 2, 'the': 71, 'universe.': 5, 'The': 6, 'questions': 2, 'I': 7, 'would': 3, 'like': 3, 'to': 22, 'talk': 1, 'about': 4, 'are:': 1, 'one,': 1, 'where': 1, 'did': 3, 'we': 21, 'come': 2, 'from?': 1, 'How': 1, 'universe': 9, 'into': 4, 'being?': 1, 'Are': 1, 'alone': 2, 'in': 14, 'universe?': 3, 'Is': 1, 'there': 8, 'alien': 3, 'life': 9, 'out': 3, 'there?': 1, 'What': 1, 'future': 3, 'of': 39, 'human': 2, 'race?': 1, 'Up': 1, 'until': 2, '1920s,': 1, 'everyone': 2, 'thought': 1, 'was': 10, 'essentially': 1, 'static': 1, 'and': 18, 'unchanging': 1, 'time.': 2, 'Then': 1, 'it': 8, 'discovered': 1, 'that': 11, 'expanding.': 1, 'Distant': 1, 'galaxies': 1, 'were': 3, 'moving': 1, 'away': 1, 'from': 3, 'us.': 1, 'This': 6, 'meant': 1, 'they': 2, 'must': 3, 'have': 14, 'been': 6, 'closer': 1, 'together': 1, 'past.': 2, 'If': 5, 'extrapolate': 1, 'back,': 1, 'find': 2, 'all': 3, 'on': 8, 'top': 1, 'each': 1, 'other': 4, '15': 1, 'billion': 6, 'years': 5, 'ago.': 2, 'Big': 3, 'Bang,': 1, 'beginning': 1, 'But': 6, 'anything': 1, 'before': 1, 'Bang?': 1, 'not,': 1, 'what': 1, 'created': 2, 'Why': 2, 'emerge': 1, 'Bang': 1, 'way': 1, 'did?': 1, 'We': 5, 'used': 1, 'think': 2, 'theory': 3, 'could': 1, 'be': 4, 'divided': 1, 'two': 2, 'parts.': 1, 'First,': 1, 'laws': 4, 'Maxwell’s': 1, 'equations': 1, 'general': 2, 'relativity': 2, 'determined': 1, 'evolution': 4, 'universe,': 2, 'given': 2, 'its': 1, 'state': 2, 'over': 1, 'space': 3, 'at': 2, 'one': 2, 'And': 1, 'second,': 1, 'no': 2, 'question': 1, 'initial': 4, 'made': 2, 'good': 3, 'progress': 2, 'first': 4, 'part,': 1, 'now': 2, 'knowledge': 2, 'but': 2, 'most': 3, 'extreme': 2, 'conditions.': 1, 'recently,': 1, 'had': 1, 'little': 1, 'idea': 1, 'conditions': 2, 'for': 8, 'However,': 1, 'this': 1, 'division': 1, 'depends': 1, 'time': 4, 'being': 2, 'separate': 1, 'distinct.': 1, 'Under': 1, 'conditions,': 1, 'quantum': 1, 'allow': 1, 'behave': 1, 'another': 1, 'dimension': 1, 'space.': 3, 'removes': 1, 'distinction': 1, 'between': 1, 'space,': 1, 'means': 1, 'can': 3, 'also': 1, 'determine': 1, 'state.': 1, 'spontaneously': 2, 'create': 1, 'itself': 2, 'nothing.': 1, 'Moreover,': 1, 'calculate': 1, 'a': 11, 'probability': 3, 'different': 1, 'states.': 1, 'These': 1, 'predictions': 1, 'are': 7, 'excellent': 1, 'agreement': 1, 'with': 2, 'observations': 1, 'by': 4, 'WMAP': 1, 'satellite': 1, 'cosmic': 1, 'microwave': 1, 'background,': 1, 'which': 3, 'an': 4, 'imprint': 1, 'very': 3, 'early': 1, 'solved': 1, 'mystery': 1, 'creation.': 1, 'Maybe': 1, 'should': 3, 'patent': 1, 'charge': 1, 'royalties': 1, 'their': 1, 'existence.': 1, 'turn': 1, 'second': 1, 'big': 3, 'question:': 1, 'alone,': 1, 'believe': 1, 'arose': 1, 'Earth,': 2, 'so': 2, 'possible': 1, 'appear': 2, 'suitable': 1, 'planets,': 1, 'seem': 2, 'large': 1, 'number': 1, 'galaxy.': 1, 'don’t': 2, 'know': 1, 'how': 1, 'appeared.': 1, 'pieces': 1, 'observational': 1, 'evidence': 1, 'appearing.': 1, 'fossils': 1, 'algae': 1, '3.5': 1, 'Earth': 4, 'formed': 1, '4.6': 1, 'ago': 1, 'probably': 3, 'too': 1, 'hot': 1, 'half': 2, 'years.': 3, 'So': 1, 'appeared': 1, 'within': 2, 'possible,': 1, 'short': 1, 'compared': 1, '10-billion-year': 1, 'lifetime': 1, 'planet': 3, 'type.': 1, 'suggests': 1, 'appearing': 1, 'reasonably': 1, 'high.': 1, 'low,': 1, 'expected': 1, 'take': 1, 'ten': 1, 'available.': 1, 'On': 1, 'hand,': 1, 'visited': 1, 'aliens.': 1, 'am': 2, 'discounting': 1, 'reports': 2, 'UFOs.': 1, 'only': 3, 'cranks': 1, 'weirdos?': 1, 'government': 1, 'conspiracy': 1, 'suppress': 1, 'keep': 1, 'scientific': 1, 'aliens': 2, 'bring,': 1, 'seems': 2, 'singularly': 1, 'ineffective': 1, 'policy': 2, 'far.': 1, 'Furthermore,': 1, 'despite': 1, 'extensive': 1, 'search': 1, 'SETI': 1, 'project,': 1, 'haven’t': 1, 'heard': 1, 'any': 1, 'television': 1, 'quiz': 1, 'shows.': 1, 'indicates': 1, 'civilizations': 1, 'our': 6, 'stage': 1, 'development': 1, 'radius': 1, 'few': 1, 'hundred': 4, 'light': 1, 'Issuing': 1, 'insurance': 1, 'against': 1, 'abduction': 1, 'pretty': 1, 'safe': 1, 'bet.': 1, 'brings': 1, 'me': 2, 'last': 2, 'questions:': 1, 'race.': 1, 'intelligent': 1, 'beings': 1, 'galaxy,': 1, 'make': 1, 'sure': 1, 'survive': 1, 'continue.': 1, 'entering': 1, 'increasingly': 1, 'dangerous': 1, 'period': 1, 'history.': 1, 'Our': 2, 'population': 1, 'use': 1, 'finite': 1, 'resources': 1, 'growing': 1, 'exponentially,': 1, 'along': 1, 'technical': 1, 'ability': 1, 'change': 1, 'environment': 1, 'ill.': 1, 'genetic': 1, 'code': 1, 'still': 1, 'carries': 1, 'selfish': 1, 'aggressive': 1, 'instincts': 1, 'survival': 2, 'advantage': 1, 'It': 1, 'will': 1, 'difficult': 1, 'enough': 1, 'avoid': 1, 'disaster': 1, 'next': 3, 'years,': 2, 'let': 1, 'thousand': 1, 'million.': 1, 'chance': 1, 'long-term': 1, 'not': 2, 'remain': 1, 'inward-looking': 1, 'spread': 1, 'answers': 2, 'these': 2, 'show': 1, 'remarkable': 1, 'if': 1, 'want': 1, 'continue': 1, 'beyond': 1, 'That': 1, 'why': 1, 'favor': 1, 'manned': 1, '–': 2, 'say,': 1, 'personned': 1, 'flight.': 1, 'All': 1, 'my': 2, 'sought': 1, 'understand': 1, 'questions.': 1, 'lucky': 1, 'disability': 1, 'has': 2, 'serious': 1, 'handicap.': 1, 'Indeed,': 1, 'more': 1, 'people': 1, 'pursue': 1, 'quest': 1, 'knowledge.': 1, 'ultimate': 1, 'goal': 1, 'complete': 1, 'making': 1, 'progress.': 1, 'Thank': 1, 'you': 1, 'listening.': 1}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "total = len(text_as_list)\n",
    "\n",
    "for i in text_as_list:\n",
    "    dic[i] = text_as_list.count(i)\n",
    "    \n",
    "    \n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd1b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3baa175",
   "metadata": {},
   "source": [
    "#### Without printing the whole dictionary, find how many times the word \"question\" appears in the list by using your new dictiornary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e6a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(dic[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6c425",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe from the items of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b642dabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bigger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>or</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>making</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>progress.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Thank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>listening.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0   1\n",
       "0         There   1\n",
       "1            is  12\n",
       "2       nothing   1\n",
       "3        bigger   1\n",
       "4            or   5\n",
       "..          ...  ..\n",
       "411      making   1\n",
       "412   progress.   1\n",
       "413       Thank   1\n",
       "414         you   1\n",
       "415  listening.   1\n",
       "\n",
       "[416 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dic.items())\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243050",
   "metadata": {},
   "source": [
    "#### Get the first row of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "595fb43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  There  1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404c70e",
   "metadata": {},
   "source": [
    "#### Get the first column of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05d6c34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1      12\n",
       "2       1\n",
       "3       1\n",
       "4       5\n",
       "       ..\n",
       "411     1\n",
       "412     1\n",
       "413     1\n",
       "414     1\n",
       "415     1\n",
       "Name: 1, Length: 416, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d289e",
   "metadata": {},
   "source": [
    "#### By using the `pandas.DataFrame.loc`, find how many times the words galaxies and galaxies appear in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20833ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'galaxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'galaxy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgalaxy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgalaxies\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3862\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   3863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3864\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   3867\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'galaxy'"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.set_index(1, inplace=True)\n",
    "df.loc['galaxy']\n",
    "df.loc['galaxies']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9540e5",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints 5! (i.e., the factorial of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af1dd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>progress.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listening.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1             \n",
       "1        There\n",
       "12          is\n",
       "1      nothing\n",
       "1       bigger\n",
       "5           or\n",
       "..         ...\n",
       "1       making\n",
       "1    progress.\n",
       "1        Thank\n",
       "1          you\n",
       "1   listening.\n",
       "\n",
       "[416 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76832032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact(n):\n",
    "    if n==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * fact(n-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80ed0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(fact(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4090",
   "metadata": {},
   "source": [
    "#### Write a recursion in a function that prints the $n^{th}$ [Fibonacci number](https://en.wikipedia.org/wiki/Fibonacci_number):\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2100ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if (n<=1):\n",
    "        return n\n",
    "    return fib (n-2) + fib(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45e165",
   "metadata": {},
   "source": [
    "#### Which is the $20^{th}$ Fibonacci number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7b9e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78def8f1",
   "metadata": {},
   "source": [
    "_We will try together tail recursion._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
